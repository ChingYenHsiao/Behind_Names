{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "(1) Import 使用的模組進來 , Import library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import csv\r\n",
    "import os\r\n",
    "import sys\r\n",
    "import pickle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#from NameModules.fortune_calculator import moe_data_dict, special_word_dict\r\n",
    "from NameModules.fortune_calculator import stroke_total\r\n",
    "from NameModules.fortune_calculator import stroke_outside\r\n",
    "from NameModules.fortune_calculator import stroke_man\r\n",
    "from NameModules.fortune_calculator import stroke_heaven\r\n",
    "from NameModules.fortune_calculator import stroke_earth\r\n",
    "from NameModules.fortune_calculator import test_name_Fortune_telling\r\n",
    "from NameModules.fortune_calculator import get_talent_type\r\n",
    "from NameModules.fortune_calculator import get_talent_state\r\n",
    "from NameModules.fortune_calculator import get_stroke_state\r\n",
    "from NameModules.fortune_calculator import Get_stroke\r\n",
    "from NameModules.share_lib import is_chinese, is_number, PrintException\r\n",
    "from NameModules.Taiwan_name_seperate import checkLastName, GetLastName, GetFirstName, get_LastName_from_FN, is_biFirstName\r\n",
    "\r\n",
    "\r\n",
    "'''\r\n",
    "checkLastName: 檢查名字的姓氏有無在百家姓的list中\r\n",
    "GetLastName: 取姓氏\r\n",
    "GetLastName: 取名字\r\n",
    "get_LastName_from_FN:\r\n",
    "is_biFirstName:是否是疊字名字 \r\n",
    "'''\r\n",
    "from NameModules.Taiwan_name_seperate import Taiwan_LastName_List, Taiwan_LastName_len1_List, Taiwan_LastName_len2_List\r\n",
    "from NameModules.NameModule import contain_Simplified_character , contain_unreadable_character\r\n",
    "\r\n",
    "'''\r\n",
    "contain_Simplified_character: find名字是否含非繁體字會用之字的簡體字\r\n",
    "contain_unreadable_character: 名字否含不可解讀的編碼的特殊字元\r\n",
    "'''\r\n",
    "\r\n",
    "from NameModules.share_lib import is_number,is_chinese, reduce_mem_usage\r\n",
    "'''\r\n",
    "reduce_mem_usage: 自動將df各欄的型態轉型成可接受的較小size 型態\r\n",
    "'''\r\n",
    "\r\n",
    "from gensim.models import word2vec\r\n",
    "\r\n",
    "from hanziconv import HanziConv \r\n",
    "\r\n",
    "\r\n",
    "def NamePreprecoess(Name_df):\r\n",
    "    ID_col = 'userID'\r\n",
    "    if ID_col in Name_df.columns:\r\n",
    "        #Drop duplicate name in FB source\r\n",
    "        FB_Name_df = Name_df [ Name_df[ID_col].apply(lambda x: type(x)!=float) ]\r\n",
    "        ori_len = len(FB_Name_df)\r\n",
    "        FB_Name_df = FB_Name_df.drop_duplicates(subset= ID_col ,keep='first',inplace=False)\r\n",
    "        print ('Drop duplicate FB name: from ',ori_len,'->',len(FB_Name_df),' drop:',ori_len-len(FB_Name_df))\r\n",
    "        \r\n",
    "        Name_df = Name_df[ Name_df[ID_col].apply(lambda x: type(x)==float) ]\r\n",
    "        Name_df = pd.concat([Name_df, FB_Name_df], ignore_index=True)\r\n",
    "    \r\n",
    "    #Drop Message is not number\r\n",
    "    ori_len = len(Name_df)\r\n",
    "    Name_df  = Name_df[ Name_df.message.apply(lambda x:type(x)!=float) ]\r\n",
    "    Name_df  = Name_df[ Name_df.message.apply(lambda x: is_number(x)) ]\r\n",
    "    print ('Drop Message is not number: ',ori_len,'->',len(Name_df),' drop:',ori_len-len(Name_df))\r\n",
    "    ori_len = len(Name_df)\r\n",
    "    \r\n",
    "    #Drop English name\r\n",
    "    ori_len = len(Name_df)\r\n",
    "    Name_df = Name_df[ Name_df.name.apply(lambda x: (is_chinese(x))) ]\r\n",
    "    print ('Drop English name: from ',ori_len,'->',len(Name_df),' drop:',ori_len - len(Name_df))\r\n",
    "\r\n",
    "    ori_len = len(Name_df)\r\n",
    "    #Drop last name is not in Taiwan all last name\r\n",
    "    Name_df = Name_df[Name_df.name.apply(lambda x: ( checkLastName(x)))]\r\n",
    "    print ('Dron last name is not in Taiwan last name list :',ori_len,'->',len(Name_df),' drop:',ori_len - len(Name_df))\r\n",
    "    ori_len = len(Name_df)\r\n",
    "\r\n",
    "    Name_df['LastName'] = Name_df.name.apply(lambda x: (GetLastName(x)))\r\n",
    "    Name_df['FirstName'] = Name_df.name.apply(lambda x: (GetFirstName(x)))\r\n",
    "\r\n",
    "    #Drop First name is longer than 3 \r\n",
    "    Name_df = Name_df[Name_df.FirstName.apply(lambda x: len(x)<3 )]\r\n",
    "    print ('Drop First name is longer than 3  :',ori_len,'->',len(Name_df),' drop:',ori_len - len(Name_df))\r\n",
    "    ori_len = len(Name_df)\r\n",
    "    \r\n",
    "    return Name_df\r\n",
    "\r\n",
    "\r\n",
    "def Read_Saved_Files():\r\n",
    "    pkl_data_path = './pkl_data/'\r\n",
    "    '''\r\n",
    "    w2v phonetic\r\n",
    "    '''\r\n",
    "    # 2XX萬名字的涵蓋的中文字 List,共8578種字, 如果把character 變成 編號的時候可以用\r\n",
    "    Totalname_list = ''\r\n",
    "    with open( pkl_data_path + 'Totalname_list.pkl', 'rb') as handle:\r\n",
    "        Totalname_list = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    # 萌典的本體 dict\r\n",
    "    moe_data_dict = {}\r\n",
    "    with open( pkl_data_path +'moe_data_dict.pkl', 'rb') as handle:\r\n",
    "        moe_data_dict = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    # 存同義字或是詞的dict\r\n",
    "    common_dict = {}\r\n",
    "    with open( pkl_data_path + 'common_dict.pkl', 'rb') as handle:\r\n",
    "        common_dict = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    '''\r\n",
    "    phonetic\r\n",
    "    '''\r\n",
    "    son_in_list = []\r\n",
    "    with open( pkl_data_path + 'son_in_list.pkl', 'rb') as handle:\r\n",
    "        son_in_list = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    mu_in_list = []\r\n",
    "    with open( pkl_data_path + 'mu_in_list.pkl', 'rb') as handle:\r\n",
    "        mu_in_list = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    special_word_dict = {}\r\n",
    "    with open( pkl_data_path + 'special_word_dict.pkl', 'rb') as handle:\r\n",
    "        special_word_dict = pickle.loads(handle.read())\r\n",
    "\r\n",
    "    return Totalname_list, moe_data_dict, common_dict, son_in_list, mu_in_list, special_word_dict\r\n",
    "\r\n",
    "def get_x_feature(feature_list , columns):\r\n",
    "    f = []\r\n",
    "    if 'gender' in feature_list:\r\n",
    "        f+=['Male_prob' , 'Female_prob']\r\n",
    "    \r\n",
    "    if 'uni-gram' in feature_list:\r\n",
    "        f+=['FN1','FN2']\r\n",
    "        \r\n",
    "    for col in columns:\r\n",
    "        if 'w2v' in feature_list and '_wv_' in col:\r\n",
    "            f+= [col]\r\n",
    "        elif 'phonetic' in feature_list and ( 'muin_' in col or 'sonin_' in col):\r\n",
    "            f+=[col]\r\n",
    "        elif 'fortune_map' in feature_list and (\"格_\" in col or '三才_' in col):\r\n",
    "            f+=[col]\r\n",
    "        elif 'Zodiac' in feature_list and 'Zodiac_' in col:\r\n",
    "            f+=[col]\r\n",
    "        elif 'radical' in feature_list and 'radical_' in col:\r\n",
    "            f+=[col]\r\n",
    "            \r\n",
    "    return f \r\n",
    "\r\n",
    "def add_word_vector(vector_model,word,n):\r\n",
    "    if word in vector_model.wv:\r\n",
    "        return vector_model.wv[word][n]\r\n",
    "    else:\r\n",
    "        if word in common_dict:\r\n",
    "            if common_dict[word] in vector_model.wv:\r\n",
    "                return vector_model.wv[common_dict[word]][n]\r\n",
    "            else:\r\n",
    "                return 0\r\n",
    "        else:\r\n",
    "            return 0\r\n",
    "        \r\n",
    "def Get_FN_WV( vector_model, FirstName, FN_loc ,WV_loc):\r\n",
    "    FN =' '\r\n",
    "    if len(FirstName)==2:\r\n",
    "        if FN_loc == 1:FN=FirstName[0]\r\n",
    "        else:FN=FirstName[1]\r\n",
    "    elif FN_loc==2:\r\n",
    "        FN=FirstName\r\n",
    "    return add_word_vector( vector_model,FN,WV_loc)       \r\n",
    "\r\n",
    "def character_to_index(name,n):\r\n",
    "    if n==1:\r\n",
    "        if name[0] in Totalname_list:\r\n",
    "            return Totalname_list.index(name[0])\r\n",
    "        else:\r\n",
    "            Totalname_list.append(name[0])\r\n",
    "            return Totalname_list.index(name[0])\r\n",
    "    if n==2 and len(name)==2:\r\n",
    "        if name[1] in Totalname_list:\r\n",
    "            return Totalname_list.index(name[1])\r\n",
    "        else:\r\n",
    "            Totalname_list.append(name[1])\r\n",
    "            return Totalname_list.index(name[1])\r\n",
    "    return -1\r\n",
    "\r\n",
    "def add_pin_in_column(character, mode):\r\n",
    "    # mode 1 = sonin = consonant\r\n",
    "    # mode 2 = muin = vowel\r\n",
    "\r\n",
    "    if character == -1:\r\n",
    "        return None\r\n",
    "    \r\n",
    "    #不在字典內的補齊\r\n",
    "    specail_word_pinyin_dic = {'艶': 'yàn', '鳯': 'fèng', '恵': 'huì', '姈': 'líng', '寳': 'bǎo', '姫': 'jī', '鑅': 'róng',\r\n",
    "                               \"玂\": \"qí\", \"浤\": \"hóng\", '煊': 'xuān', '斔': 'zhōng', '琜': 'lái', '苰': 'hóng', '玹': 'xuán', '姵': 'pèi', '妏': 'wèn',\r\n",
    "                               '妘': 'yún', '珺': 'jùn', '媗': 'xuān', '彣': 'wén', '玹': 'xuán', '瀞': 'jìng', '妡': 'xīn', '琁': 'xuán', '浤': 'hóng', '緁': 'jī',\r\n",
    "                               '媜': 'zhēng', '姸': 'yán', '嬅': 'huà', '眞': 'zhēn', '廼': 'nǎi', '寛': 'kuān', '秝': 'lì', '蕥': 'yǎ', '汯': 'hóng', '逹': 'dá', '萓': 'yí',\r\n",
    "                               '媃': 'róu', '孋': 'lí', '媁': 'wěi', '祤': 'yǔ', '媄': 'měi', '夆': 'fēng', '蒝': 'yuán', '嬣': 'níng', '砡': 'yù', '芠': 'wén',\r\n",
    "                               '姳': 'mǐng', '蔆': 'líng', '菈': 'lā', '鍹': 'xuān', '榳': 'tíng', '錤': 'jī', '憓': 'huì', '潓': 'huì', '瓈': 'lí', '芛': 'wěi',\r\n",
    "                               '峮': 'qún', '鋕': 'zhì', '姷': 'yòu', '兪': 'yú', '瑠': 'liú', '嫙': 'xuán', '珅': 'shēn', '暟': 'kǎi', '斈': 'xué', '煐': 'yīng', '淓': 'fāng', '瑨': 'jìn', '嬨': 'cí', '琹': 'qín', '珆': 'yí', '琣': 'pěi',\r\n",
    "                               '娪': 'wú', '荺': 'yǔn', '爕': 'xiè', '玶': 'píng', '鋆': 'yún', '愼': 'shèn', '斳': 'qín', '瑈': 'róu', '澪': 'líng', '珦': 'xiàng', '妶': 'xián', '姃': 'zhēng', '薾': 'ěr', '溎': 'guì', '琄': 'xuàn', '琡': 'shū', '瑭': 'táng', '嫆': 'róng'\r\n",
    "                               }\r\n",
    "    #term = character\r\n",
    "    term = Totalname_list[character]\r\n",
    "    unkown_dict = {}\r\n",
    "    try:\r\n",
    "        if term not in moe_data_dict:\r\n",
    "            term = HanziConv.toTraditional(term)\r\n",
    "\r\n",
    "        if term == ' ':\r\n",
    "            return None\r\n",
    "\r\n",
    "        if term in moe_data_dict:\r\n",
    "            for hete in moe_data_dict[term]['heteronyms']:\r\n",
    "                if 'pinyin' in hete and moe_data_dict[term]['title'] != '啐':\r\n",
    "                    word_p = hete['pinyin']\r\n",
    "\r\n",
    "                    if '（' in (hete['pinyin']):\r\n",
    "                        if '（讀音）' in hete['pinyin']:\r\n",
    "                            word_p = hete['pinyin'].replace('（讀音）', '')\r\n",
    "                        if '（語音）' in hete['pinyin']:\r\n",
    "                            word_p = hete['pinyin'].replace('（語音）', '')\r\n",
    "                        if '(' in word_p:\r\n",
    "                            print(word_p+\"!!\")\r\n",
    "\r\n",
    "                    for mu in mu_in_list:\r\n",
    "                        if mu in word_p:\r\n",
    "                            if mode == 'sonin':\r\n",
    "                                return word_p[: word_p.index(mu)]\r\n",
    "                            else:\r\n",
    "                                return mu\r\n",
    "            # 找不到字音，看是否是哪個字的異體字\r\n",
    "            for hete in moe_data_dict[term]['heteronyms']:\r\n",
    "                for define in hete['definitions']:\r\n",
    "                    if '異體字' in define['def']:\r\n",
    "                        d = define['def']\r\n",
    "                        alt_term = d[d.index('「')+1: d.index('」')]\r\n",
    "                        # print(alt_term,term)\r\n",
    "\r\n",
    "                        for hete2 in moe_data_dict[alt_term]['heteronyms']:\r\n",
    "                            if 'pinyin' in hete2 and moe_data_dict[alt_term]['title'] != '啐':\r\n",
    "\r\n",
    "                                word_p = hete2['pinyin']\r\n",
    "                                if '（' in (hete2['pinyin']):\r\n",
    "                                    if '（讀音）' in hete2['pinyin']:\r\n",
    "                                        word_p = hete2['pinyin'].replace(\r\n",
    "                                            '（讀音）', '')\r\n",
    "                                    if '（語音）' in hete2['pinyin']:\r\n",
    "                                        word_p = hete2['pinyin'].replace(\r\n",
    "                                            '（語音）', '')\r\n",
    "                                    if '(' in word_p:\r\n",
    "                                        print(word_p+\"!!\")\r\n",
    "\r\n",
    "                                for mu in mu_in_list:\r\n",
    "                                    if mu in word_p:\r\n",
    "                                        if mode == 'sonin':\r\n",
    "                                            return word_p[: word_p.index(mu)]\r\n",
    "                                        else:\r\n",
    "                                            return mu\r\n",
    "            # print('在字典內但沒有拼音：',term)\r\n",
    "        else:\r\n",
    "            # print('不在字典內：',term)\r\n",
    "\r\n",
    "            if term in special_word_dict:\r\n",
    "                word_p = special_word_dict[term]['pinyin']\r\n",
    "                for mu in mu_in_list:\r\n",
    "                    if mu in word_p:\r\n",
    "                        if mode == 'sonin':\r\n",
    "                            return word_p[: word_p.index(mu)]\r\n",
    "                        else:\r\n",
    "                            return mu\r\n",
    "            else:\r\n",
    "                print('拼音不明：',term)\r\n",
    "                if term not in unkown_dict:\r\n",
    "                    unkown_dict[term] = 1\r\n",
    "                else:\r\n",
    "                    unkown_dict[term] += 1\r\n",
    "\r\n",
    "#             if len( moe_df[moe_df.字詞名.apply(lambda x: x==term)])>0:\r\n",
    "#                 print('不在字典內：',term)\r\n",
    "        return unkown_dict\r\n",
    "    except Exception as e:\r\n",
    "        print(e)\r\n",
    "        PrintException()\r\n",
    "\r\n",
    "def add_W2V_feature( Name_df,w2v_Vector_number):\r\n",
    "    ###############################################################\r\n",
    "    #Add w2v\r\n",
    "    #用17G的維基百科+幾十M的萌典範文訓練的w2v, 每個entry是一個字\r\n",
    "    moe_model = word2vec.Word2Vec.load(\"./w2v_data/wiki_moe_100_model.bin\")\r\n",
    "    \r\n",
    "    for i in range(0,w2v_Vector_number):\r\n",
    "        Name_df['FN1_wv_'+str(i)]  = Name_df[\"FirstName\"].apply(lambda x:  Get_FN_WV( moe_model , x, 1 , i))\r\n",
    "        Name_df['FN2_wv_'+str(i)]  = Name_df[\"FirstName\"].apply(lambda x:  Get_FN_WV( moe_model , x, 2 , i))\r\n",
    "        \r\n",
    "    Name_df , NA_list = reduce_mem_usage( Name_df )\r\n",
    "    \r\n",
    "    w2v_feature = get_x_feature( ['w2v'], Name_df.columns)\r\n",
    "    print(\"w2v_feature len\",len(w2v_feature))\r\n",
    "    ################################################################ \r\n",
    "    return Name_df , w2v_feature\r\n",
    "\r\n",
    "def add_phonetic_feature(Name_df):\r\n",
    "    Name_df['FN1'] = Name_df.FirstName.apply(lambda x: character_to_index(x,1))\r\n",
    "    Name_df['FN2'] = Name_df.FirstName.apply(lambda x: character_to_index(x,2))\r\n",
    "    \r\n",
    "    Name_df['FN1_sonin'] = Name_df.FN1.apply(lambda x:  add_pin_in_column(x,'sonin') )\r\n",
    "    Name_df['FN1_muin'] = Name_df.FN1.apply(lambda x:  add_pin_in_column(x,'muin') )\r\n",
    "\r\n",
    "    Name_df['FN2_sonin'] = Name_df.FN2.apply(lambda x:  add_pin_in_column(x,'sonin') )\r\n",
    "    Name_df['FN2_muin'] = Name_df.FN2.apply(lambda x:  add_pin_in_column(x,'muin') )\r\n",
    "\r\n",
    "    Name_df = pd.get_dummies(Name_df, columns=[\"FN1_sonin\"])\r\n",
    "    Name_df = pd.get_dummies(Name_df, columns=[\"FN1_muin\"])\r\n",
    "    Name_df = pd.get_dummies(Name_df, columns=[\"FN2_sonin\"])\r\n",
    "    Name_df = pd.get_dummies(Name_df, columns=[\"FN2_muin\"])\r\n",
    "    \r\n",
    "    phonetic_feature = get_x_feature( ['phonetic'] , Name_df.columns)\r\n",
    "    print('phonetic_feature len:',len(phonetic_feature))\r\n",
    "    \r\n",
    "    return Name_df , phonetic_feature\r\n",
    "\r\n",
    "def add_fortune_map_feature(sampled_df):\r\n",
    "    sampled_df['天格'] = sampled_df['LastName'].apply(lambda x: get_stroke_state(stroke_heaven (x)) )\r\n",
    "    sampled_df['地格'] = sampled_df['LastName'].apply(lambda x: get_stroke_state(stroke_earth (x)) )\r\n",
    "    sampled_df['人格'] = sampled_df.apply(lambda x: get_stroke_state(stroke_man (x)) ,axis = 1)\r\n",
    "    sampled_df['外格'] = sampled_df.apply(lambda x: get_stroke_state(stroke_outside (x)) ,axis = 1)\r\n",
    "    sampled_df['總格'] = sampled_df.apply(lambda x: get_stroke_state(stroke_total (x)) ,axis = 1)\r\n",
    "    sampled_df['三才'] = sampled_df.apply(lambda x: get_talent_state(get_talent_type(stroke_heaven(\r\n",
    "        x['LastName'])) + get_talent_type(stroke_earth(x['LastName'])) + get_talent_type(stroke_man(x))), axis=1)\r\n",
    "    \r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"天格\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"地格\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"人格\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"外格\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"總格\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"三才\"])\r\n",
    "\r\n",
    "    fortune_map_feature_list = get_x_feature( ['fortune_map'] , sampled_df.columns)\r\n",
    "    print(\"len on fortune_map_feature_list:\",len(fortune_map_feature_list))\r\n",
    "    return sampled_df , fortune_map_feature_list\r\n",
    "\r\n",
    "def add_radical_column_age(character):\r\n",
    "    if character in moe_data_dict:\r\n",
    "        return moe_data_dict[character]['radical'] \r\n",
    "    elif character in special_word_dict :\r\n",
    "        return special_word_dict[character]['radical']  \r\n",
    "    else:\r\n",
    "        return '不明'\r\n",
    "        #return -1\r\n",
    "\r\n",
    "def add_radical_feature(sampled_df):\r\n",
    "    #FN1存成index\r\n",
    "    sampled_df['FN1_radical'] = sampled_df['FN1'].apply(lambda x: add_radical_column_age( Totalname_list[x]))\r\n",
    "    sampled_df['FN2_radical'] = sampled_df['FN2'].apply(lambda x: add_radical_column_age( Totalname_list[x]))\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"FN1_radical\"])\r\n",
    "    sampled_df = pd.get_dummies(sampled_df, columns=[\"FN2_radical\"])\r\n",
    "\r\n",
    "    Radical_feature_list = get_x_feature( ['radical'] , sampled_df.columns)\r\n",
    "    print(\"len of Radical_feature_list: \",len(Radical_feature_list))\r\n",
    "    return sampled_df , Radical_feature_list\r\n",
    "    \r\n",
    "def get_zodiac_from_birthyear(birthyear):\r\n",
    "    zodiac_list = ['鼠', '牛', '虎', '兔', '龍', '蛇', '馬', '羊', '猴', '雞', '狗', '豬']\r\n",
    "    return zodiac_list[divmod((birthyear - 4), 12)[1]]\r\n",
    "\r\n",
    "\r\n",
    "def add_zodiac_feature(Name_df):\r\n",
    "    Name_df['Zodiac'] = Name_df['message'].apply(lambda x: get_zodiac_from_birthyear(x))\r\n",
    "    Name_df = pd.get_dummies(Name_df, columns=[\"Zodiac\"])\r\n",
    "    \r\n",
    "    Zodiac_feature_list = get_x_feature(\"Zodiac\" , Name_df )\r\n",
    "    print(\"len of Zodiac_feature_list: \",len(Zodiac_feature_list))\r\n",
    "    return Name_df , Zodiac_feature_list "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(2)讀檔 Read Files"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "Path = './NameData/gcname_df_featured.csv'\r\n",
    "Name_df = pd.read_csv(Path, dtype='str')\r\n",
    "#Name_df [['name', 'BirthYear','FirstName','LastName','gender','message','userID','WritingNumber']].to_csv(\"./NameData/Total_Name.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "Name_df.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['name', 'BirthYear', 'FirstName', 'LastName', 'gender', 'message',\n",
       "       'userID', 'FN1_wv_0', 'FN2_wv_0', 'FN1_wv_1',\n",
       "       ...\n",
       "       'Zodiac_狗', 'Zodiac_猴', 'Zodiac_羊', 'Zodiac_虎', 'Zodiac_蛇', 'Zodiac_豬',\n",
       "       'Zodiac_雞', 'Zodiac_馬', 'Zodiac_鼠', 'Zodiac_龍'],\n",
       "      dtype='object', length=977)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Name_df = Name_df[[ 'name', 'BirthYear', 'FirstName', 'LastName', 'gender',\r\n",
    "#       'message', 'userID']]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "source": [
    "#將object type 復原回int\r\n",
    "Name_df['BirthYear'] = Name_df.BirthYear.apply(lambda x: int(x))\r\n",
    "Name_df['gender'] = Name_df.gender.apply(lambda x: int(float(x)))\r\n",
    "Name_df['message'] =  Name_df.message.apply(lambda x: int(x))\r\n",
    "\r\n",
    "type_dic = {}\r\n",
    "for w2v_col in get_x_feature(['w2v'],Name_df):\r\n",
    "    type_dic[ w2v_col ] = 'float32'\r\n",
    "\r\n",
    "for col in get_x_feature(['phonetic','fortune_map','Zodiac','radical'],Name_df):\r\n",
    "    type_dic[ col ] = 'int8'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "source": [
    "Name_df = Name_df.astype( type_dic )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "Name_df.dtypes"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "name         object\n",
       "BirthYear     int64\n",
       "FirstName    object\n",
       "LastName     object\n",
       "gender        int64\n",
       "              ...  \n",
       "Zodiac_豬       int8\n",
       "Zodiac_雞       int8\n",
       "Zodiac_馬       int8\n",
       "Zodiac_鼠       int8\n",
       "Zodiac_龍       int8\n",
       "Length: 977, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from collections import Counter\r\n",
    "#FN_counter = Counter(Name_df['FirstName'].tolist())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3) Preparing for learing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-1)Import learning fucntion"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import confusion_matrix"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "## from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.metrics import confusion_matrix\r\n",
    "\r\n",
    "\r\n",
    "def dataset_statistics(dataset):\r\n",
    "    \"\"\"\r\n",
    "    Basic statistics of the dataset\r\n",
    "    :param dataset: Pandas dataframe\r\n",
    "    :return: None, print the basic statistics of the dataset\r\n",
    "    \"\"\"\r\n",
    "    print(dataset.describe())\r\n",
    "\r\n",
    "# http://dataaspirant.com/2017/06/26/random-forest-classifier-python-scikit-learn/\r\n",
    "# Split train and test\r\n",
    "\r\n",
    "\r\n",
    "def split_dataset(dataset, train_percentage, feature_headers, target_header):\r\n",
    "    \"\"\"\r\n",
    "    Split the dataset with train_percentage\r\n",
    "    :param dataset:\r\n",
    "    :param train_percentage:\r\n",
    "    :param feature_headers:\r\n",
    "    :param target_header:\r\n",
    "    :return: train_x, test_x, train_y, test_y\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Split dataset into train and test dataset\r\n",
    "    train_x, test_x, train_y, test_y = train_test_split(dataset[feature_headers], dataset[target_header],\r\n",
    "                                                        train_size=train_percentage)\r\n",
    "    return train_x, test_x, train_y, test_y\r\n",
    "\r\n",
    "\r\n",
    "def random_forest_classifier(features, target, estimators_num=32,  min_samples_leaf_num=1):\r\n",
    "    \"\"\"\r\n",
    "    To train the random forest classifier with features and target data\r\n",
    "    :param features:\r\n",
    "    :param target:\r\n",
    "    :return: trained random forest classifier\r\n",
    "    \"\"\"\r\n",
    "    clf = RandomForestClassifier(\r\n",
    "        n_estimators= estimators_num, n_jobs=4, min_samples_leaf= min_samples_leaf_num , random_state=42)\r\n",
    "    print('estimators_num = ' , estimators_num , 'min_samples_leaf_num = ' , min_samples_leaf_num ,\"Training Data len = \", len(features))\r\n",
    "    clf.fit(features, target)\r\n",
    "    return clf\r\n",
    "\r\n",
    "\r\n",
    "def random_forest_Regressor(features, target):\r\n",
    "    \"\"\"\r\n",
    "    To train the random forest classifier with features and target data\r\n",
    "    :param features:\r\n",
    "    :param target:\r\n",
    "    :return: trained random forest classifier\r\n",
    "    \"\"\"\r\n",
    "    clf = RandomForestRegressor(n_estimators=32, n_jobs=4, min_samples_leaf=1)\r\n",
    "    clf.fit(features, target)\r\n",
    "    return clf\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-1) Train gender RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "from sklearn.metrics import recall_score\r\n",
    "from sklearn.metrics import f1_score\r\n",
    "from sklearn.metrics import precision_score\r\n",
    "from sklearn.metrics import classification_report\r\n",
    "from sklearn import metrics"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "source": [
    "Name_df[ [\"gender\",\"FirstName\"]].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138501.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.58640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.49248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             gender\n",
       "count  138501.00000\n",
       "mean        0.58640\n",
       "std         0.49248\n",
       "min         0.00000\n",
       "25%         0.00000\n",
       "50%         1.00000\n",
       "75%         1.00000\n",
       "max         1.00000"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "y_feature = ['gender']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "feature_combinations = []"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-2)Make Feature Combinations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "source": [
    "feature_list = ['w2v', 'phonetic','fortune_map','Zodiac','radical']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "feature_list_gender = ['w2v', 'phonetic','fortune_map','Zodiac','radical','uni-gram']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from itertools import chain, combinations\r\n",
    "\r\n",
    "def get_all_combinations(feature_list):\r\n",
    "    feature_combinations = [ x for x in feature_list]\r\n",
    "    for i in range(2 , len(feature_list)+1):\r\n",
    "        for combo in ( combinations(feature_list , r= i) ):\r\n",
    "            temp =[]\r\n",
    "            for f in combo:\r\n",
    "                temp+=[f]\r\n",
    "            feature_combinations += [temp]\r\n",
    "    return feature_combinations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "feature_combinations_gender = get_all_combinations(feature_list_gender)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "x_feature = get_x_feature (['w2v'] , Name_df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "Name_df.FN1"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0          256\n",
       "1         3763\n",
       "2          884\n",
       "3          987\n",
       "4          755\n",
       "          ... \n",
       "138496     203\n",
       "138497      29\n",
       "138498    1158\n",
       "138499      78\n",
       "138500     249\n",
       "Name: FN1, Length: 138501, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "Name_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>message</th>\n",
       "      <th>userID</th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Zodiac_狗</th>\n",
       "      <th>Zodiac_猴</th>\n",
       "      <th>Zodiac_羊</th>\n",
       "      <th>Zodiac_虎</th>\n",
       "      <th>Zodiac_蛇</th>\n",
       "      <th>Zodiac_豬</th>\n",
       "      <th>Zodiac_雞</th>\n",
       "      <th>Zodiac_馬</th>\n",
       "      <th>Zodiac_鼠</th>\n",
       "      <th>Zodiac_龍</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁承先</td>\n",
       "      <td>0</td>\n",
       "      <td>承先</td>\n",
       "      <td>丁</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.082778</td>\n",
       "      <td>-5.796417</td>\n",
       "      <td>4.782166</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁昞原</td>\n",
       "      <td>0</td>\n",
       "      <td>昞原</td>\n",
       "      <td>丁</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.442101</td>\n",
       "      <td>0.381964</td>\n",
       "      <td>1.215422</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>方超</td>\n",
       "      <td>0</td>\n",
       "      <td>超</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.596860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>方九龍</td>\n",
       "      <td>0</td>\n",
       "      <td>九龍</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.789320</td>\n",
       "      <td>-2.980340</td>\n",
       "      <td>-1.893114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>方大錚</td>\n",
       "      <td>0</td>\n",
       "      <td>大錚</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.813373</td>\n",
       "      <td>-4.719679</td>\n",
       "      <td>-0.937114</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138496</th>\n",
       "      <td>程麗庭</td>\n",
       "      <td>8</td>\n",
       "      <td>麗庭</td>\n",
       "      <td>程</td>\n",
       "      <td>0</td>\n",
       "      <td>1982</td>\n",
       "      <td>259328941245892</td>\n",
       "      <td>3.107082</td>\n",
       "      <td>1.373621</td>\n",
       "      <td>0.181308</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138497</th>\n",
       "      <td>許家榛</td>\n",
       "      <td>7</td>\n",
       "      <td>家榛</td>\n",
       "      <td>許</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>505551569779505</td>\n",
       "      <td>-0.024527</td>\n",
       "      <td>-0.138811</td>\n",
       "      <td>1.429394</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138498</th>\n",
       "      <td>田崑成</td>\n",
       "      <td>7</td>\n",
       "      <td>崑成</td>\n",
       "      <td>田</td>\n",
       "      <td>1</td>\n",
       "      <td>1978</td>\n",
       "      <td>138985933375787</td>\n",
       "      <td>4.559606</td>\n",
       "      <td>6.068225</td>\n",
       "      <td>2.725899</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138499</th>\n",
       "      <td>筱欣</td>\n",
       "      <td>11</td>\n",
       "      <td>欣</td>\n",
       "      <td>筱</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1282157788580648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.398280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138500</th>\n",
       "      <td>劉思昀</td>\n",
       "      <td>12</td>\n",
       "      <td>思昀</td>\n",
       "      <td>劉</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>1461152050629940</td>\n",
       "      <td>2.650452</td>\n",
       "      <td>-1.726804</td>\n",
       "      <td>0.494862</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138501 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  BirthYear FirstName LastName  gender  message            userID  \\\n",
       "0       丁承先          0        承先        丁       1     1940               NaN   \n",
       "1       丁昞原          0        昞原        丁       1     1940               NaN   \n",
       "2        方超          0         超        方       1     1940               NaN   \n",
       "3       方九龍          0        九龍        方       1     1940               NaN   \n",
       "4       方大錚          0        大錚        方       1     1940               NaN   \n",
       "...     ...        ...       ...      ...     ...      ...               ...   \n",
       "138496  程麗庭          8        麗庭        程       0     1982   259328941245892   \n",
       "138497  許家榛          7        家榛        許       0     1979   505551569779505   \n",
       "138498  田崑成          7        崑成        田       1     1978   138985933375787   \n",
       "138499   筱欣         11         欣        筱       0     1998  1282157788580648   \n",
       "138500  劉思昀         12        思昀        劉       0     2003  1461152050629940   \n",
       "\n",
       "        FN1_wv_0  FN2_wv_0  FN1_wv_1  ...  Zodiac_狗  Zodiac_猴  Zodiac_羊  \\\n",
       "0      -0.082778 -5.796417  4.782166  ...         0         0         0   \n",
       "1      -1.442101  0.381964  1.215422  ...         0         0         0   \n",
       "2       0.000000 -3.596860  0.000000  ...         0         0         0   \n",
       "3       3.789320 -2.980340 -1.893114  ...         0         0         0   \n",
       "4       3.813373 -4.719679 -0.937114  ...         0         0         0   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "138496  3.107082  1.373621  0.181308  ...         1         0         0   \n",
       "138497 -0.024527 -0.138811  1.429394  ...         0         0         1   \n",
       "138498  4.559606  6.068225  2.725899  ...         0         0         0   \n",
       "138499  0.000000 -2.398280  0.000000  ...         0         0         0   \n",
       "138500  2.650452 -1.726804  0.494862  ...         0         0         1   \n",
       "\n",
       "        Zodiac_虎  Zodiac_蛇  Zodiac_豬  Zodiac_雞  Zodiac_馬  Zodiac_鼠  Zodiac_龍  \n",
       "0              0         0         0         0         0         0         1  \n",
       "1              0         0         0         0         0         0         1  \n",
       "2              0         0         0         0         0         0         1  \n",
       "3              0         0         0         0         0         0         1  \n",
       "4              0         0         0         0         0         0         1  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "138496         0         0         0         0         0         0         0  \n",
       "138497         0         0         0         0         0         0         0  \n",
       "138498         0         0         0         0         1         0         0  \n",
       "138499         1         0         0         0         0         0         0  \n",
       "138500         0         0         0         0         0         0         0  \n",
       "\n",
       "[138501 rows x 977 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-3)Add most gender as y feature"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "source": [
    "sampled_df = Name_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#用來扣掉同名字但有不同性別存在的名字\r\n",
    "#name_gender_dict內大於0的就是男生,反之女生,0則男女各半\r\n",
    "name_gender_dict = {}\r\n",
    "def name_gender_count(row):\r\n",
    "    name = row['FirstName']\r\n",
    "    gender = row['gender']\r\n",
    "    if name in name_gender_dict:\r\n",
    "        if gender==1:\r\n",
    "            name_gender_dict[name]+=1\r\n",
    "        else:\r\n",
    "            name_gender_dict[name]-=1\r\n",
    "    else:\r\n",
    "        if gender==1:\r\n",
    "            name_gender_dict[name]=1\r\n",
    "        else:\r\n",
    "            name_gender_dict[name]=-1        \r\n",
    "    \r\n",
    "sampled_df.apply(lambda row: name_gender_count(row),axis=1)\r\n",
    "print(name_gender_dict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "#中性名字沒分第三類別,直接任塞一性別\r\n",
    "import random\r\n",
    "for name in name_gender_dict:\r\n",
    "    if name_gender_dict[name] ==0:\r\n",
    "        if random.randint(0,1) == 0:\r\n",
    "            name_gender_dict[name] = -1\r\n",
    "        else:\r\n",
    "            name_gender_dict[name] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "source": [
    "def add_most_gender(row):\r\n",
    "    name = row['FirstName']\r\n",
    "    gender = row['gender']\r\n",
    "    \r\n",
    "    if name_gender_dict[name] > 0:\r\n",
    "        return 1\r\n",
    "    if name_gender_dict[name] < 0:\r\n",
    "        return 0\r\n",
    "\r\n",
    "    if name_gender_dict[name] == 0:\r\n",
    "        return -1\r\n",
    "sampled_df['mgender'] = sampled_df.apply(lambda row: add_most_gender(row),axis=1)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "sampled_df.gender.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    81217\n",
       "0    57284\n",
       "Name: gender, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 193
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "sampled_df.mgender.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1    81475\n",
       "0    57026\n",
       "Name: mgender, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-4)W2V 做normalize"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "def _normalize(X, train = True, specified_column = None, X_mean = None, X_std = None):\r\n",
    "    # This function normalizes specific columns of X.\r\n",
    "    # The mean and standard variance of training data will be reused when processing testing data.\r\n",
    "    #\r\n",
    "    # Arguments:\r\n",
    "    #     X: data to be processed\r\n",
    "    #     train: 'True' when processing training data, 'False' for testing data\r\n",
    "    #     specific_column: indexes of the columns that will be normalized. If 'None', all columns\r\n",
    "    #         will be normalized.\r\n",
    "    #     X_mean: mean value of training data, used when train = 'False'\r\n",
    "    #     X_std: standard deviation of training data, used when train = 'False'\r\n",
    "    # Outputs:\r\n",
    "    #     X: normalized data\r\n",
    "    #     X_mean: computed mean value of training data\r\n",
    "    #     X_std: computed standard deviation of training data\r\n",
    "\r\n",
    "    if specified_column == None:\r\n",
    "        #np.arange(X.shape[1])只拿的到pd的shape  [0~n],不能拿到pd的欄位名稱\r\n",
    "        specified_column = np.arange(X.shape[1])\r\n",
    "        #specified_column = X.columns\r\n",
    "    if train:\r\n",
    "        #X_mean為一個list放每行的mean\r\n",
    "        X_mean = np.mean(X[:, specified_column] ,0).reshape(1, -1)\r\n",
    "        X_std  = np.std(X[:, specified_column], 0).reshape(1, -1)\r\n",
    "\r\n",
    "    X[:,specified_column] = (X[:, specified_column] - X_mean) / (X_std + 1e-8)\r\n",
    "     \r\n",
    "    return X, X_mean, X_std"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "def w2v_normalize(sampled_df):\r\n",
    "    x_feature = get_x_feature ( ['w2v'] , Name_df.columns)\r\n",
    "    w2v_np = sampled_df[ x_feature ].to_numpy()\r\n",
    "    # Normalize training and testing data\r\n",
    "    w2v_np, X_mean, X_std = _normalize(w2v_np, train = True)\r\n",
    "    \r\n",
    "    idx = 0\r\n",
    "    for i in range(100):\r\n",
    "        for j in range(1,3):\r\n",
    "            col = (\"FN{}_wv_{}\".format(j,i))\r\n",
    "            print(col)\r\n",
    "            FN_w2vX =[] \r\n",
    "            for vector_list in (w2v_np):\r\n",
    "                FN_w2vX+=[ vector_list[idx]  ]\r\n",
    "            idx+=1\r\n",
    "            sampled_df[col] = FN_w2vX\r\n",
    "    return sampled_df"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "source": [
    "#未normalized\r\n",
    "sampled_df[ x_feature ].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>FN2_wv_1</th>\n",
       "      <th>FN1_wv_2</th>\n",
       "      <th>FN2_wv_2</th>\n",
       "      <th>FN1_wv_3</th>\n",
       "      <th>FN2_wv_3</th>\n",
       "      <th>FN1_wv_4</th>\n",
       "      <th>FN2_wv_4</th>\n",
       "      <th>...</th>\n",
       "      <th>FN1_wv_95</th>\n",
       "      <th>FN2_wv_95</th>\n",
       "      <th>FN1_wv_96</th>\n",
       "      <th>FN2_wv_96</th>\n",
       "      <th>FN1_wv_97</th>\n",
       "      <th>FN2_wv_97</th>\n",
       "      <th>FN1_wv_98</th>\n",
       "      <th>FN2_wv_98</th>\n",
       "      <th>FN1_wv_99</th>\n",
       "      <th>FN2_wv_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "      <td>138501.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.149561</td>\n",
       "      <td>-1.142548</td>\n",
       "      <td>0.335170</td>\n",
       "      <td>0.984800</td>\n",
       "      <td>-1.303121</td>\n",
       "      <td>-1.285600</td>\n",
       "      <td>0.969382</td>\n",
       "      <td>1.649082</td>\n",
       "      <td>0.932246</td>\n",
       "      <td>0.639874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852125</td>\n",
       "      <td>0.855012</td>\n",
       "      <td>-0.818223</td>\n",
       "      <td>-1.027274</td>\n",
       "      <td>0.639393</td>\n",
       "      <td>0.495382</td>\n",
       "      <td>0.975133</td>\n",
       "      <td>0.860273</td>\n",
       "      <td>-1.179080</td>\n",
       "      <td>-1.059375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.492488</td>\n",
       "      <td>3.323843</td>\n",
       "      <td>3.474877</td>\n",
       "      <td>3.337498</td>\n",
       "      <td>3.092279</td>\n",
       "      <td>3.200081</td>\n",
       "      <td>3.298764</td>\n",
       "      <td>3.259781</td>\n",
       "      <td>3.352327</td>\n",
       "      <td>3.217403</td>\n",
       "      <td>...</td>\n",
       "      <td>3.348929</td>\n",
       "      <td>3.137315</td>\n",
       "      <td>3.328003</td>\n",
       "      <td>3.158895</td>\n",
       "      <td>3.503989</td>\n",
       "      <td>3.088225</td>\n",
       "      <td>2.894282</td>\n",
       "      <td>2.827303</td>\n",
       "      <td>3.368849</td>\n",
       "      <td>3.369553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-14.552404</td>\n",
       "      <td>-14.552404</td>\n",
       "      <td>-15.155359</td>\n",
       "      <td>-15.155359</td>\n",
       "      <td>-10.770514</td>\n",
       "      <td>-12.120364</td>\n",
       "      <td>-13.059869</td>\n",
       "      <td>-13.059869</td>\n",
       "      <td>-19.813513</td>\n",
       "      <td>-19.813513</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.671687</td>\n",
       "      <td>-15.675972</td>\n",
       "      <td>-11.840435</td>\n",
       "      <td>-13.274806</td>\n",
       "      <td>-10.960847</td>\n",
       "      <td>-10.634512</td>\n",
       "      <td>-13.096807</td>\n",
       "      <td>-13.096807</td>\n",
       "      <td>-11.716203</td>\n",
       "      <td>-11.936399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-3.428356</td>\n",
       "      <td>-3.267654</td>\n",
       "      <td>-1.943416</td>\n",
       "      <td>-1.286454</td>\n",
       "      <td>-3.024722</td>\n",
       "      <td>-3.490335</td>\n",
       "      <td>-0.700949</td>\n",
       "      <td>-0.314655</td>\n",
       "      <td>-0.800308</td>\n",
       "      <td>-1.321648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926266</td>\n",
       "      <td>-0.984259</td>\n",
       "      <td>-3.091983</td>\n",
       "      <td>-3.060984</td>\n",
       "      <td>-1.220916</td>\n",
       "      <td>-1.220916</td>\n",
       "      <td>-0.894890</td>\n",
       "      <td>-1.018355</td>\n",
       "      <td>-3.538004</td>\n",
       "      <td>-3.236742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.849926</td>\n",
       "      <td>-1.173061</td>\n",
       "      <td>0.181308</td>\n",
       "      <td>1.185356</td>\n",
       "      <td>-1.684384</td>\n",
       "      <td>-1.669534</td>\n",
       "      <td>1.110161</td>\n",
       "      <td>1.810379</td>\n",
       "      <td>0.969153</td>\n",
       "      <td>0.752990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866414</td>\n",
       "      <td>1.216405</td>\n",
       "      <td>-0.612317</td>\n",
       "      <td>-1.291795</td>\n",
       "      <td>0.270797</td>\n",
       "      <td>0.459639</td>\n",
       "      <td>0.671934</td>\n",
       "      <td>0.629546</td>\n",
       "      <td>-0.906662</td>\n",
       "      <td>-1.021606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.880691</td>\n",
       "      <td>0.837845</td>\n",
       "      <td>2.884024</td>\n",
       "      <td>3.441082</td>\n",
       "      <td>0.328431</td>\n",
       "      <td>0.566860</td>\n",
       "      <td>3.235934</td>\n",
       "      <td>3.917055</td>\n",
       "      <td>3.014434</td>\n",
       "      <td>2.652030</td>\n",
       "      <td>...</td>\n",
       "      <td>2.981780</td>\n",
       "      <td>2.909477</td>\n",
       "      <td>1.220726</td>\n",
       "      <td>0.991717</td>\n",
       "      <td>2.560374</td>\n",
       "      <td>2.222106</td>\n",
       "      <td>2.960142</td>\n",
       "      <td>2.960142</td>\n",
       "      <td>0.654513</td>\n",
       "      <td>0.882206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13.809453</td>\n",
       "      <td>13.809453</td>\n",
       "      <td>13.278703</td>\n",
       "      <td>12.627606</td>\n",
       "      <td>12.577226</td>\n",
       "      <td>13.612901</td>\n",
       "      <td>15.600971</td>\n",
       "      <td>15.600971</td>\n",
       "      <td>12.603272</td>\n",
       "      <td>12.603272</td>\n",
       "      <td>...</td>\n",
       "      <td>13.278911</td>\n",
       "      <td>13.278911</td>\n",
       "      <td>17.067118</td>\n",
       "      <td>17.067118</td>\n",
       "      <td>15.014699</td>\n",
       "      <td>14.567921</td>\n",
       "      <td>13.154280</td>\n",
       "      <td>13.154280</td>\n",
       "      <td>14.519915</td>\n",
       "      <td>14.381725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            FN1_wv_0       FN2_wv_0       FN1_wv_1       FN2_wv_1  \\\n",
       "count  138501.000000  138501.000000  138501.000000  138501.000000   \n",
       "mean       -1.149561      -1.142548       0.335170       0.984800   \n",
       "std         3.492488       3.323843       3.474877       3.337498   \n",
       "min       -14.552404     -14.552404     -15.155359     -15.155359   \n",
       "25%        -3.428356      -3.267654      -1.943416      -1.286454   \n",
       "50%        -0.849926      -1.173061       0.181308       1.185356   \n",
       "75%         0.880691       0.837845       2.884024       3.441082   \n",
       "max        13.809453      13.809453      13.278703      12.627606   \n",
       "\n",
       "            FN1_wv_2       FN2_wv_2       FN1_wv_3       FN2_wv_3  \\\n",
       "count  138501.000000  138501.000000  138501.000000  138501.000000   \n",
       "mean       -1.303121      -1.285600       0.969382       1.649082   \n",
       "std         3.092279       3.200081       3.298764       3.259781   \n",
       "min       -10.770514     -12.120364     -13.059869     -13.059869   \n",
       "25%        -3.024722      -3.490335      -0.700949      -0.314655   \n",
       "50%        -1.684384      -1.669534       1.110161       1.810379   \n",
       "75%         0.328431       0.566860       3.235934       3.917055   \n",
       "max        12.577226      13.612901      15.600971      15.600971   \n",
       "\n",
       "            FN1_wv_4       FN2_wv_4  ...      FN1_wv_95      FN2_wv_95  \\\n",
       "count  138501.000000  138501.000000  ...  138501.000000  138501.000000   \n",
       "mean        0.932246       0.639874  ...       0.852125       0.855012   \n",
       "std         3.352327       3.217403  ...       3.348929       3.137315   \n",
       "min       -19.813513     -19.813513  ...     -13.671687     -15.675972   \n",
       "25%        -0.800308      -1.321648  ...      -0.926266      -0.984259   \n",
       "50%         0.969153       0.752990  ...       0.866414       1.216405   \n",
       "75%         3.014434       2.652030  ...       2.981780       2.909477   \n",
       "max        12.603272      12.603272  ...      13.278911      13.278911   \n",
       "\n",
       "           FN1_wv_96      FN2_wv_96      FN1_wv_97      FN2_wv_97  \\\n",
       "count  138501.000000  138501.000000  138501.000000  138501.000000   \n",
       "mean       -0.818223      -1.027274       0.639393       0.495382   \n",
       "std         3.328003       3.158895       3.503989       3.088225   \n",
       "min       -11.840435     -13.274806     -10.960847     -10.634512   \n",
       "25%        -3.091983      -3.060984      -1.220916      -1.220916   \n",
       "50%        -0.612317      -1.291795       0.270797       0.459639   \n",
       "75%         1.220726       0.991717       2.560374       2.222106   \n",
       "max        17.067118      17.067118      15.014699      14.567921   \n",
       "\n",
       "           FN1_wv_98      FN2_wv_98      FN1_wv_99      FN2_wv_99  \n",
       "count  138501.000000  138501.000000  138501.000000  138501.000000  \n",
       "mean        0.975133       0.860273      -1.179080      -1.059375  \n",
       "std         2.894282       2.827303       3.368849       3.369553  \n",
       "min       -13.096807     -13.096807     -11.716203     -11.936399  \n",
       "25%        -0.894890      -1.018355      -3.538004      -3.236742  \n",
       "50%         0.671934       0.629546      -0.906662      -1.021606  \n",
       "75%         2.960142       2.960142       0.654513       0.882206  \n",
       "max        13.154280      13.154280      14.519915      14.381725  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 232
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "sampled_df[x_feature]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>FN2_wv_1</th>\n",
       "      <th>FN1_wv_2</th>\n",
       "      <th>FN2_wv_2</th>\n",
       "      <th>FN1_wv_3</th>\n",
       "      <th>FN2_wv_3</th>\n",
       "      <th>FN1_wv_4</th>\n",
       "      <th>FN2_wv_4</th>\n",
       "      <th>...</th>\n",
       "      <th>FN1_wv_95</th>\n",
       "      <th>FN2_wv_95</th>\n",
       "      <th>FN1_wv_96</th>\n",
       "      <th>FN2_wv_96</th>\n",
       "      <th>FN1_wv_97</th>\n",
       "      <th>FN2_wv_97</th>\n",
       "      <th>FN1_wv_98</th>\n",
       "      <th>FN2_wv_98</th>\n",
       "      <th>FN1_wv_99</th>\n",
       "      <th>FN2_wv_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.082778</td>\n",
       "      <td>-5.796417</td>\n",
       "      <td>4.782166</td>\n",
       "      <td>-0.217218</td>\n",
       "      <td>-3.571659</td>\n",
       "      <td>-5.335327</td>\n",
       "      <td>-8.585439</td>\n",
       "      <td>0.896868</td>\n",
       "      <td>6.623681</td>\n",
       "      <td>0.994031</td>\n",
       "      <td>...</td>\n",
       "      <td>0.497893</td>\n",
       "      <td>2.754097</td>\n",
       "      <td>-6.471545</td>\n",
       "      <td>0.587246</td>\n",
       "      <td>-5.607302</td>\n",
       "      <td>-2.159950</td>\n",
       "      <td>4.919923</td>\n",
       "      <td>0.551634</td>\n",
       "      <td>-4.087385</td>\n",
       "      <td>-2.308148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.442101</td>\n",
       "      <td>0.381964</td>\n",
       "      <td>1.215422</td>\n",
       "      <td>2.645488</td>\n",
       "      <td>-1.004735</td>\n",
       "      <td>-1.196166</td>\n",
       "      <td>0.030470</td>\n",
       "      <td>4.425450</td>\n",
       "      <td>0.634333</td>\n",
       "      <td>-0.119361</td>\n",
       "      <td>...</td>\n",
       "      <td>1.299436</td>\n",
       "      <td>-0.530058</td>\n",
       "      <td>0.151594</td>\n",
       "      <td>1.345441</td>\n",
       "      <td>-1.183616</td>\n",
       "      <td>0.623379</td>\n",
       "      <td>-0.605316</td>\n",
       "      <td>-0.215416</td>\n",
       "      <td>0.720008</td>\n",
       "      <td>5.855138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.596860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.960489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.759137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.892981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.062888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.683001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.143760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.756191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.617392</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.906404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.789320</td>\n",
       "      <td>-2.980340</td>\n",
       "      <td>-1.893114</td>\n",
       "      <td>0.727061</td>\n",
       "      <td>8.631498</td>\n",
       "      <td>2.532944</td>\n",
       "      <td>-1.192231</td>\n",
       "      <td>8.816960</td>\n",
       "      <td>0.861374</td>\n",
       "      <td>1.124468</td>\n",
       "      <td>...</td>\n",
       "      <td>3.327790</td>\n",
       "      <td>0.101130</td>\n",
       "      <td>1.703527</td>\n",
       "      <td>6.744654</td>\n",
       "      <td>-3.576160</td>\n",
       "      <td>2.269994</td>\n",
       "      <td>4.723351</td>\n",
       "      <td>4.592242</td>\n",
       "      <td>2.390387</td>\n",
       "      <td>-3.591447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.813373</td>\n",
       "      <td>-4.719679</td>\n",
       "      <td>-0.937114</td>\n",
       "      <td>2.741030</td>\n",
       "      <td>-2.302430</td>\n",
       "      <td>-1.445924</td>\n",
       "      <td>1.900387</td>\n",
       "      <td>-2.508925</td>\n",
       "      <td>4.940345</td>\n",
       "      <td>0.752990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926266</td>\n",
       "      <td>2.260610</td>\n",
       "      <td>5.119319</td>\n",
       "      <td>-0.142316</td>\n",
       "      <td>3.783037</td>\n",
       "      <td>-2.275315</td>\n",
       "      <td>1.980577</td>\n",
       "      <td>-1.235366</td>\n",
       "      <td>-2.943175</td>\n",
       "      <td>0.554239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138496</th>\n",
       "      <td>3.107082</td>\n",
       "      <td>1.373621</td>\n",
       "      <td>0.181308</td>\n",
       "      <td>7.103828</td>\n",
       "      <td>-1.789464</td>\n",
       "      <td>-1.372236</td>\n",
       "      <td>1.171252</td>\n",
       "      <td>-0.022872</td>\n",
       "      <td>1.328304</td>\n",
       "      <td>-3.410328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086999</td>\n",
       "      <td>6.691445</td>\n",
       "      <td>-0.047737</td>\n",
       "      <td>2.491465</td>\n",
       "      <td>-1.211868</td>\n",
       "      <td>-0.915223</td>\n",
       "      <td>1.569784</td>\n",
       "      <td>-1.038645</td>\n",
       "      <td>-4.228339</td>\n",
       "      <td>3.407803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138497</th>\n",
       "      <td>-0.024527</td>\n",
       "      <td>-0.138811</td>\n",
       "      <td>1.429394</td>\n",
       "      <td>3.504970</td>\n",
       "      <td>-5.721419</td>\n",
       "      <td>-0.308425</td>\n",
       "      <td>-1.453798</td>\n",
       "      <td>1.116156</td>\n",
       "      <td>4.826768</td>\n",
       "      <td>0.447931</td>\n",
       "      <td>...</td>\n",
       "      <td>6.056461</td>\n",
       "      <td>-1.345802</td>\n",
       "      <td>4.155251</td>\n",
       "      <td>1.048379</td>\n",
       "      <td>6.082980</td>\n",
       "      <td>-0.555668</td>\n",
       "      <td>-3.041093</td>\n",
       "      <td>1.900405</td>\n",
       "      <td>1.069293</td>\n",
       "      <td>0.627254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138498</th>\n",
       "      <td>4.559606</td>\n",
       "      <td>6.068225</td>\n",
       "      <td>2.725899</td>\n",
       "      <td>-2.063284</td>\n",
       "      <td>-2.807246</td>\n",
       "      <td>-0.077769</td>\n",
       "      <td>4.147959</td>\n",
       "      <td>1.140175</td>\n",
       "      <td>1.654552</td>\n",
       "      <td>-4.686434</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.934218</td>\n",
       "      <td>-7.699350</td>\n",
       "      <td>4.781729</td>\n",
       "      <td>-6.722366</td>\n",
       "      <td>3.168396</td>\n",
       "      <td>2.253842</td>\n",
       "      <td>3.530610</td>\n",
       "      <td>-1.759062</td>\n",
       "      <td>-1.181018</td>\n",
       "      <td>2.278829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138499</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.398280</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.651978</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.263631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.889518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.008286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.664589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.361263</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.832688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.729279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.815454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138500</th>\n",
       "      <td>2.650452</td>\n",
       "      <td>-1.726804</td>\n",
       "      <td>0.494862</td>\n",
       "      <td>2.413824</td>\n",
       "      <td>-6.060824</td>\n",
       "      <td>-1.227584</td>\n",
       "      <td>1.027903</td>\n",
       "      <td>2.121388</td>\n",
       "      <td>-3.974995</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>...</td>\n",
       "      <td>10.431598</td>\n",
       "      <td>3.715172</td>\n",
       "      <td>-4.926141</td>\n",
       "      <td>-1.650892</td>\n",
       "      <td>3.178382</td>\n",
       "      <td>0.114886</td>\n",
       "      <td>4.400489</td>\n",
       "      <td>-0.761678</td>\n",
       "      <td>-2.425627</td>\n",
       "      <td>0.667735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138501 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FN1_wv_0  FN2_wv_0  FN1_wv_1  FN2_wv_1  FN1_wv_2  FN2_wv_2  FN1_wv_3  \\\n",
       "0      -0.082778 -5.796417  4.782166 -0.217218 -3.571659 -5.335327 -8.585439   \n",
       "1      -1.442101  0.381964  1.215422  2.645488 -1.004735 -1.196166  0.030470   \n",
       "2       0.000000 -3.596860  0.000000 -5.960489  0.000000 -0.759137  0.000000   \n",
       "3       3.789320 -2.980340 -1.893114  0.727061  8.631498  2.532944 -1.192231   \n",
       "4       3.813373 -4.719679 -0.937114  2.741030 -2.302430 -1.445924  1.900387   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "138496  3.107082  1.373621  0.181308  7.103828 -1.789464 -1.372236  1.171252   \n",
       "138497 -0.024527 -0.138811  1.429394  3.504970 -5.721419 -0.308425 -1.453798   \n",
       "138498  4.559606  6.068225  2.725899 -2.063284 -2.807246 -0.077769  4.147959   \n",
       "138499  0.000000 -2.398280  0.000000  1.651978  0.000000 -1.263631  0.000000   \n",
       "138500  2.650452 -1.726804  0.494862  2.413824 -6.060824 -1.227584  1.027903   \n",
       "\n",
       "        FN2_wv_3  FN1_wv_4  FN2_wv_4  ...  FN1_wv_95  FN2_wv_95  FN1_wv_96  \\\n",
       "0       0.896868  6.623681  0.994031  ...   0.497893   2.754097  -6.471545   \n",
       "1       4.425450  0.634333 -0.119361  ...   1.299436  -0.530058   0.151594   \n",
       "2      -0.892981  0.000000 -1.062888  ...   0.000000   1.683001   0.000000   \n",
       "3       8.816960  0.861374  1.124468  ...   3.327790   0.101130   1.703527   \n",
       "4      -2.508925  4.940345  0.752990  ...  -0.926266   2.260610   5.119319   \n",
       "...          ...       ...       ...  ...        ...        ...        ...   \n",
       "138496 -0.022872  1.328304 -3.410328  ...   0.086999   6.691445  -0.047737   \n",
       "138497  1.116156  4.826768  0.447931  ...   6.056461  -1.345802   4.155251   \n",
       "138498  1.140175  1.654552 -4.686434  ...  -1.934218  -7.699350   4.781729   \n",
       "138499  3.889518  0.000000 -1.008286  ...   0.000000   4.664589   0.000000   \n",
       "138500  2.121388 -3.974995  0.571491  ...  10.431598   3.715172  -4.926141   \n",
       "\n",
       "        FN2_wv_96  FN1_wv_97  FN2_wv_97  FN1_wv_98  FN2_wv_98  FN1_wv_99  \\\n",
       "0        0.587246  -5.607302  -2.159950   4.919923   0.551634  -4.087385   \n",
       "1        1.345441  -1.183616   0.623379  -0.605316  -0.215416   0.720008   \n",
       "2        4.143760   0.000000   4.756191   0.000000  -3.617392   0.000000   \n",
       "3        6.744654  -3.576160   2.269994   4.723351   4.592242   2.390387   \n",
       "4       -0.142316   3.783037  -2.275315   1.980577  -1.235366  -2.943175   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "138496   2.491465  -1.211868  -0.915223   1.569784  -1.038645  -4.228339   \n",
       "138497   1.048379   6.082980  -0.555668  -3.041093   1.900405   1.069293   \n",
       "138498  -6.722366   3.168396   2.253842   3.530610  -1.759062  -1.181018   \n",
       "138499  -2.361263   0.000000   5.832688   0.000000   5.729279   0.000000   \n",
       "138500  -1.650892   3.178382   0.114886   4.400489  -0.761678  -2.425627   \n",
       "\n",
       "        FN2_wv_99  \n",
       "0       -2.308148  \n",
       "1        5.855138  \n",
       "2       -7.906404  \n",
       "3       -3.591447  \n",
       "4        0.554239  \n",
       "...           ...  \n",
       "138496   3.407803  \n",
       "138497   0.627254  \n",
       "138498   2.278829  \n",
       "138499  -0.815454  \n",
       "138500   0.667735  \n",
       "\n",
       "[138501 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sampled_df = w2v_normalize(sampled_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "sampled_df[x_feature]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>FN2_wv_1</th>\n",
       "      <th>FN1_wv_2</th>\n",
       "      <th>FN2_wv_2</th>\n",
       "      <th>FN1_wv_3</th>\n",
       "      <th>FN2_wv_3</th>\n",
       "      <th>FN1_wv_4</th>\n",
       "      <th>FN2_wv_4</th>\n",
       "      <th>...</th>\n",
       "      <th>FN1_wv_95</th>\n",
       "      <th>FN2_wv_95</th>\n",
       "      <th>FN1_wv_96</th>\n",
       "      <th>FN2_wv_96</th>\n",
       "      <th>FN1_wv_97</th>\n",
       "      <th>FN2_wv_97</th>\n",
       "      <th>FN1_wv_98</th>\n",
       "      <th>FN2_wv_98</th>\n",
       "      <th>FN1_wv_99</th>\n",
       "      <th>FN2_wv_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.305452</td>\n",
       "      <td>-1.400152</td>\n",
       "      <td>1.279761</td>\n",
       "      <td>-0.360157</td>\n",
       "      <td>-0.733616</td>\n",
       "      <td>-1.265512</td>\n",
       "      <td>-2.896495</td>\n",
       "      <td>-0.230757</td>\n",
       "      <td>1.697763</td>\n",
       "      <td>0.110076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.105775</td>\n",
       "      <td>0.605324</td>\n",
       "      <td>-1.698719</td>\n",
       "      <td>0.511105</td>\n",
       "      <td>-1.782745</td>\n",
       "      <td>-0.859828</td>\n",
       "      <td>1.362965</td>\n",
       "      <td>-0.109164</td>\n",
       "      <td>-0.863296</td>\n",
       "      <td>-0.370606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.083763</td>\n",
       "      <td>0.458661</td>\n",
       "      <td>0.253320</td>\n",
       "      <td>0.497587</td>\n",
       "      <td>0.096494</td>\n",
       "      <td>0.027948</td>\n",
       "      <td>-0.284626</td>\n",
       "      <td>0.851707</td>\n",
       "      <td>-0.088868</td>\n",
       "      <td>-0.235978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133569</td>\n",
       "      <td>-0.441484</td>\n",
       "      <td>0.291412</td>\n",
       "      <td>0.751125</td>\n",
       "      <td>-0.520268</td>\n",
       "      <td>0.041447</td>\n",
       "      <td>-0.546061</td>\n",
       "      <td>-0.380466</td>\n",
       "      <td>0.563722</td>\n",
       "      <td>2.052064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329154</td>\n",
       "      <td>-0.738399</td>\n",
       "      <td>-0.096455</td>\n",
       "      <td>-2.080995</td>\n",
       "      <td>0.421413</td>\n",
       "      <td>0.164516</td>\n",
       "      <td>-0.293863</td>\n",
       "      <td>-0.779829</td>\n",
       "      <td>-0.278090</td>\n",
       "      <td>-0.529237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254448</td>\n",
       "      <td>0.263917</td>\n",
       "      <td>0.245861</td>\n",
       "      <td>1.636982</td>\n",
       "      <td>-0.182476</td>\n",
       "      <td>1.379700</td>\n",
       "      <td>-0.336918</td>\n",
       "      <td>-1.583729</td>\n",
       "      <td>0.349996</td>\n",
       "      <td>-2.032036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.414149</td>\n",
       "      <td>-0.552914</td>\n",
       "      <td>-0.641258</td>\n",
       "      <td>-0.077225</td>\n",
       "      <td>3.212729</td>\n",
       "      <td>1.193269</td>\n",
       "      <td>-0.655282</td>\n",
       "      <td>2.198891</td>\n",
       "      <td>-0.021141</td>\n",
       "      <td>0.150617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739243</td>\n",
       "      <td>-0.240296</td>\n",
       "      <td>0.757739</td>\n",
       "      <td>2.460340</td>\n",
       "      <td>-1.203077</td>\n",
       "      <td>0.574640</td>\n",
       "      <td>1.295047</td>\n",
       "      <td>1.319980</td>\n",
       "      <td>1.059555</td>\n",
       "      <td>-0.751459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.421036</td>\n",
       "      <td>-1.076207</td>\n",
       "      <td>-0.366139</td>\n",
       "      <td>0.526214</td>\n",
       "      <td>-0.323164</td>\n",
       "      <td>-0.050100</td>\n",
       "      <td>0.282229</td>\n",
       "      <td>-1.275553</td>\n",
       "      <td>1.195621</td>\n",
       "      <td>0.035158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.531035</td>\n",
       "      <td>0.448027</td>\n",
       "      <td>1.784122</td>\n",
       "      <td>0.280149</td>\n",
       "      <td>0.897165</td>\n",
       "      <td>-0.897184</td>\n",
       "      <td>0.347391</td>\n",
       "      <td>-0.741218</td>\n",
       "      <td>-0.523651</td>\n",
       "      <td>0.478883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138496</th>\n",
       "      <td>1.218804</td>\n",
       "      <td>0.757008</td>\n",
       "      <td>-0.044278</td>\n",
       "      <td>1.833425</td>\n",
       "      <td>-0.157277</td>\n",
       "      <td>-0.027073</td>\n",
       "      <td>0.061196</td>\n",
       "      <td>-0.512906</td>\n",
       "      <td>0.118145</td>\n",
       "      <td>-1.258847</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228470</td>\n",
       "      <td>1.860334</td>\n",
       "      <td>0.231517</td>\n",
       "      <td>1.113919</td>\n",
       "      <td>-0.528331</td>\n",
       "      <td>-0.456770</td>\n",
       "      <td>0.205458</td>\n",
       "      <td>-0.671639</td>\n",
       "      <td>-0.905137</td>\n",
       "      <td>1.325753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138497</th>\n",
       "      <td>0.322131</td>\n",
       "      <td>0.301982</td>\n",
       "      <td>0.314897</td>\n",
       "      <td>0.755110</td>\n",
       "      <td>-1.428821</td>\n",
       "      <td>0.305360</td>\n",
       "      <td>-0.734575</td>\n",
       "      <td>-0.163486</td>\n",
       "      <td>1.161741</td>\n",
       "      <td>-0.059658</td>\n",
       "      <td>...</td>\n",
       "      <td>1.554035</td>\n",
       "      <td>-0.701499</td>\n",
       "      <td>1.494437</td>\n",
       "      <td>0.657084</td>\n",
       "      <td>1.553546</td>\n",
       "      <td>-0.340342</td>\n",
       "      <td>-1.387646</td>\n",
       "      <td>0.367890</td>\n",
       "      <td>0.667403</td>\n",
       "      <td>0.500552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138498</th>\n",
       "      <td>1.634705</td>\n",
       "      <td>2.169416</td>\n",
       "      <td>0.688006</td>\n",
       "      <td>-0.913288</td>\n",
       "      <td>-0.486415</td>\n",
       "      <td>0.377439</td>\n",
       "      <td>0.963569</td>\n",
       "      <td>-0.156118</td>\n",
       "      <td>0.215465</td>\n",
       "      <td>-1.655474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832013</td>\n",
       "      <td>-2.726661</td>\n",
       "      <td>1.682683</td>\n",
       "      <td>-1.802881</td>\n",
       "      <td>0.721753</td>\n",
       "      <td>0.569410</td>\n",
       "      <td>0.882943</td>\n",
       "      <td>-0.926446</td>\n",
       "      <td>-0.000575</td>\n",
       "      <td>0.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138499</th>\n",
       "      <td>0.329154</td>\n",
       "      <td>-0.377797</td>\n",
       "      <td>-0.096455</td>\n",
       "      <td>0.199904</td>\n",
       "      <td>0.421413</td>\n",
       "      <td>0.006865</td>\n",
       "      <td>-0.293863</td>\n",
       "      <td>0.687299</td>\n",
       "      <td>-0.278090</td>\n",
       "      <td>-0.512266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254448</td>\n",
       "      <td>1.214284</td>\n",
       "      <td>0.245861</td>\n",
       "      <td>-0.422298</td>\n",
       "      <td>-0.182476</td>\n",
       "      <td>1.728283</td>\n",
       "      <td>-0.336918</td>\n",
       "      <td>1.722144</td>\n",
       "      <td>0.349996</td>\n",
       "      <td>0.072390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138500</th>\n",
       "      <td>1.088057</td>\n",
       "      <td>-0.175778</td>\n",
       "      <td>0.045956</td>\n",
       "      <td>0.428174</td>\n",
       "      <td>-1.538580</td>\n",
       "      <td>0.018129</td>\n",
       "      <td>0.017740</td>\n",
       "      <td>0.144889</td>\n",
       "      <td>-1.463837</td>\n",
       "      <td>-0.021254</td>\n",
       "      <td>...</td>\n",
       "      <td>2.860469</td>\n",
       "      <td>0.911662</td>\n",
       "      <td>-1.234354</td>\n",
       "      <td>-0.197417</td>\n",
       "      <td>0.724602</td>\n",
       "      <td>-0.123209</td>\n",
       "      <td>1.183495</td>\n",
       "      <td>-0.573677</td>\n",
       "      <td>-0.370023</td>\n",
       "      <td>0.512565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138501 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        FN1_wv_0  FN2_wv_0  FN1_wv_1  FN2_wv_1  FN1_wv_2  FN2_wv_2  FN1_wv_3  \\\n",
       "0       0.305452 -1.400152  1.279761 -0.360157 -0.733616 -1.265512 -2.896495   \n",
       "1      -0.083763  0.458661  0.253320  0.497587  0.096494  0.027948 -0.284626   \n",
       "2       0.329154 -0.738399 -0.096455 -2.080995  0.421413  0.164516 -0.293863   \n",
       "3       1.414149 -0.552914 -0.641258 -0.077225  3.212729  1.193269 -0.655282   \n",
       "4       1.421036 -1.076207 -0.366139  0.526214 -0.323164 -0.050100  0.282229   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "138496  1.218804  0.757008 -0.044278  1.833425 -0.157277 -0.027073  0.061196   \n",
       "138497  0.322131  0.301982  0.314897  0.755110 -1.428821  0.305360 -0.734575   \n",
       "138498  1.634705  2.169416  0.688006 -0.913288 -0.486415  0.377439  0.963569   \n",
       "138499  0.329154 -0.377797 -0.096455  0.199904  0.421413  0.006865 -0.293863   \n",
       "138500  1.088057 -0.175778  0.045956  0.428174 -1.538580  0.018129  0.017740   \n",
       "\n",
       "        FN2_wv_3  FN1_wv_4  FN2_wv_4  ...  FN1_wv_95  FN2_wv_95  FN1_wv_96  \\\n",
       "0      -0.230757  1.697763  0.110076  ...  -0.105775   0.605324  -1.698719   \n",
       "1       0.851707 -0.088868 -0.235978  ...   0.133569  -0.441484   0.291412   \n",
       "2      -0.779829 -0.278090 -0.529237  ...  -0.254448   0.263917   0.245861   \n",
       "3       2.198891 -0.021141  0.150617  ...   0.739243  -0.240296   0.757739   \n",
       "4      -1.275553  1.195621  0.035158  ...  -0.531035   0.448027   1.784122   \n",
       "...          ...       ...       ...  ...        ...        ...        ...   \n",
       "138496 -0.512906  0.118145 -1.258847  ...  -0.228470   1.860334   0.231517   \n",
       "138497 -0.163486  1.161741 -0.059658  ...   1.554035  -0.701499   1.494437   \n",
       "138498 -0.156118  0.215465 -1.655474  ...  -0.832013  -2.726661   1.682683   \n",
       "138499  0.687299 -0.278090 -0.512266  ...  -0.254448   1.214284   0.245861   \n",
       "138500  0.144889 -1.463837 -0.021254  ...   2.860469   0.911662  -1.234354   \n",
       "\n",
       "        FN2_wv_96  FN1_wv_97  FN2_wv_97  FN1_wv_98  FN2_wv_98  FN1_wv_99  \\\n",
       "0        0.511105  -1.782745  -0.859828   1.362965  -0.109164  -0.863296   \n",
       "1        0.751125  -0.520268   0.041447  -0.546061  -0.380466   0.563722   \n",
       "2        1.636982  -0.182476   1.379700  -0.336918  -1.583729   0.349996   \n",
       "3        2.460340  -1.203077   0.574640   1.295047   1.319980   1.059555   \n",
       "4        0.280149   0.897165  -0.897184   0.347391  -0.741218  -0.523651   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "138496   1.113919  -0.528331  -0.456770   0.205458  -0.671639  -0.905137   \n",
       "138497   0.657084   1.553546  -0.340342  -1.387646   0.367890   0.667403   \n",
       "138498  -1.802881   0.721753   0.569410   0.882943  -0.926446  -0.000575   \n",
       "138499  -0.422298  -0.182476   1.728283  -0.336918   1.722144   0.349996   \n",
       "138500  -0.197417   0.724602  -0.123209   1.183495  -0.573677  -0.370023   \n",
       "\n",
       "        FN2_wv_99  \n",
       "0       -0.370606  \n",
       "1        2.052064  \n",
       "2       -2.032036  \n",
       "3       -0.751459  \n",
       "4        0.478883  \n",
       "...           ...  \n",
       "138496   1.325753  \n",
       "138497   0.500552  \n",
       "138498   0.990700  \n",
       "138499   0.072390  \n",
       "138500   0.512565  \n",
       "\n",
       "[138501 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "pd.options.display.float_format = '{:,.4f}'.format"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "#已normalized\r\n",
    "sampled_df[ x_feature ].describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>FN2_wv_1</th>\n",
       "      <th>FN1_wv_2</th>\n",
       "      <th>FN2_wv_2</th>\n",
       "      <th>FN1_wv_3</th>\n",
       "      <th>FN2_wv_3</th>\n",
       "      <th>FN1_wv_4</th>\n",
       "      <th>FN2_wv_4</th>\n",
       "      <th>...</th>\n",
       "      <th>FN1_wv_95</th>\n",
       "      <th>FN2_wv_95</th>\n",
       "      <th>FN1_wv_96</th>\n",
       "      <th>FN2_wv_96</th>\n",
       "      <th>FN1_wv_97</th>\n",
       "      <th>FN2_wv_97</th>\n",
       "      <th>FN1_wv_98</th>\n",
       "      <th>FN2_wv_98</th>\n",
       "      <th>FN1_wv_99</th>\n",
       "      <th>FN2_wv_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "      <td>138,501.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.8376</td>\n",
       "      <td>-4.0345</td>\n",
       "      <td>-4.4579</td>\n",
       "      <td>-4.8360</td>\n",
       "      <td>-3.0616</td>\n",
       "      <td>-3.3858</td>\n",
       "      <td>-4.2529</td>\n",
       "      <td>-4.5123</td>\n",
       "      <td>-6.1885</td>\n",
       "      <td>-6.3571</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.3369</td>\n",
       "      <td>-5.2692</td>\n",
       "      <td>-3.3120</td>\n",
       "      <td>-3.8772</td>\n",
       "      <td>-3.3106</td>\n",
       "      <td>-3.6040</td>\n",
       "      <td>-4.8620</td>\n",
       "      <td>-4.9366</td>\n",
       "      <td>-3.1278</td>\n",
       "      <td>-3.2280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.6525</td>\n",
       "      <td>-0.6394</td>\n",
       "      <td>-0.6557</td>\n",
       "      <td>-0.6805</td>\n",
       "      <td>-0.5567</td>\n",
       "      <td>-0.6890</td>\n",
       "      <td>-0.5064</td>\n",
       "      <td>-0.6024</td>\n",
       "      <td>-0.5168</td>\n",
       "      <td>-0.6097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.5310</td>\n",
       "      <td>-0.5863</td>\n",
       "      <td>-0.6832</td>\n",
       "      <td>-0.6438</td>\n",
       "      <td>-0.5309</td>\n",
       "      <td>-0.5558</td>\n",
       "      <td>-0.6461</td>\n",
       "      <td>-0.6645</td>\n",
       "      <td>-0.7002</td>\n",
       "      <td>-0.6462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0858</td>\n",
       "      <td>-0.0092</td>\n",
       "      <td>-0.0443</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>-0.1233</td>\n",
       "      <td>-0.1200</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.1152</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>-0.0837</td>\n",
       "      <td>-0.1052</td>\n",
       "      <td>-0.0116</td>\n",
       "      <td>-0.1048</td>\n",
       "      <td>-0.0816</td>\n",
       "      <td>0.0809</td>\n",
       "      <td>0.0112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.5813</td>\n",
       "      <td>0.5958</td>\n",
       "      <td>0.7335</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>0.5276</td>\n",
       "      <td>0.5789</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>0.6211</td>\n",
       "      <td>0.6254</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6359</td>\n",
       "      <td>0.6549</td>\n",
       "      <td>0.6127</td>\n",
       "      <td>0.6391</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.6858</td>\n",
       "      <td>0.7427</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>0.5762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.2832</td>\n",
       "      <td>4.4984</td>\n",
       "      <td>3.7249</td>\n",
       "      <td>3.4885</td>\n",
       "      <td>4.4887</td>\n",
       "      <td>4.6557</td>\n",
       "      <td>4.4355</td>\n",
       "      <td>4.2800</td>\n",
       "      <td>3.4815</td>\n",
       "      <td>3.7184</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7107</td>\n",
       "      <td>3.9601</td>\n",
       "      <td>5.3742</td>\n",
       "      <td>5.7281</td>\n",
       "      <td>4.1026</td>\n",
       "      <td>4.5569</td>\n",
       "      <td>4.2080</td>\n",
       "      <td>4.3483</td>\n",
       "      <td>4.6601</td>\n",
       "      <td>4.5826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          FN1_wv_0     FN2_wv_0     FN1_wv_1     FN2_wv_1     FN1_wv_2  \\\n",
       "count 138,501.0000 138,501.0000 138,501.0000 138,501.0000 138,501.0000   \n",
       "mean       -0.0000      -0.0000      -0.0000      -0.0000       0.0000   \n",
       "std         1.0000       1.0000       1.0000       1.0000       1.0000   \n",
       "min        -3.8376      -4.0345      -4.4579      -4.8360      -3.0616   \n",
       "25%        -0.6525      -0.6394      -0.6557      -0.6805      -0.5567   \n",
       "50%         0.0858      -0.0092      -0.0443       0.0601      -0.1233   \n",
       "75%         0.5813       0.5958       0.7335       0.7360       0.5276   \n",
       "max         4.2832       4.4984       3.7249       3.4885       4.4887   \n",
       "\n",
       "          FN2_wv_2     FN1_wv_3     FN2_wv_3     FN1_wv_4     FN2_wv_4  ...  \\\n",
       "count 138,501.0000 138,501.0000 138,501.0000 138,501.0000 138,501.0000  ...   \n",
       "mean       -0.0000      -0.0000       0.0000      -0.0000       0.0000  ...   \n",
       "std         1.0000       1.0000       1.0000       1.0000       1.0000  ...   \n",
       "min        -3.3858      -4.2529      -4.5123      -6.1885      -6.3571  ...   \n",
       "25%        -0.6890      -0.5064      -0.6024      -0.5168      -0.6097  ...   \n",
       "50%        -0.1200       0.0427       0.0495       0.0110       0.0352  ...   \n",
       "75%         0.5789       0.6871       0.6957       0.6211       0.6254  ...   \n",
       "max         4.6557       4.4355       4.2800       3.4815       3.7184  ...   \n",
       "\n",
       "         FN1_wv_95    FN2_wv_95    FN1_wv_96    FN2_wv_96    FN1_wv_97  \\\n",
       "count 138,501.0000 138,501.0000 138,501.0000 138,501.0000 138,501.0000   \n",
       "mean        0.0000       0.0000       0.0000      -0.0000       0.0000   \n",
       "std         1.0000       1.0000       1.0000       1.0000       1.0000   \n",
       "min        -4.3369      -5.2692      -3.3120      -3.8772      -3.3106   \n",
       "25%        -0.5310      -0.5863      -0.6832      -0.6438      -0.5309   \n",
       "50%         0.0043       0.1152       0.0619      -0.0837      -0.1052   \n",
       "75%         0.6359       0.6549       0.6127       0.6391       0.5482   \n",
       "max         3.7107       3.9601       5.3742       5.7281       4.1026   \n",
       "\n",
       "         FN2_wv_97    FN1_wv_98    FN2_wv_98    FN1_wv_99    FN2_wv_99  \n",
       "count 138,501.0000 138,501.0000 138,501.0000 138,501.0000 138,501.0000  \n",
       "mean       -0.0000      -0.0000       0.0000       0.0000      -0.0000  \n",
       "std         1.0000       1.0000       1.0000       1.0000       1.0000  \n",
       "min        -3.6040      -4.8620      -4.9366      -3.1278      -3.2280  \n",
       "25%        -0.5558      -0.6461      -0.6645      -0.7002      -0.6462  \n",
       "50%        -0.0116      -0.1048      -0.0816       0.0809       0.0112  \n",
       "75%         0.5591       0.6858       0.7427       0.5443       0.5762  \n",
       "max         4.5569       4.2080       4.3483       4.6601       4.5826  \n",
       "\n",
       "[8 rows x 200 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "sampled_df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>message</th>\n",
       "      <th>userID</th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Zodiac_猴</th>\n",
       "      <th>Zodiac_羊</th>\n",
       "      <th>Zodiac_虎</th>\n",
       "      <th>Zodiac_蛇</th>\n",
       "      <th>Zodiac_豬</th>\n",
       "      <th>Zodiac_雞</th>\n",
       "      <th>Zodiac_馬</th>\n",
       "      <th>Zodiac_鼠</th>\n",
       "      <th>Zodiac_龍</th>\n",
       "      <th>mgender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>丁承先</td>\n",
       "      <td>0</td>\n",
       "      <td>承先</td>\n",
       "      <td>丁</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3055</td>\n",
       "      <td>-1.4002</td>\n",
       "      <td>1.2798</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>丁昞原</td>\n",
       "      <td>0</td>\n",
       "      <td>昞原</td>\n",
       "      <td>丁</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0838</td>\n",
       "      <td>0.4587</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>方超</td>\n",
       "      <td>0</td>\n",
       "      <td>超</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>-0.7384</td>\n",
       "      <td>-0.0965</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>方九龍</td>\n",
       "      <td>0</td>\n",
       "      <td>九龍</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4141</td>\n",
       "      <td>-0.5529</td>\n",
       "      <td>-0.6413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>方大錚</td>\n",
       "      <td>0</td>\n",
       "      <td>大錚</td>\n",
       "      <td>方</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4210</td>\n",
       "      <td>-1.0762</td>\n",
       "      <td>-0.3661</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  name  BirthYear FirstName LastName  gender  message userID  FN1_wv_0  \\\n",
       "0  丁承先          0        承先        丁       1     1940    NaN    0.3055   \n",
       "1  丁昞原          0        昞原        丁       1     1940    NaN   -0.0838   \n",
       "2   方超          0         超        方       1     1940    NaN    0.3292   \n",
       "3  方九龍          0        九龍        方       1     1940    NaN    1.4141   \n",
       "4  方大錚          0        大錚        方       1     1940    NaN    1.4210   \n",
       "\n",
       "   FN2_wv_0  FN1_wv_1  ...  Zodiac_猴  Zodiac_羊  Zodiac_虎  Zodiac_蛇  Zodiac_豬  \\\n",
       "0   -1.4002    1.2798  ...         0         0         0         0         0   \n",
       "1    0.4587    0.2533  ...         0         0         0         0         0   \n",
       "2   -0.7384   -0.0965  ...         0         0         0         0         0   \n",
       "3   -0.5529   -0.6413  ...         0         0         0         0         0   \n",
       "4   -1.0762   -0.3661  ...         0         0         0         0         0   \n",
       "\n",
       "   Zodiac_雞  Zodiac_馬  Zodiac_鼠  Zodiac_龍  mgender  \n",
       "0         0         0         0         1        1  \n",
       "1         0         0         0         1        1  \n",
       "2         0         0         0         1        1  \n",
       "3         0         0         0         1        1  \n",
       "4         0         0         0         1        1  \n",
       "\n",
       "[5 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "rename_dic = {}\r\n",
    "for col in (sampled_df.columns):\r\n",
    "    if \"FN1\" in col:\r\n",
    "        rename_dic[col] = col.replace(\"FN1\",\"FN2\")\r\n",
    "    elif  \"FN2\" in col:\r\n",
    "        rename_dic[col] = col.replace(\"FN2\",\"FN1\")\r\n",
    "rename_dic"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'FN1_wv_0': 'FN2_wv_0',\n",
       " 'FN2_wv_0': 'FN1_wv_0',\n",
       " 'FN1_wv_1': 'FN2_wv_1',\n",
       " 'FN2_wv_1': 'FN1_wv_1',\n",
       " 'FN1_wv_2': 'FN2_wv_2',\n",
       " 'FN2_wv_2': 'FN1_wv_2',\n",
       " 'FN1_wv_3': 'FN2_wv_3',\n",
       " 'FN2_wv_3': 'FN1_wv_3',\n",
       " 'FN1_wv_4': 'FN2_wv_4',\n",
       " 'FN2_wv_4': 'FN1_wv_4',\n",
       " 'FN1_wv_5': 'FN2_wv_5',\n",
       " 'FN2_wv_5': 'FN1_wv_5',\n",
       " 'FN1_wv_6': 'FN2_wv_6',\n",
       " 'FN2_wv_6': 'FN1_wv_6',\n",
       " 'FN1_wv_7': 'FN2_wv_7',\n",
       " 'FN2_wv_7': 'FN1_wv_7',\n",
       " 'FN1_wv_8': 'FN2_wv_8',\n",
       " 'FN2_wv_8': 'FN1_wv_8',\n",
       " 'FN1_wv_9': 'FN2_wv_9',\n",
       " 'FN2_wv_9': 'FN1_wv_9',\n",
       " 'FN1_wv_10': 'FN2_wv_10',\n",
       " 'FN2_wv_10': 'FN1_wv_10',\n",
       " 'FN1_wv_11': 'FN2_wv_11',\n",
       " 'FN2_wv_11': 'FN1_wv_11',\n",
       " 'FN1_wv_12': 'FN2_wv_12',\n",
       " 'FN2_wv_12': 'FN1_wv_12',\n",
       " 'FN1_wv_13': 'FN2_wv_13',\n",
       " 'FN2_wv_13': 'FN1_wv_13',\n",
       " 'FN1_wv_14': 'FN2_wv_14',\n",
       " 'FN2_wv_14': 'FN1_wv_14',\n",
       " 'FN1_wv_15': 'FN2_wv_15',\n",
       " 'FN2_wv_15': 'FN1_wv_15',\n",
       " 'FN1_wv_16': 'FN2_wv_16',\n",
       " 'FN2_wv_16': 'FN1_wv_16',\n",
       " 'FN1_wv_17': 'FN2_wv_17',\n",
       " 'FN2_wv_17': 'FN1_wv_17',\n",
       " 'FN1_wv_18': 'FN2_wv_18',\n",
       " 'FN2_wv_18': 'FN1_wv_18',\n",
       " 'FN1_wv_19': 'FN2_wv_19',\n",
       " 'FN2_wv_19': 'FN1_wv_19',\n",
       " 'FN1_wv_20': 'FN2_wv_20',\n",
       " 'FN2_wv_20': 'FN1_wv_20',\n",
       " 'FN1_wv_21': 'FN2_wv_21',\n",
       " 'FN2_wv_21': 'FN1_wv_21',\n",
       " 'FN1_wv_22': 'FN2_wv_22',\n",
       " 'FN2_wv_22': 'FN1_wv_22',\n",
       " 'FN1_wv_23': 'FN2_wv_23',\n",
       " 'FN2_wv_23': 'FN1_wv_23',\n",
       " 'FN1_wv_24': 'FN2_wv_24',\n",
       " 'FN2_wv_24': 'FN1_wv_24',\n",
       " 'FN1_wv_25': 'FN2_wv_25',\n",
       " 'FN2_wv_25': 'FN1_wv_25',\n",
       " 'FN1_wv_26': 'FN2_wv_26',\n",
       " 'FN2_wv_26': 'FN1_wv_26',\n",
       " 'FN1_wv_27': 'FN2_wv_27',\n",
       " 'FN2_wv_27': 'FN1_wv_27',\n",
       " 'FN1_wv_28': 'FN2_wv_28',\n",
       " 'FN2_wv_28': 'FN1_wv_28',\n",
       " 'FN1_wv_29': 'FN2_wv_29',\n",
       " 'FN2_wv_29': 'FN1_wv_29',\n",
       " 'FN1_wv_30': 'FN2_wv_30',\n",
       " 'FN2_wv_30': 'FN1_wv_30',\n",
       " 'FN1_wv_31': 'FN2_wv_31',\n",
       " 'FN2_wv_31': 'FN1_wv_31',\n",
       " 'FN1_wv_32': 'FN2_wv_32',\n",
       " 'FN2_wv_32': 'FN1_wv_32',\n",
       " 'FN1_wv_33': 'FN2_wv_33',\n",
       " 'FN2_wv_33': 'FN1_wv_33',\n",
       " 'FN1_wv_34': 'FN2_wv_34',\n",
       " 'FN2_wv_34': 'FN1_wv_34',\n",
       " 'FN1_wv_35': 'FN2_wv_35',\n",
       " 'FN2_wv_35': 'FN1_wv_35',\n",
       " 'FN1_wv_36': 'FN2_wv_36',\n",
       " 'FN2_wv_36': 'FN1_wv_36',\n",
       " 'FN1_wv_37': 'FN2_wv_37',\n",
       " 'FN2_wv_37': 'FN1_wv_37',\n",
       " 'FN1_wv_38': 'FN2_wv_38',\n",
       " 'FN2_wv_38': 'FN1_wv_38',\n",
       " 'FN1_wv_39': 'FN2_wv_39',\n",
       " 'FN2_wv_39': 'FN1_wv_39',\n",
       " 'FN1_wv_40': 'FN2_wv_40',\n",
       " 'FN2_wv_40': 'FN1_wv_40',\n",
       " 'FN1_wv_41': 'FN2_wv_41',\n",
       " 'FN2_wv_41': 'FN1_wv_41',\n",
       " 'FN1_wv_42': 'FN2_wv_42',\n",
       " 'FN2_wv_42': 'FN1_wv_42',\n",
       " 'FN1_wv_43': 'FN2_wv_43',\n",
       " 'FN2_wv_43': 'FN1_wv_43',\n",
       " 'FN1_wv_44': 'FN2_wv_44',\n",
       " 'FN2_wv_44': 'FN1_wv_44',\n",
       " 'FN1_wv_45': 'FN2_wv_45',\n",
       " 'FN2_wv_45': 'FN1_wv_45',\n",
       " 'FN1_wv_46': 'FN2_wv_46',\n",
       " 'FN2_wv_46': 'FN1_wv_46',\n",
       " 'FN1_wv_47': 'FN2_wv_47',\n",
       " 'FN2_wv_47': 'FN1_wv_47',\n",
       " 'FN1_wv_48': 'FN2_wv_48',\n",
       " 'FN2_wv_48': 'FN1_wv_48',\n",
       " 'FN1_wv_49': 'FN2_wv_49',\n",
       " 'FN2_wv_49': 'FN1_wv_49',\n",
       " 'FN1_wv_50': 'FN2_wv_50',\n",
       " 'FN2_wv_50': 'FN1_wv_50',\n",
       " 'FN1_wv_51': 'FN2_wv_51',\n",
       " 'FN2_wv_51': 'FN1_wv_51',\n",
       " 'FN1_wv_52': 'FN2_wv_52',\n",
       " 'FN2_wv_52': 'FN1_wv_52',\n",
       " 'FN1_wv_53': 'FN2_wv_53',\n",
       " 'FN2_wv_53': 'FN1_wv_53',\n",
       " 'FN1_wv_54': 'FN2_wv_54',\n",
       " 'FN2_wv_54': 'FN1_wv_54',\n",
       " 'FN1_wv_55': 'FN2_wv_55',\n",
       " 'FN2_wv_55': 'FN1_wv_55',\n",
       " 'FN1_wv_56': 'FN2_wv_56',\n",
       " 'FN2_wv_56': 'FN1_wv_56',\n",
       " 'FN1_wv_57': 'FN2_wv_57',\n",
       " 'FN2_wv_57': 'FN1_wv_57',\n",
       " 'FN1_wv_58': 'FN2_wv_58',\n",
       " 'FN2_wv_58': 'FN1_wv_58',\n",
       " 'FN1_wv_59': 'FN2_wv_59',\n",
       " 'FN2_wv_59': 'FN1_wv_59',\n",
       " 'FN1_wv_60': 'FN2_wv_60',\n",
       " 'FN2_wv_60': 'FN1_wv_60',\n",
       " 'FN1_wv_61': 'FN2_wv_61',\n",
       " 'FN2_wv_61': 'FN1_wv_61',\n",
       " 'FN1_wv_62': 'FN2_wv_62',\n",
       " 'FN2_wv_62': 'FN1_wv_62',\n",
       " 'FN1_wv_63': 'FN2_wv_63',\n",
       " 'FN2_wv_63': 'FN1_wv_63',\n",
       " 'FN1_wv_64': 'FN2_wv_64',\n",
       " 'FN2_wv_64': 'FN1_wv_64',\n",
       " 'FN1_wv_65': 'FN2_wv_65',\n",
       " 'FN2_wv_65': 'FN1_wv_65',\n",
       " 'FN1_wv_66': 'FN2_wv_66',\n",
       " 'FN2_wv_66': 'FN1_wv_66',\n",
       " 'FN1_wv_67': 'FN2_wv_67',\n",
       " 'FN2_wv_67': 'FN1_wv_67',\n",
       " 'FN1_wv_68': 'FN2_wv_68',\n",
       " 'FN2_wv_68': 'FN1_wv_68',\n",
       " 'FN1_wv_69': 'FN2_wv_69',\n",
       " 'FN2_wv_69': 'FN1_wv_69',\n",
       " 'FN1_wv_70': 'FN2_wv_70',\n",
       " 'FN2_wv_70': 'FN1_wv_70',\n",
       " 'FN1_wv_71': 'FN2_wv_71',\n",
       " 'FN2_wv_71': 'FN1_wv_71',\n",
       " 'FN1_wv_72': 'FN2_wv_72',\n",
       " 'FN2_wv_72': 'FN1_wv_72',\n",
       " 'FN1_wv_73': 'FN2_wv_73',\n",
       " 'FN2_wv_73': 'FN1_wv_73',\n",
       " 'FN1_wv_74': 'FN2_wv_74',\n",
       " 'FN2_wv_74': 'FN1_wv_74',\n",
       " 'FN1_wv_75': 'FN2_wv_75',\n",
       " 'FN2_wv_75': 'FN1_wv_75',\n",
       " 'FN1_wv_76': 'FN2_wv_76',\n",
       " 'FN2_wv_76': 'FN1_wv_76',\n",
       " 'FN1_wv_77': 'FN2_wv_77',\n",
       " 'FN2_wv_77': 'FN1_wv_77',\n",
       " 'FN1_wv_78': 'FN2_wv_78',\n",
       " 'FN2_wv_78': 'FN1_wv_78',\n",
       " 'FN1_wv_79': 'FN2_wv_79',\n",
       " 'FN2_wv_79': 'FN1_wv_79',\n",
       " 'FN1_wv_80': 'FN2_wv_80',\n",
       " 'FN2_wv_80': 'FN1_wv_80',\n",
       " 'FN1_wv_81': 'FN2_wv_81',\n",
       " 'FN2_wv_81': 'FN1_wv_81',\n",
       " 'FN1_wv_82': 'FN2_wv_82',\n",
       " 'FN2_wv_82': 'FN1_wv_82',\n",
       " 'FN1_wv_83': 'FN2_wv_83',\n",
       " 'FN2_wv_83': 'FN1_wv_83',\n",
       " 'FN1_wv_84': 'FN2_wv_84',\n",
       " 'FN2_wv_84': 'FN1_wv_84',\n",
       " 'FN1_wv_85': 'FN2_wv_85',\n",
       " 'FN2_wv_85': 'FN1_wv_85',\n",
       " 'FN1_wv_86': 'FN2_wv_86',\n",
       " 'FN2_wv_86': 'FN1_wv_86',\n",
       " 'FN1_wv_87': 'FN2_wv_87',\n",
       " 'FN2_wv_87': 'FN1_wv_87',\n",
       " 'FN1_wv_88': 'FN2_wv_88',\n",
       " 'FN2_wv_88': 'FN1_wv_88',\n",
       " 'FN1_wv_89': 'FN2_wv_89',\n",
       " 'FN2_wv_89': 'FN1_wv_89',\n",
       " 'FN1_wv_90': 'FN2_wv_90',\n",
       " 'FN2_wv_90': 'FN1_wv_90',\n",
       " 'FN1_wv_91': 'FN2_wv_91',\n",
       " 'FN2_wv_91': 'FN1_wv_91',\n",
       " 'FN1_wv_92': 'FN2_wv_92',\n",
       " 'FN2_wv_92': 'FN1_wv_92',\n",
       " 'FN1_wv_93': 'FN2_wv_93',\n",
       " 'FN2_wv_93': 'FN1_wv_93',\n",
       " 'FN1_wv_94': 'FN2_wv_94',\n",
       " 'FN2_wv_94': 'FN1_wv_94',\n",
       " 'FN1_wv_95': 'FN2_wv_95',\n",
       " 'FN2_wv_95': 'FN1_wv_95',\n",
       " 'FN1_wv_96': 'FN2_wv_96',\n",
       " 'FN2_wv_96': 'FN1_wv_96',\n",
       " 'FN1_wv_97': 'FN2_wv_97',\n",
       " 'FN2_wv_97': 'FN1_wv_97',\n",
       " 'FN1_wv_98': 'FN2_wv_98',\n",
       " 'FN2_wv_98': 'FN1_wv_98',\n",
       " 'FN1_wv_99': 'FN2_wv_99',\n",
       " 'FN2_wv_99': 'FN1_wv_99',\n",
       " 'FN1': 'FN2',\n",
       " 'FN2': 'FN1',\n",
       " 'FN1_sonin_': 'FN2_sonin_',\n",
       " 'FN1_sonin_b': 'FN2_sonin_b',\n",
       " 'FN1_sonin_c': 'FN2_sonin_c',\n",
       " 'FN1_sonin_ch': 'FN2_sonin_ch',\n",
       " 'FN1_sonin_chu': 'FN2_sonin_chu',\n",
       " 'FN1_sonin_cu': 'FN2_sonin_cu',\n",
       " 'FN1_sonin_d': 'FN2_sonin_d',\n",
       " 'FN1_sonin_du': 'FN2_sonin_du',\n",
       " 'FN1_sonin_f': 'FN2_sonin_f',\n",
       " 'FN1_sonin_g': 'FN2_sonin_g',\n",
       " 'FN1_sonin_gu': 'FN2_sonin_gu',\n",
       " 'FN1_sonin_h': 'FN2_sonin_h',\n",
       " 'FN1_sonin_hu': 'FN2_sonin_hu',\n",
       " 'FN1_sonin_j': 'FN2_sonin_j',\n",
       " 'FN1_sonin_k': 'FN2_sonin_k',\n",
       " 'FN1_sonin_ku': 'FN2_sonin_ku',\n",
       " 'FN1_sonin_l': 'FN2_sonin_l',\n",
       " 'FN1_sonin_m': 'FN2_sonin_m',\n",
       " 'FN1_sonin_n': 'FN2_sonin_n',\n",
       " 'FN1_sonin_p': 'FN2_sonin_p',\n",
       " 'FN1_sonin_q': 'FN2_sonin_q',\n",
       " 'FN1_sonin_r': 'FN2_sonin_r',\n",
       " 'FN1_sonin_ru': 'FN2_sonin_ru',\n",
       " 'FN1_sonin_s': 'FN2_sonin_s',\n",
       " 'FN1_sonin_sh': 'FN2_sonin_sh',\n",
       " 'FN1_sonin_shu': 'FN2_sonin_shu',\n",
       " 'FN1_sonin_su': 'FN2_sonin_su',\n",
       " 'FN1_sonin_t': 'FN2_sonin_t',\n",
       " 'FN1_sonin_w': 'FN2_sonin_w',\n",
       " 'FN1_sonin_x': 'FN2_sonin_x',\n",
       " 'FN1_sonin_y': 'FN2_sonin_y',\n",
       " 'FN1_sonin_z': 'FN2_sonin_z',\n",
       " 'FN1_sonin_zh': 'FN2_sonin_zh',\n",
       " 'FN1_sonin_zhu': 'FN2_sonin_zhu',\n",
       " 'FN1_sonin_zu': 'FN2_sonin_zu',\n",
       " 'FN1_muin_e': 'FN2_muin_e',\n",
       " 'FN1_muin_en': 'FN2_muin_en',\n",
       " 'FN1_muin_ià': 'FN2_muin_ià',\n",
       " 'FN1_muin_iàn': 'FN2_muin_iàn',\n",
       " 'FN1_muin_iàng': 'FN2_muin_iàng',\n",
       " 'FN1_muin_iào': 'FN2_muin_iào',\n",
       " 'FN1_muin_iá': 'FN2_muin_iá',\n",
       " 'FN1_muin_ián': 'FN2_muin_ián',\n",
       " 'FN1_muin_iáng': 'FN2_muin_iáng',\n",
       " 'FN1_muin_iáo': 'FN2_muin_iáo',\n",
       " 'FN1_muin_iè': 'FN2_muin_iè',\n",
       " 'FN1_muin_ié': 'FN2_muin_ié',\n",
       " 'FN1_muin_ióng': 'FN2_muin_ióng',\n",
       " 'FN1_muin_iù': 'FN2_muin_iù',\n",
       " 'FN1_muin_iú': 'FN2_muin_iú',\n",
       " 'FN1_muin_iā': 'FN2_muin_iā',\n",
       " 'FN1_muin_iān': 'FN2_muin_iān',\n",
       " 'FN1_muin_iāng': 'FN2_muin_iāng',\n",
       " 'FN1_muin_iāo': 'FN2_muin_iāo',\n",
       " 'FN1_muin_iē': 'FN2_muin_iē',\n",
       " 'FN1_muin_iě': 'FN2_muin_iě',\n",
       " 'FN1_muin_iōng': 'FN2_muin_iōng',\n",
       " 'FN1_muin_iū': 'FN2_muin_iū',\n",
       " 'FN1_muin_iǎ': 'FN2_muin_iǎ',\n",
       " 'FN1_muin_iǎn': 'FN2_muin_iǎn',\n",
       " 'FN1_muin_iǎng': 'FN2_muin_iǎng',\n",
       " 'FN1_muin_iǎo': 'FN2_muin_iǎo',\n",
       " 'FN1_muin_iǒng': 'FN2_muin_iǒng',\n",
       " 'FN1_muin_iǔ': 'FN2_muin_iǔ',\n",
       " 'FN1_muin_uà': 'FN2_muin_uà',\n",
       " 'FN1_muin_uài': 'FN2_muin_uài',\n",
       " 'FN1_muin_uàn': 'FN2_muin_uàn',\n",
       " 'FN1_muin_uàng': 'FN2_muin_uàng',\n",
       " 'FN1_muin_uá': 'FN2_muin_uá',\n",
       " 'FN1_muin_uái': 'FN2_muin_uái',\n",
       " 'FN1_muin_uán': 'FN2_muin_uán',\n",
       " 'FN1_muin_uáng': 'FN2_muin_uáng',\n",
       " 'FN1_muin_uè': 'FN2_muin_uè',\n",
       " 'FN1_muin_ué': 'FN2_muin_ué',\n",
       " 'FN1_muin_uò': 'FN2_muin_uò',\n",
       " 'FN1_muin_uó': 'FN2_muin_uó',\n",
       " 'FN1_muin_uā': 'FN2_muin_uā',\n",
       " 'FN1_muin_uān': 'FN2_muin_uān',\n",
       " 'FN1_muin_uāng': 'FN2_muin_uāng',\n",
       " 'FN1_muin_uē': 'FN2_muin_uē',\n",
       " 'FN1_muin_uě': 'FN2_muin_uě',\n",
       " 'FN1_muin_uō': 'FN2_muin_uō',\n",
       " 'FN1_muin_uǎ': 'FN2_muin_uǎ',\n",
       " 'FN1_muin_uǎn': 'FN2_muin_uǎn',\n",
       " 'FN1_muin_uǎng': 'FN2_muin_uǎng',\n",
       " 'FN1_muin_uǒ': 'FN2_muin_uǒ',\n",
       " 'FN1_muin_à': 'FN2_muin_à',\n",
       " 'FN1_muin_ài': 'FN2_muin_ài',\n",
       " 'FN1_muin_àn': 'FN2_muin_àn',\n",
       " 'FN1_muin_àng': 'FN2_muin_àng',\n",
       " 'FN1_muin_ào': 'FN2_muin_ào',\n",
       " 'FN1_muin_á': 'FN2_muin_á',\n",
       " 'FN1_muin_ái': 'FN2_muin_ái',\n",
       " 'FN1_muin_án': 'FN2_muin_án',\n",
       " 'FN1_muin_áng': 'FN2_muin_áng',\n",
       " 'FN1_muin_áo': 'FN2_muin_áo',\n",
       " 'FN1_muin_è': 'FN2_muin_è',\n",
       " 'FN1_muin_èi': 'FN2_muin_èi',\n",
       " 'FN1_muin_èn': 'FN2_muin_èn',\n",
       " 'FN1_muin_èng': 'FN2_muin_èng',\n",
       " 'FN1_muin_èr': 'FN2_muin_èr',\n",
       " 'FN1_muin_é': 'FN2_muin_é',\n",
       " 'FN1_muin_éi': 'FN2_muin_éi',\n",
       " 'FN1_muin_én': 'FN2_muin_én',\n",
       " 'FN1_muin_éng': 'FN2_muin_éng',\n",
       " 'FN1_muin_ér': 'FN2_muin_ér',\n",
       " 'FN1_muin_ì': 'FN2_muin_ì',\n",
       " 'FN1_muin_ìn': 'FN2_muin_ìn',\n",
       " 'FN1_muin_ìng': 'FN2_muin_ìng',\n",
       " 'FN1_muin_í': 'FN2_muin_í',\n",
       " 'FN1_muin_ín': 'FN2_muin_ín',\n",
       " 'FN1_muin_íng': 'FN2_muin_íng',\n",
       " 'FN1_muin_ò': 'FN2_muin_ò',\n",
       " 'FN1_muin_òng': 'FN2_muin_òng',\n",
       " 'FN1_muin_òu': 'FN2_muin_òu',\n",
       " 'FN1_muin_ó': 'FN2_muin_ó',\n",
       " 'FN1_muin_óng': 'FN2_muin_óng',\n",
       " 'FN1_muin_óu': 'FN2_muin_óu',\n",
       " 'FN1_muin_ù': 'FN2_muin_ù',\n",
       " 'FN1_muin_ùn': 'FN2_muin_ùn',\n",
       " 'FN1_muin_ú': 'FN2_muin_ú',\n",
       " 'FN1_muin_ún': 'FN2_muin_ún',\n",
       " 'FN1_muin_üè': 'FN2_muin_üè',\n",
       " 'FN1_muin_ā': 'FN2_muin_ā',\n",
       " 'FN1_muin_āi': 'FN2_muin_āi',\n",
       " 'FN1_muin_ān': 'FN2_muin_ān',\n",
       " 'FN1_muin_āng': 'FN2_muin_āng',\n",
       " 'FN1_muin_āo': 'FN2_muin_āo',\n",
       " 'FN1_muin_ē': 'FN2_muin_ē',\n",
       " 'FN1_muin_ēi': 'FN2_muin_ēi',\n",
       " 'FN1_muin_ēn': 'FN2_muin_ēn',\n",
       " 'FN1_muin_ēng': 'FN2_muin_ēng',\n",
       " 'FN1_muin_ě': 'FN2_muin_ě',\n",
       " 'FN1_muin_ěi': 'FN2_muin_ěi',\n",
       " 'FN1_muin_ěn': 'FN2_muin_ěn',\n",
       " 'FN1_muin_ěng': 'FN2_muin_ěng',\n",
       " 'FN1_muin_ěr': 'FN2_muin_ěr',\n",
       " 'FN1_muin_ī': 'FN2_muin_ī',\n",
       " 'FN1_muin_īn': 'FN2_muin_īn',\n",
       " 'FN1_muin_īng': 'FN2_muin_īng',\n",
       " 'FN1_muin_ō': 'FN2_muin_ō',\n",
       " 'FN1_muin_ōng': 'FN2_muin_ōng',\n",
       " 'FN1_muin_ōu': 'FN2_muin_ōu',\n",
       " 'FN1_muin_ū': 'FN2_muin_ū',\n",
       " 'FN1_muin_ūn': 'FN2_muin_ūn',\n",
       " 'FN1_muin_ǎ': 'FN2_muin_ǎ',\n",
       " 'FN1_muin_ǎi': 'FN2_muin_ǎi',\n",
       " 'FN1_muin_ǎn': 'FN2_muin_ǎn',\n",
       " 'FN1_muin_ǎng': 'FN2_muin_ǎng',\n",
       " 'FN1_muin_ǎo': 'FN2_muin_ǎo',\n",
       " 'FN1_muin_ǐ': 'FN2_muin_ǐ',\n",
       " 'FN1_muin_ǐn': 'FN2_muin_ǐn',\n",
       " 'FN1_muin_ǐng': 'FN2_muin_ǐng',\n",
       " 'FN1_muin_ǒ': 'FN2_muin_ǒ',\n",
       " 'FN1_muin_ǒng': 'FN2_muin_ǒng',\n",
       " 'FN1_muin_ǒu': 'FN2_muin_ǒu',\n",
       " 'FN1_muin_ǔ': 'FN2_muin_ǔ',\n",
       " 'FN1_muin_ǔn': 'FN2_muin_ǔn',\n",
       " 'FN1_muin_ǚ': 'FN2_muin_ǚ',\n",
       " 'FN1_muin_ǜ': 'FN2_muin_ǜ',\n",
       " 'FN2_sonin_': 'FN1_sonin_',\n",
       " 'FN2_sonin_b': 'FN1_sonin_b',\n",
       " 'FN2_sonin_c': 'FN1_sonin_c',\n",
       " 'FN2_sonin_ch': 'FN1_sonin_ch',\n",
       " 'FN2_sonin_chu': 'FN1_sonin_chu',\n",
       " 'FN2_sonin_cu': 'FN1_sonin_cu',\n",
       " 'FN2_sonin_d': 'FN1_sonin_d',\n",
       " 'FN2_sonin_du': 'FN1_sonin_du',\n",
       " 'FN2_sonin_f': 'FN1_sonin_f',\n",
       " 'FN2_sonin_g': 'FN1_sonin_g',\n",
       " 'FN2_sonin_gu': 'FN1_sonin_gu',\n",
       " 'FN2_sonin_h': 'FN1_sonin_h',\n",
       " 'FN2_sonin_hu': 'FN1_sonin_hu',\n",
       " 'FN2_sonin_j': 'FN1_sonin_j',\n",
       " 'FN2_sonin_k': 'FN1_sonin_k',\n",
       " 'FN2_sonin_ku': 'FN1_sonin_ku',\n",
       " 'FN2_sonin_l': 'FN1_sonin_l',\n",
       " 'FN2_sonin_m': 'FN1_sonin_m',\n",
       " 'FN2_sonin_n': 'FN1_sonin_n',\n",
       " 'FN2_sonin_p': 'FN1_sonin_p',\n",
       " 'FN2_sonin_q': 'FN1_sonin_q',\n",
       " 'FN2_sonin_r': 'FN1_sonin_r',\n",
       " 'FN2_sonin_ru': 'FN1_sonin_ru',\n",
       " 'FN2_sonin_s': 'FN1_sonin_s',\n",
       " 'FN2_sonin_sh': 'FN1_sonin_sh',\n",
       " 'FN2_sonin_shu': 'FN1_sonin_shu',\n",
       " 'FN2_sonin_su': 'FN1_sonin_su',\n",
       " 'FN2_sonin_t': 'FN1_sonin_t',\n",
       " 'FN2_sonin_tu': 'FN1_sonin_tu',\n",
       " 'FN2_sonin_w': 'FN1_sonin_w',\n",
       " 'FN2_sonin_x': 'FN1_sonin_x',\n",
       " 'FN2_sonin_y': 'FN1_sonin_y',\n",
       " 'FN2_sonin_z': 'FN1_sonin_z',\n",
       " 'FN2_sonin_zh': 'FN1_sonin_zh',\n",
       " 'FN2_sonin_zhu': 'FN1_sonin_zhu',\n",
       " 'FN2_sonin_zu': 'FN1_sonin_zu',\n",
       " 'FN2_muin_en': 'FN1_muin_en',\n",
       " 'FN2_muin_ià': 'FN1_muin_ià',\n",
       " 'FN2_muin_iàn': 'FN1_muin_iàn',\n",
       " 'FN2_muin_iàng': 'FN1_muin_iàng',\n",
       " 'FN2_muin_iào': 'FN1_muin_iào',\n",
       " 'FN2_muin_iá': 'FN1_muin_iá',\n",
       " 'FN2_muin_ián': 'FN1_muin_ián',\n",
       " 'FN2_muin_iáng': 'FN1_muin_iáng',\n",
       " 'FN2_muin_iáo': 'FN1_muin_iáo',\n",
       " 'FN2_muin_iè': 'FN1_muin_iè',\n",
       " 'FN2_muin_ié': 'FN1_muin_ié',\n",
       " 'FN2_muin_ióng': 'FN1_muin_ióng',\n",
       " 'FN2_muin_iù': 'FN1_muin_iù',\n",
       " 'FN2_muin_iú': 'FN1_muin_iú',\n",
       " 'FN2_muin_iā': 'FN1_muin_iā',\n",
       " 'FN2_muin_iān': 'FN1_muin_iān',\n",
       " 'FN2_muin_iāng': 'FN1_muin_iāng',\n",
       " 'FN2_muin_iāo': 'FN1_muin_iāo',\n",
       " 'FN2_muin_iē': 'FN1_muin_iē',\n",
       " 'FN2_muin_iě': 'FN1_muin_iě',\n",
       " 'FN2_muin_iū': 'FN1_muin_iū',\n",
       " 'FN2_muin_iǎ': 'FN1_muin_iǎ',\n",
       " 'FN2_muin_iǎn': 'FN1_muin_iǎn',\n",
       " 'FN2_muin_iǎng': 'FN1_muin_iǎng',\n",
       " 'FN2_muin_iǎo': 'FN1_muin_iǎo',\n",
       " 'FN2_muin_iǒng': 'FN1_muin_iǒng',\n",
       " 'FN2_muin_iǔ': 'FN1_muin_iǔ',\n",
       " 'FN2_muin_uà': 'FN1_muin_uà',\n",
       " 'FN2_muin_uài': 'FN1_muin_uài',\n",
       " 'FN2_muin_uàn': 'FN1_muin_uàn',\n",
       " 'FN2_muin_uàng': 'FN1_muin_uàng',\n",
       " 'FN2_muin_uá': 'FN1_muin_uá',\n",
       " 'FN2_muin_uái': 'FN1_muin_uái',\n",
       " 'FN2_muin_uán': 'FN1_muin_uán',\n",
       " 'FN2_muin_uáng': 'FN1_muin_uáng',\n",
       " 'FN2_muin_uè': 'FN1_muin_uè',\n",
       " 'FN2_muin_ué': 'FN1_muin_ué',\n",
       " 'FN2_muin_uò': 'FN1_muin_uò',\n",
       " 'FN2_muin_uó': 'FN1_muin_uó',\n",
       " 'FN2_muin_uā': 'FN1_muin_uā',\n",
       " 'FN2_muin_uāi': 'FN1_muin_uāi',\n",
       " 'FN2_muin_uān': 'FN1_muin_uān',\n",
       " 'FN2_muin_uāng': 'FN1_muin_uāng',\n",
       " 'FN2_muin_uē': 'FN1_muin_uē',\n",
       " 'FN2_muin_uě': 'FN1_muin_uě',\n",
       " 'FN2_muin_uō': 'FN1_muin_uō',\n",
       " 'FN2_muin_uǎi': 'FN1_muin_uǎi',\n",
       " 'FN2_muin_uǎn': 'FN1_muin_uǎn',\n",
       " 'FN2_muin_uǎng': 'FN1_muin_uǎng',\n",
       " 'FN2_muin_uǒ': 'FN1_muin_uǒ',\n",
       " 'FN2_muin_à': 'FN1_muin_à',\n",
       " 'FN2_muin_ài': 'FN1_muin_ài',\n",
       " 'FN2_muin_àn': 'FN1_muin_àn',\n",
       " 'FN2_muin_àng': 'FN1_muin_àng',\n",
       " 'FN2_muin_ào': 'FN1_muin_ào',\n",
       " 'FN2_muin_á': 'FN1_muin_á',\n",
       " 'FN2_muin_ái': 'FN1_muin_ái',\n",
       " 'FN2_muin_án': 'FN1_muin_án',\n",
       " 'FN2_muin_áng': 'FN1_muin_áng',\n",
       " 'FN2_muin_áo': 'FN1_muin_áo',\n",
       " 'FN2_muin_è': 'FN1_muin_è',\n",
       " 'FN2_muin_èi': 'FN1_muin_èi',\n",
       " 'FN2_muin_èn': 'FN1_muin_èn',\n",
       " 'FN2_muin_èng': 'FN1_muin_èng',\n",
       " 'FN2_muin_èr': 'FN1_muin_èr',\n",
       " 'FN2_muin_é': 'FN1_muin_é',\n",
       " 'FN2_muin_éi': 'FN1_muin_éi',\n",
       " 'FN2_muin_én': 'FN1_muin_én',\n",
       " 'FN2_muin_éng': 'FN1_muin_éng',\n",
       " 'FN2_muin_ér': 'FN1_muin_ér',\n",
       " 'FN2_muin_ì': 'FN1_muin_ì',\n",
       " 'FN2_muin_ìn': 'FN1_muin_ìn',\n",
       " 'FN2_muin_ìng': 'FN1_muin_ìng',\n",
       " 'FN2_muin_í': 'FN1_muin_í',\n",
       " 'FN2_muin_ín': 'FN1_muin_ín',\n",
       " 'FN2_muin_íng': 'FN1_muin_íng',\n",
       " 'FN2_muin_ò': 'FN1_muin_ò',\n",
       " 'FN2_muin_òng': 'FN1_muin_òng',\n",
       " 'FN2_muin_òu': 'FN1_muin_òu',\n",
       " 'FN2_muin_ó': 'FN1_muin_ó',\n",
       " 'FN2_muin_óng': 'FN1_muin_óng',\n",
       " 'FN2_muin_óu': 'FN1_muin_óu',\n",
       " 'FN2_muin_ù': 'FN1_muin_ù',\n",
       " 'FN2_muin_ùn': 'FN1_muin_ùn',\n",
       " 'FN2_muin_ú': 'FN1_muin_ú',\n",
       " 'FN2_muin_ún': 'FN1_muin_ún',\n",
       " 'FN2_muin_üè': 'FN1_muin_üè',\n",
       " 'FN2_muin_ā': 'FN1_muin_ā',\n",
       " 'FN2_muin_āi': 'FN1_muin_āi',\n",
       " 'FN2_muin_ān': 'FN1_muin_ān',\n",
       " 'FN2_muin_āng': 'FN1_muin_āng',\n",
       " 'FN2_muin_āo': 'FN1_muin_āo',\n",
       " 'FN2_muin_ē': 'FN1_muin_ē',\n",
       " 'FN2_muin_ēi': 'FN1_muin_ēi',\n",
       " 'FN2_muin_ēn': 'FN1_muin_ēn',\n",
       " 'FN2_muin_ēng': 'FN1_muin_ēng',\n",
       " 'FN2_muin_ě': 'FN1_muin_ě',\n",
       " 'FN2_muin_ěi': 'FN1_muin_ěi',\n",
       " 'FN2_muin_ěn': 'FN1_muin_ěn',\n",
       " 'FN2_muin_ěng': 'FN1_muin_ěng',\n",
       " 'FN2_muin_ěr': 'FN1_muin_ěr',\n",
       " 'FN2_muin_ī': 'FN1_muin_ī',\n",
       " 'FN2_muin_īn': 'FN1_muin_īn',\n",
       " 'FN2_muin_īng': 'FN1_muin_īng',\n",
       " 'FN2_muin_ō': 'FN1_muin_ō',\n",
       " 'FN2_muin_ōng': 'FN1_muin_ōng',\n",
       " 'FN2_muin_ōu': 'FN1_muin_ōu',\n",
       " 'FN2_muin_ū': 'FN1_muin_ū',\n",
       " 'FN2_muin_ūn': 'FN1_muin_ūn',\n",
       " 'FN2_muin_ǎ': 'FN1_muin_ǎ',\n",
       " 'FN2_muin_ǎi': 'FN1_muin_ǎi',\n",
       " 'FN2_muin_ǎn': 'FN1_muin_ǎn',\n",
       " 'FN2_muin_ǎng': 'FN1_muin_ǎng',\n",
       " 'FN2_muin_ǎo': 'FN1_muin_ǎo',\n",
       " 'FN2_muin_ǐ': 'FN1_muin_ǐ',\n",
       " 'FN2_muin_ǐn': 'FN1_muin_ǐn',\n",
       " 'FN2_muin_ǐng': 'FN1_muin_ǐng',\n",
       " 'FN2_muin_ǒ': 'FN1_muin_ǒ',\n",
       " 'FN2_muin_ǒng': 'FN1_muin_ǒng',\n",
       " 'FN2_muin_ǒu': 'FN1_muin_ǒu',\n",
       " 'FN2_muin_ǔ': 'FN1_muin_ǔ',\n",
       " 'FN2_muin_ǔn': 'FN1_muin_ǔn',\n",
       " 'FN2_muin_ǘ': 'FN1_muin_ǘ',\n",
       " 'FN2_muin_ǚ': 'FN1_muin_ǚ',\n",
       " 'FN2_muin_ǜ': 'FN1_muin_ǜ',\n",
       " 'FN1_radical_一': 'FN2_radical_一',\n",
       " 'FN1_radical_丨': 'FN2_radical_丨',\n",
       " 'FN1_radical_丶': 'FN2_radical_丶',\n",
       " 'FN1_radical_丿': 'FN2_radical_丿',\n",
       " 'FN1_radical_乙': 'FN2_radical_乙',\n",
       " 'FN1_radical_亅': 'FN2_radical_亅',\n",
       " 'FN1_radical_二': 'FN2_radical_二',\n",
       " 'FN1_radical_亠': 'FN2_radical_亠',\n",
       " 'FN1_radical_人': 'FN2_radical_人',\n",
       " 'FN1_radical_儿': 'FN2_radical_儿',\n",
       " 'FN1_radical_先': 'FN2_radical_先',\n",
       " 'FN1_radical_入': 'FN2_radical_入',\n",
       " 'FN1_radical_八': 'FN2_radical_八',\n",
       " 'FN1_radical_冂': 'FN2_radical_冂',\n",
       " 'FN1_radical_冖': 'FN2_radical_冖',\n",
       " 'FN1_radical_冫': 'FN2_radical_冫',\n",
       " 'FN1_radical_几': 'FN2_radical_几',\n",
       " 'FN1_radical_凵': 'FN2_radical_凵',\n",
       " 'FN1_radical_刀': 'FN2_radical_刀',\n",
       " 'FN1_radical_力': 'FN2_radical_力',\n",
       " 'FN1_radical_勹': 'FN2_radical_勹',\n",
       " 'FN1_radical_匕': 'FN2_radical_匕',\n",
       " 'FN1_radical_匚': 'FN2_radical_匚',\n",
       " 'FN1_radical_匸': 'FN2_radical_匸',\n",
       " 'FN1_radical_十': 'FN2_radical_十',\n",
       " 'FN1_radical_卜': 'FN2_radical_卜',\n",
       " 'FN1_radical_卩': 'FN2_radical_卩',\n",
       " 'FN1_radical_厂': 'FN2_radical_厂',\n",
       " 'FN1_radical_厶': 'FN2_radical_厶',\n",
       " 'FN1_radical_又': 'FN2_radical_又',\n",
       " 'FN1_radical_口': 'FN2_radical_口',\n",
       " 'FN1_radical_囗': 'FN2_radical_囗',\n",
       " 'FN1_radical_土': 'FN2_radical_土',\n",
       " 'FN1_radical_士': 'FN2_radical_士',\n",
       " 'FN1_radical_夊': 'FN2_radical_夊',\n",
       " 'FN1_radical_夕': 'FN2_radical_夕',\n",
       " 'FN1_radical_大': 'FN2_radical_大',\n",
       " 'FN1_radical_女': 'FN2_radical_女',\n",
       " 'FN1_radical_子': 'FN2_radical_子',\n",
       " 'FN1_radical_宀': 'FN2_radical_宀',\n",
       " 'FN1_radical_寸': 'FN2_radical_寸',\n",
       " 'FN1_radical_小': 'FN2_radical_小',\n",
       " 'FN1_radical_尢': 'FN2_radical_尢',\n",
       " 'FN1_radical_尸': 'FN2_radical_尸',\n",
       " 'FN1_radical_屮': 'FN2_radical_屮',\n",
       " 'FN1_radical_山': 'FN2_radical_山',\n",
       " 'FN1_radical_巛': 'FN2_radical_巛',\n",
       " 'FN1_radical_工': 'FN2_radical_工',\n",
       " 'FN1_radical_己': 'FN2_radical_己',\n",
       " 'FN1_radical_巾': 'FN2_radical_巾',\n",
       " 'FN1_radical_干': 'FN2_radical_干',\n",
       " 'FN1_radical_幺': 'FN2_radical_幺',\n",
       " 'FN1_radical_广': 'FN2_radical_广',\n",
       " 'FN1_radical_廴': 'FN2_radical_廴',\n",
       " 'FN1_radical_廾': 'FN2_radical_廾',\n",
       " 'FN1_radical_弋': 'FN2_radical_弋',\n",
       " 'FN1_radical_弓': 'FN2_radical_弓',\n",
       " 'FN1_radical_彐': 'FN2_radical_彐',\n",
       " 'FN1_radical_彡': 'FN2_radical_彡',\n",
       " 'FN1_radical_彳': 'FN2_radical_彳',\n",
       " 'FN1_radical_心': 'FN2_radical_心',\n",
       " 'FN1_radical_戈': 'FN2_radical_戈',\n",
       " 'FN1_radical_戶': 'FN2_radical_戶',\n",
       " 'FN1_radical_手': 'FN2_radical_手',\n",
       " 'FN1_radical_支': 'FN2_radical_支',\n",
       " 'FN1_radical_攴': 'FN2_radical_攴',\n",
       " 'FN1_radical_文': 'FN2_radical_文',\n",
       " 'FN1_radical_斗': 'FN2_radical_斗',\n",
       " 'FN1_radical_斤': 'FN2_radical_斤',\n",
       " 'FN1_radical_方': 'FN2_radical_方',\n",
       " 'FN1_radical_日': 'FN2_radical_日',\n",
       " 'FN1_radical_曰': 'FN2_radical_曰',\n",
       " 'FN1_radical_月': 'FN2_radical_月',\n",
       " 'FN1_radical_木': 'FN2_radical_木',\n",
       " 'FN1_radical_欠': 'FN2_radical_欠',\n",
       " 'FN1_radical_止': 'FN2_radical_止',\n",
       " 'FN1_radical_歹': 'FN2_radical_歹',\n",
       " 'FN1_radical_殳': 'FN2_radical_殳',\n",
       " 'FN1_radical_毋': 'FN2_radical_毋',\n",
       " 'FN1_radical_比': 'FN2_radical_比',\n",
       " 'FN1_radical_毛': 'FN2_radical_毛',\n",
       " 'FN1_radical_氏': 'FN2_radical_氏',\n",
       " 'FN1_radical_气': 'FN2_radical_气',\n",
       " 'FN1_radical_水': 'FN2_radical_水',\n",
       " 'FN1_radical_火': 'FN2_radical_火',\n",
       " 'FN1_radical_爪': 'FN2_radical_爪',\n",
       " 'FN1_radical_父': 'FN2_radical_父',\n",
       " 'FN1_radical_爻': 'FN2_radical_爻',\n",
       " 'FN1_radical_片': 'FN2_radical_片',\n",
       " 'FN1_radical_牙': 'FN2_radical_牙',\n",
       " 'FN1_radical_牛': 'FN2_radical_牛',\n",
       " 'FN1_radical_犬': 'FN2_radical_犬',\n",
       " 'FN1_radical_玄': 'FN2_radical_玄',\n",
       " 'FN1_radical_玉': 'FN2_radical_玉',\n",
       " 'FN1_radical_瓜': 'FN2_radical_瓜',\n",
       " 'FN1_radical_瓦': 'FN2_radical_瓦',\n",
       " 'FN1_radical_甘': 'FN2_radical_甘',\n",
       " 'FN1_radical_生': 'FN2_radical_生',\n",
       " 'FN1_radical_用': 'FN2_radical_用',\n",
       " 'FN1_radical_田': 'FN2_radical_田',\n",
       " 'FN1_radical_疋': 'FN2_radical_疋',\n",
       " 'FN1_radical_疒': 'FN2_radical_疒',\n",
       " 'FN1_radical_癶': 'FN2_radical_癶',\n",
       " 'FN1_radical_白': 'FN2_radical_白',\n",
       " 'FN1_radical_皮': 'FN2_radical_皮',\n",
       " 'FN1_radical_皿': 'FN2_radical_皿',\n",
       " 'FN1_radical_目': 'FN2_radical_目',\n",
       " 'FN1_radical_矢': 'FN2_radical_矢',\n",
       " 'FN1_radical_石': 'FN2_radical_石',\n",
       " 'FN1_radical_示': 'FN2_radical_示',\n",
       " 'FN1_radical_礻': 'FN2_radical_礻',\n",
       " 'FN1_radical_禸': 'FN2_radical_禸',\n",
       " 'FN1_radical_禾': 'FN2_radical_禾',\n",
       " 'FN1_radical_穴': 'FN2_radical_穴',\n",
       " 'FN1_radical_立': 'FN2_radical_立',\n",
       " 'FN1_radical_竹': 'FN2_radical_竹',\n",
       " 'FN1_radical_米': 'FN2_radical_米',\n",
       " 'FN1_radical_糸': 'FN2_radical_糸',\n",
       " 'FN1_radical_缶': 'FN2_radical_缶',\n",
       " 'FN1_radical_网': 'FN2_radical_网',\n",
       " 'FN1_radical_羊': 'FN2_radical_羊',\n",
       " 'FN1_radical_羽': 'FN2_radical_羽',\n",
       " 'FN1_radical_老': 'FN2_radical_老',\n",
       " 'FN1_radical_而': 'FN2_radical_而',\n",
       " 'FN1_radical_耒': 'FN2_radical_耒',\n",
       " 'FN1_radical_耳': 'FN2_radical_耳',\n",
       " 'FN1_radical_聿': 'FN2_radical_聿',\n",
       " 'FN1_radical_肉': 'FN2_radical_肉',\n",
       " 'FN1_radical_臣': 'FN2_radical_臣',\n",
       " 'FN1_radical_自': 'FN2_radical_自',\n",
       " 'FN1_radical_至': 'FN2_radical_至',\n",
       " 'FN1_radical_臼': 'FN2_radical_臼',\n",
       " 'FN1_radical_舌': 'FN2_radical_舌',\n",
       " 'FN1_radical_舛': 'FN2_radical_舛',\n",
       " 'FN1_radical_舟': 'FN2_radical_舟',\n",
       " 'FN1_radical_艮': 'FN2_radical_艮',\n",
       " 'FN1_radical_色': 'FN2_radical_色',\n",
       " 'FN1_radical_艸': 'FN2_radical_艸',\n",
       " 'FN1_radical_虍': 'FN2_radical_虍',\n",
       " 'FN1_radical_虫': 'FN2_radical_虫',\n",
       " 'FN1_radical_行': 'FN2_radical_行',\n",
       " 'FN1_radical_衣': 'FN2_radical_衣',\n",
       " 'FN1_radical_襾': 'FN2_radical_襾',\n",
       " 'FN1_radical_見': 'FN2_radical_見',\n",
       " 'FN1_radical_言': 'FN2_radical_言',\n",
       " 'FN1_radical_谷': 'FN2_radical_谷',\n",
       " 'FN1_radical_豆': 'FN2_radical_豆',\n",
       " 'FN1_radical_豕': 'FN2_radical_豕',\n",
       " 'FN1_radical_豸': 'FN2_radical_豸',\n",
       " 'FN1_radical_貝': 'FN2_radical_貝',\n",
       " 'FN1_radical_赤': 'FN2_radical_赤',\n",
       " 'FN1_radical_走': 'FN2_radical_走',\n",
       " 'FN1_radical_足': 'FN2_radical_足',\n",
       " 'FN1_radical_身': 'FN2_radical_身',\n",
       " 'FN1_radical_車': 'FN2_radical_車',\n",
       " 'FN1_radical_辛': 'FN2_radical_辛',\n",
       " 'FN1_radical_辰': 'FN2_radical_辰',\n",
       " 'FN1_radical_辵': 'FN2_radical_辵',\n",
       " 'FN1_radical_邑': 'FN2_radical_邑',\n",
       " 'FN1_radical_酉': 'FN2_radical_酉',\n",
       " 'FN1_radical_釆': 'FN2_radical_釆',\n",
       " 'FN1_radical_里': 'FN2_radical_里',\n",
       " 'FN1_radical_金': 'FN2_radical_金',\n",
       " 'FN1_radical_釒钅': 'FN2_radical_釒钅',\n",
       " 'FN1_radical_長': 'FN2_radical_長',\n",
       " 'FN1_radical_镸': 'FN2_radical_镸',\n",
       " 'FN1_radical_門': 'FN2_radical_門',\n",
       " 'FN1_radical_阜': 'FN2_radical_阜',\n",
       " 'FN1_radical_隶': 'FN2_radical_隶',\n",
       " 'FN1_radical_隹': 'FN2_radical_隹',\n",
       " 'FN1_radical_雨': 'FN2_radical_雨',\n",
       " 'FN1_radical_青': 'FN2_radical_青',\n",
       " 'FN1_radical_非': 'FN2_radical_非',\n",
       " 'FN1_radical_革': 'FN2_radical_革',\n",
       " 'FN1_radical_韋': 'FN2_radical_韋',\n",
       " 'FN1_radical_音': 'FN2_radical_音',\n",
       " 'FN1_radical_頁': 'FN2_radical_頁',\n",
       " 'FN1_radical_風': 'FN2_radical_風',\n",
       " 'FN1_radical_飛': 'FN2_radical_飛',\n",
       " 'FN1_radical_食': 'FN2_radical_食',\n",
       " 'FN1_radical_首': 'FN2_radical_首',\n",
       " 'FN1_radical_香': 'FN2_radical_香',\n",
       " 'FN1_radical_馬': 'FN2_radical_馬',\n",
       " 'FN1_radical_骨': 'FN2_radical_骨',\n",
       " 'FN1_radical_高': 'FN2_radical_高',\n",
       " 'FN1_radical_髟': 'FN2_radical_髟',\n",
       " 'FN1_radical_鬼': 'FN2_radical_鬼',\n",
       " 'FN1_radical_魚': 'FN2_radical_魚',\n",
       " 'FN1_radical_鳥': 'FN2_radical_鳥',\n",
       " 'FN1_radical_鹵': 'FN2_radical_鹵',\n",
       " 'FN1_radical_鹿': 'FN2_radical_鹿',\n",
       " 'FN1_radical_麥': 'FN2_radical_麥',\n",
       " 'FN1_radical_麻': 'FN2_radical_麻',\n",
       " 'FN1_radical_黃': 'FN2_radical_黃',\n",
       " 'FN1_radical_黍': 'FN2_radical_黍',\n",
       " 'FN1_radical_黑': 'FN2_radical_黑',\n",
       " 'FN1_radical_黹': 'FN2_radical_黹',\n",
       " 'FN1_radical_鼎': 'FN2_radical_鼎',\n",
       " 'FN1_radical_鼻': 'FN2_radical_鼻',\n",
       " 'FN1_radical_齊': 'FN2_radical_齊',\n",
       " 'FN1_radical_齒': 'FN2_radical_齒',\n",
       " 'FN1_radical_龍': 'FN2_radical_龍',\n",
       " 'FN2_radical_一': 'FN1_radical_一',\n",
       " 'FN2_radical_丨': 'FN1_radical_丨',\n",
       " 'FN2_radical_丶': 'FN1_radical_丶',\n",
       " 'FN2_radical_丿': 'FN1_radical_丿',\n",
       " 'FN2_radical_乙': 'FN1_radical_乙',\n",
       " 'FN2_radical_亅': 'FN1_radical_亅',\n",
       " 'FN2_radical_二': 'FN1_radical_二',\n",
       " 'FN2_radical_亠': 'FN1_radical_亠',\n",
       " 'FN2_radical_人': 'FN1_radical_人',\n",
       " 'FN2_radical_儿': 'FN1_radical_儿',\n",
       " 'FN2_radical_入': 'FN1_radical_入',\n",
       " 'FN2_radical_八': 'FN1_radical_八',\n",
       " 'FN2_radical_冂': 'FN1_radical_冂',\n",
       " 'FN2_radical_冖': 'FN1_radical_冖',\n",
       " 'FN2_radical_冫': 'FN1_radical_冫',\n",
       " 'FN2_radical_几': 'FN1_radical_几',\n",
       " 'FN2_radical_凵': 'FN1_radical_凵',\n",
       " 'FN2_radical_刀': 'FN1_radical_刀',\n",
       " 'FN2_radical_力': 'FN1_radical_力',\n",
       " 'FN2_radical_勹': 'FN1_radical_勹',\n",
       " 'FN2_radical_匕': 'FN1_radical_匕',\n",
       " 'FN2_radical_匚': 'FN1_radical_匚',\n",
       " 'FN2_radical_匸': 'FN1_radical_匸',\n",
       " 'FN2_radical_十': 'FN1_radical_十',\n",
       " 'FN2_radical_卜': 'FN1_radical_卜',\n",
       " 'FN2_radical_卩': 'FN1_radical_卩',\n",
       " 'FN2_radical_厂': 'FN1_radical_厂',\n",
       " 'FN2_radical_厶': 'FN1_radical_厶',\n",
       " 'FN2_radical_又': 'FN1_radical_又',\n",
       " 'FN2_radical_口': 'FN1_radical_口',\n",
       " 'FN2_radical_囗': 'FN1_radical_囗',\n",
       " 'FN2_radical_土': 'FN1_radical_土',\n",
       " 'FN2_radical_士': 'FN1_radical_士',\n",
       " 'FN2_radical_夂': 'FN1_radical_夂',\n",
       " 'FN2_radical_夊': 'FN1_radical_夊',\n",
       " 'FN2_radical_夕': 'FN1_radical_夕',\n",
       " 'FN2_radical_大': 'FN1_radical_大',\n",
       " 'FN2_radical_女': 'FN1_radical_女',\n",
       " 'FN2_radical_子': 'FN1_radical_子',\n",
       " 'FN2_radical_宀': 'FN1_radical_宀',\n",
       " 'FN2_radical_寸': 'FN1_radical_寸',\n",
       " 'FN2_radical_小': 'FN1_radical_小',\n",
       " 'FN2_radical_尢': 'FN1_radical_尢',\n",
       " 'FN2_radical_尸': 'FN1_radical_尸',\n",
       " 'FN2_radical_屮': 'FN1_radical_屮',\n",
       " 'FN2_radical_山': 'FN1_radical_山',\n",
       " 'FN2_radical_巛': 'FN1_radical_巛',\n",
       " 'FN2_radical_工': 'FN1_radical_工',\n",
       " 'FN2_radical_己': 'FN1_radical_己',\n",
       " 'FN2_radical_巾': 'FN1_radical_巾',\n",
       " 'FN2_radical_干': 'FN1_radical_干',\n",
       " 'FN2_radical_幺': 'FN1_radical_幺',\n",
       " 'FN2_radical_广': 'FN1_radical_广',\n",
       " 'FN2_radical_廴': 'FN1_radical_廴',\n",
       " 'FN2_radical_廾': 'FN1_radical_廾',\n",
       " 'FN2_radical_弋': 'FN1_radical_弋',\n",
       " 'FN2_radical_弓': 'FN1_radical_弓',\n",
       " 'FN2_radical_彐': 'FN1_radical_彐',\n",
       " 'FN2_radical_彡': 'FN1_radical_彡',\n",
       " 'FN2_radical_彳': 'FN1_radical_彳',\n",
       " 'FN2_radical_心': 'FN1_radical_心',\n",
       " 'FN2_radical_戈': 'FN1_radical_戈',\n",
       " 'FN2_radical_戶': 'FN1_radical_戶',\n",
       " 'FN2_radical_手': 'FN1_radical_手',\n",
       " 'FN2_radical_支': 'FN1_radical_支',\n",
       " 'FN2_radical_攴': 'FN1_radical_攴',\n",
       " 'FN2_radical_文': 'FN1_radical_文',\n",
       " 'FN2_radical_斗': 'FN1_radical_斗',\n",
       " 'FN2_radical_斤': 'FN1_radical_斤',\n",
       " 'FN2_radical_方': 'FN1_radical_方',\n",
       " 'FN2_radical_日': 'FN1_radical_日',\n",
       " 'FN2_radical_曰': 'FN1_radical_曰',\n",
       " 'FN2_radical_月': 'FN1_radical_月',\n",
       " 'FN2_radical_木': 'FN1_radical_木',\n",
       " 'FN2_radical_欠': 'FN1_radical_欠',\n",
       " 'FN2_radical_止': 'FN1_radical_止',\n",
       " 'FN2_radical_歹': 'FN1_radical_歹',\n",
       " 'FN2_radical_殳': 'FN1_radical_殳',\n",
       " 'FN2_radical_毋': 'FN1_radical_毋',\n",
       " 'FN2_radical_比': 'FN1_radical_比',\n",
       " 'FN2_radical_毛': 'FN1_radical_毛',\n",
       " 'FN2_radical_氏': 'FN1_radical_氏',\n",
       " 'FN2_radical_气': 'FN1_radical_气',\n",
       " 'FN2_radical_水': 'FN1_radical_水',\n",
       " 'FN2_radical_火': 'FN1_radical_火',\n",
       " 'FN2_radical_爪': 'FN1_radical_爪',\n",
       " 'FN2_radical_爫': 'FN1_radical_爫',\n",
       " 'FN2_radical_父': 'FN1_radical_父',\n",
       " 'FN2_radical_爻': 'FN1_radical_爻',\n",
       " 'FN2_radical_片': 'FN1_radical_片',\n",
       " 'FN2_radical_牙': 'FN1_radical_牙',\n",
       " 'FN2_radical_牛': 'FN1_radical_牛',\n",
       " 'FN2_radical_犬': 'FN1_radical_犬',\n",
       " 'FN2_radical_玄': 'FN1_radical_玄',\n",
       " 'FN2_radical_玉': 'FN1_radical_玉',\n",
       " 'FN2_radical_瓜': 'FN1_radical_瓜',\n",
       " 'FN2_radical_瓦': 'FN1_radical_瓦',\n",
       " 'FN2_radical_甘': 'FN1_radical_甘',\n",
       " 'FN2_radical_生': 'FN1_radical_生',\n",
       " 'FN2_radical_用': 'FN1_radical_用',\n",
       " 'FN2_radical_田': 'FN1_radical_田',\n",
       " 'FN2_radical_疒': 'FN1_radical_疒',\n",
       " 'FN2_radical_癶': 'FN1_radical_癶',\n",
       " 'FN2_radical_白': 'FN1_radical_白',\n",
       " 'FN2_radical_皮': 'FN1_radical_皮',\n",
       " 'FN2_radical_皿': 'FN1_radical_皿',\n",
       " 'FN2_radical_目': 'FN1_radical_目',\n",
       " 'FN2_radical_矢': 'FN1_radical_矢',\n",
       " 'FN2_radical_石': 'FN1_radical_石',\n",
       " 'FN2_radical_示': 'FN1_radical_示',\n",
       " 'FN2_radical_礻': 'FN1_radical_礻',\n",
       " 'FN2_radical_禸': 'FN1_radical_禸',\n",
       " 'FN2_radical_禾': 'FN1_radical_禾',\n",
       " 'FN2_radical_穴': 'FN1_radical_穴',\n",
       " 'FN2_radical_立': 'FN1_radical_立',\n",
       " 'FN2_radical_竹': 'FN1_radical_竹',\n",
       " 'FN2_radical_米': 'FN1_radical_米',\n",
       " 'FN2_radical_糸': 'FN1_radical_糸',\n",
       " 'FN2_radical_缶': 'FN1_radical_缶',\n",
       " 'FN2_radical_网': 'FN1_radical_网',\n",
       " 'FN2_radical_羊': 'FN1_radical_羊',\n",
       " 'FN2_radical_羽': 'FN1_radical_羽',\n",
       " 'FN2_radical_老': 'FN1_radical_老',\n",
       " 'FN2_radical_而': 'FN1_radical_而',\n",
       " 'FN2_radical_耒': 'FN1_radical_耒',\n",
       " 'FN2_radical_耳': 'FN1_radical_耳',\n",
       " 'FN2_radical_聿': 'FN1_radical_聿',\n",
       " 'FN2_radical_肉': 'FN1_radical_肉',\n",
       " 'FN2_radical_臣': 'FN1_radical_臣',\n",
       " 'FN2_radical_自': 'FN1_radical_自',\n",
       " 'FN2_radical_至': 'FN1_radical_至',\n",
       " 'FN2_radical_臼': 'FN1_radical_臼',\n",
       " 'FN2_radical_舌': 'FN1_radical_舌',\n",
       " 'FN2_radical_舛': 'FN1_radical_舛',\n",
       " 'FN2_radical_舟': 'FN1_radical_舟',\n",
       " 'FN2_radical_艮': 'FN1_radical_艮',\n",
       " 'FN2_radical_色': 'FN1_radical_色',\n",
       " 'FN2_radical_艸': 'FN1_radical_艸',\n",
       " 'FN2_radical_虍': 'FN1_radical_虍',\n",
       " 'FN2_radical_虫': 'FN1_radical_虫',\n",
       " 'FN2_radical_血': 'FN1_radical_血',\n",
       " 'FN2_radical_行': 'FN1_radical_行',\n",
       " 'FN2_radical_衣': 'FN1_radical_衣',\n",
       " 'FN2_radical_襾': 'FN1_radical_襾',\n",
       " 'FN2_radical_見': 'FN1_radical_見',\n",
       " 'FN2_radical_角': 'FN1_radical_角',\n",
       " 'FN2_radical_言': 'FN1_radical_言',\n",
       " 'FN2_radical_谷': 'FN1_radical_谷',\n",
       " 'FN2_radical_豆': 'FN1_radical_豆',\n",
       " 'FN2_radical_豕': 'FN1_radical_豕',\n",
       " 'FN2_radical_豸': 'FN1_radical_豸',\n",
       " 'FN2_radical_貝': 'FN1_radical_貝',\n",
       " 'FN2_radical_赤': 'FN1_radical_赤',\n",
       " 'FN2_radical_走': 'FN1_radical_走',\n",
       " 'FN2_radical_足': 'FN1_radical_足',\n",
       " 'FN2_radical_身': 'FN1_radical_身',\n",
       " 'FN2_radical_車': 'FN1_radical_車',\n",
       " 'FN2_radical_辛': 'FN1_radical_辛',\n",
       " 'FN2_radical_辰': 'FN1_radical_辰',\n",
       " 'FN2_radical_辵': 'FN1_radical_辵',\n",
       " 'FN2_radical_邑': 'FN1_radical_邑',\n",
       " 'FN2_radical_酉': 'FN1_radical_酉',\n",
       " 'FN2_radical_釆': 'FN1_radical_釆',\n",
       " 'FN2_radical_里': 'FN1_radical_里',\n",
       " 'FN2_radical_金': 'FN1_radical_金',\n",
       " 'FN2_radical_钅': 'FN1_radical_钅',\n",
       " 'FN2_radical_長': 'FN1_radical_長',\n",
       " 'FN2_radical_門': 'FN1_radical_門',\n",
       " 'FN2_radical_阜': 'FN1_radical_阜',\n",
       " 'FN2_radical_隶': 'FN1_radical_隶',\n",
       " 'FN2_radical_隹': 'FN1_radical_隹',\n",
       " 'FN2_radical_雨': 'FN1_radical_雨',\n",
       " 'FN2_radical_青': 'FN1_radical_青',\n",
       " 'FN2_radical_非': 'FN1_radical_非',\n",
       " 'FN2_radical_面': 'FN1_radical_面',\n",
       " 'FN2_radical_革': 'FN1_radical_革',\n",
       " 'FN2_radical_韋': 'FN1_radical_韋',\n",
       " 'FN2_radical_音': 'FN1_radical_音',\n",
       " 'FN2_radical_頁': 'FN1_radical_頁',\n",
       " 'FN2_radical_風': 'FN1_radical_風',\n",
       " 'FN2_radical_飛': 'FN1_radical_飛',\n",
       " 'FN2_radical_食': 'FN1_radical_食',\n",
       " 'FN2_radical_首': 'FN1_radical_首',\n",
       " 'FN2_radical_香': 'FN1_radical_香',\n",
       " 'FN2_radical_馬': 'FN1_radical_馬',\n",
       " 'FN2_radical_骨': 'FN1_radical_骨',\n",
       " 'FN2_radical_高': 'FN1_radical_高',\n",
       " 'FN2_radical_髟': 'FN1_radical_髟',\n",
       " 'FN2_radical_鬥': 'FN1_radical_鬥',\n",
       " 'FN2_radical_鬼': 'FN1_radical_鬼',\n",
       " 'FN2_radical_魚': 'FN1_radical_魚',\n",
       " 'FN2_radical_鳥': 'FN1_radical_鳥',\n",
       " 'FN2_radical_鹵': 'FN1_radical_鹵',\n",
       " 'FN2_radical_鹿': 'FN1_radical_鹿',\n",
       " 'FN2_radical_麥': 'FN1_radical_麥',\n",
       " 'FN2_radical_麻': 'FN1_radical_麻',\n",
       " 'FN2_radical_黃': 'FN1_radical_黃',\n",
       " 'FN2_radical_黍': 'FN1_radical_黍',\n",
       " 'FN2_radical_黑': 'FN1_radical_黑',\n",
       " 'FN2_radical_鼎': 'FN1_radical_鼎',\n",
       " 'FN2_radical_鼠': 'FN1_radical_鼠',\n",
       " 'FN2_radical_鼻': 'FN1_radical_鼻',\n",
       " 'FN2_radical_齊': 'FN1_radical_齊',\n",
       " 'FN2_radical_齒': 'FN1_radical_齒',\n",
       " 'FN2_radical_龍': 'FN1_radical_龍',\n",
       " 'FN2_radical_龠': 'FN1_radical_龠'}"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "def FN_augmentation( df ):\r\n",
    "    rename_dic = {}\r\n",
    "    for col in (df.columns):\r\n",
    "        if \"FN1\" in col:\r\n",
    "            rename_dic[col] = col.replace(\"FN1\",\"FN2\")\r\n",
    "        elif  \"FN2\" in col:\r\n",
    "            rename_dic[col] = col.replace(\"FN2\",\"FN1\")\r\n",
    "    df = pd.concat([df, df.rename(columns = rename_dic)], axis=0)\r\n",
    "    \r\n",
    "    return df.fillna(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(4)Train 多種 gender RFC"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "sampled_df[ sampled_df.apply(lambda x: x['gender']!=x.mgender,axis=1) ]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>message</th>\n",
       "      <th>userID</th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Zodiac_猴</th>\n",
       "      <th>Zodiac_羊</th>\n",
       "      <th>Zodiac_虎</th>\n",
       "      <th>Zodiac_蛇</th>\n",
       "      <th>Zodiac_豬</th>\n",
       "      <th>Zodiac_雞</th>\n",
       "      <th>Zodiac_馬</th>\n",
       "      <th>Zodiac_鼠</th>\n",
       "      <th>Zodiac_龍</th>\n",
       "      <th>mgender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>何可</td>\n",
       "      <td>0</td>\n",
       "      <td>可</td>\n",
       "      <td>何</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.259699</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>吳國瑜</td>\n",
       "      <td>0</td>\n",
       "      <td>國瑜</td>\n",
       "      <td>吳</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.000507</td>\n",
       "      <td>-1.559357</td>\n",
       "      <td>-0.890834</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>李湘渝</td>\n",
       "      <td>0</td>\n",
       "      <td>湘渝</td>\n",
       "      <td>李</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.018383</td>\n",
       "      <td>1.468332</td>\n",
       "      <td>-0.057867</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>沈春秀</td>\n",
       "      <td>0</td>\n",
       "      <td>春秀</td>\n",
       "      <td>沈</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.752956</td>\n",
       "      <td>-6.028177</td>\n",
       "      <td>-3.599663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>林圓</td>\n",
       "      <td>0</td>\n",
       "      <td>圓</td>\n",
       "      <td>林</td>\n",
       "      <td>1</td>\n",
       "      <td>1940</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.936528</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138412</th>\n",
       "      <td>郭政豪</td>\n",
       "      <td>12</td>\n",
       "      <td>政豪</td>\n",
       "      <td>郭</td>\n",
       "      <td>0</td>\n",
       "      <td>2002</td>\n",
       "      <td>268428420338176</td>\n",
       "      <td>-1.794844</td>\n",
       "      <td>-3.608984</td>\n",
       "      <td>-3.385827</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138413</th>\n",
       "      <td>黃微明</td>\n",
       "      <td>11</td>\n",
       "      <td>微明</td>\n",
       "      <td>黃</td>\n",
       "      <td>0</td>\n",
       "      <td>1999</td>\n",
       "      <td>913839378766328</td>\n",
       "      <td>-1.063672</td>\n",
       "      <td>-12.395959</td>\n",
       "      <td>-2.606959</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138445</th>\n",
       "      <td>周芷茵</td>\n",
       "      <td>13</td>\n",
       "      <td>芷茵</td>\n",
       "      <td>周</td>\n",
       "      <td>1</td>\n",
       "      <td>2005</td>\n",
       "      <td>1718228048482789</td>\n",
       "      <td>-3.529580</td>\n",
       "      <td>-0.019260</td>\n",
       "      <td>5.995256</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138459</th>\n",
       "      <td>陳以利</td>\n",
       "      <td>10</td>\n",
       "      <td>以利</td>\n",
       "      <td>陳</td>\n",
       "      <td>1</td>\n",
       "      <td>1992</td>\n",
       "      <td>1802015343149713</td>\n",
       "      <td>2.032988</td>\n",
       "      <td>0.312624</td>\n",
       "      <td>-4.790244</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138476</th>\n",
       "      <td>魏紹宇</td>\n",
       "      <td>8</td>\n",
       "      <td>紹宇</td>\n",
       "      <td>魏</td>\n",
       "      <td>0</td>\n",
       "      <td>1984</td>\n",
       "      <td>881463202016635</td>\n",
       "      <td>-4.961632</td>\n",
       "      <td>-6.318617</td>\n",
       "      <td>4.248305</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5678 rows × 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  BirthYear FirstName LastName  gender  message            userID  \\\n",
       "57       何可          0         可        何       1     1940               NaN   \n",
       "82      吳國瑜          0        國瑜        吳       1     1940               NaN   \n",
       "121     李湘渝          0        湘渝        李       1     1940               NaN   \n",
       "137     沈春秀          0        春秀        沈       1     1940               NaN   \n",
       "162      林圓          0         圓        林       1     1940               NaN   \n",
       "...     ...        ...       ...      ...     ...      ...               ...   \n",
       "138412  郭政豪         12        政豪        郭       0     2002   268428420338176   \n",
       "138413  黃微明         11        微明        黃       0     1999   913839378766328   \n",
       "138445  周芷茵         13        芷茵        周       1     2005  1718228048482789   \n",
       "138459  陳以利         10        以利        陳       1     1992  1802015343149713   \n",
       "138476  魏紹宇          8        紹宇        魏       0     1984   881463202016635   \n",
       "\n",
       "        FN1_wv_0   FN2_wv_0  FN1_wv_1  ...  Zodiac_猴  Zodiac_羊  Zodiac_虎  \\\n",
       "57      0.000000  -2.259699  0.000000  ...         0         0         0   \n",
       "82      3.000507  -1.559357 -0.890834  ...         0         0         0   \n",
       "121    -1.018383   1.468332 -0.057867  ...         0         0         0   \n",
       "137     1.752956  -6.028177 -3.599663  ...         0         0         0   \n",
       "162     0.000000   0.936528  0.000000  ...         0         0         0   \n",
       "...          ...        ...       ...  ...       ...       ...       ...   \n",
       "138412 -1.794844  -3.608984 -3.385827  ...         0         0         0   \n",
       "138413 -1.063672 -12.395959 -2.606959  ...         0         0         0   \n",
       "138445 -3.529580  -0.019260  5.995256  ...         0         0         0   \n",
       "138459  2.032988   0.312624 -4.790244  ...         1         0         0   \n",
       "138476 -4.961632  -6.318617  4.248305  ...         0         0         0   \n",
       "\n",
       "        Zodiac_蛇  Zodiac_豬  Zodiac_雞  Zodiac_馬  Zodiac_鼠  Zodiac_龍  mgender  \n",
       "57             0         0         0         0         0         1        0  \n",
       "82             0         0         0         0         0         1        0  \n",
       "121            0         0         0         0         0         1        0  \n",
       "137            0         0         0         0         0         1        0  \n",
       "162            0         0         0         0         0         1        0  \n",
       "...          ...       ...       ...       ...       ...       ...      ...  \n",
       "138412         0         0         0         1         0         0        1  \n",
       "138413         0         0         0         0         0         0        1  \n",
       "138445         0         0         1         0         0         0        0  \n",
       "138459         0         0         0         0         0         0        0  \n",
       "138476         0         0         0         0         1         0        1  \n",
       "\n",
       "[5678 rows x 978 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 199
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "y_feature = 'mgender'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "w_io = open(\"./Training/result_all.csv\", \"w\")\r\n",
    "w_io.write(\"Type,feature,lens,accuracy,F1,Precision,Recall\\n\")\r\n",
    "\r\n",
    "result_io = open(\"./Training/result.csv\", \"w\")\r\n",
    "result_io.write(\"feature,lens,accuracy,F1,Precision,Recall\\n\")\r\n",
    "\r\n",
    "Accuracy_list = []\r\n",
    "precision_list = []\r\n",
    "recall_list = []\r\n",
    "F1_list = []\r\n",
    "for i,feature in enumerate(feature_combinations_gender):\r\n",
    "    if type(feature)==str:\r\n",
    "    #if type(feature)==str and 'w2v' == feature:\r\n",
    "        x_feature = get_x_feature ([feature] , Name_df.columns)\r\n",
    "    else:\r\n",
    "        #if 'w2v' not in  feature:\r\n",
    "        #    continue\r\n",
    "        x_feature = get_x_feature (feature , Name_df.columns)\r\n",
    "    f = ''.join( [ x[0].upper() for x in feature] ).upper()\r\n",
    "\r\n",
    "    print(\"Combination\",i,\"Training feature category:\",feature)\r\n",
    "    print(\"len of x_feature:\",len(x_feature))\r\n",
    "    tmp1,tmp2,tmp3,tmp4 = [] , [] , [] , []\r\n",
    "    for test_time in range(1):\r\n",
    "        \r\n",
    "        dev_df = sampled_df.sample( n= len(Name_df)//10, frac=None , replace=False, weights=None, random_state=None, axis=0)\r\n",
    "        #train_x, test_x, train_y, test_y = split_dataset( sampled_df.drop(dev_df.index), 0.7, x_feature, y_feature)\r\n",
    "        train_x, test_x, train_y, test_y = split_dataset( FN_augmentation(sampled_df.drop(dev_df.index)), 0.7, x_feature, y_feature)\r\n",
    "        # Create random forest classifier instance\r\n",
    "        trained_model = random_forest_classifier(train_x, train_y.values.reshape(-1, 1).ravel(), estimators_num = 64 , min_samples_leaf_num = 1)\r\n",
    "        print('Finished training')\r\n",
    "        predictions = trained_model.predict(test_x)\r\n",
    "        print('Finished prdeiction')\r\n",
    "        \r\n",
    "        print(\"Train Metrics\")\r\n",
    "        print(\"train_x len \",len(train_x))\r\n",
    "        Accuracy, precision , recall , F1 = RFC_metrics(train_x , train_y  , trained_model )\r\n",
    "        w_io.write(\"Train,\"+f+\",{},{},{},{},{}\\n\".format(len(x_feature), Accuracy, precision , recall , F1))\r\n",
    "        print(\"\\nTest Metrics\")\r\n",
    "        print(\"Test len \",len(test_x))\r\n",
    "        Accuracy, precision , recall , F1 = RFC_metrics(test_x , test_y  , trained_model )\r\n",
    "        w_io.write(\"Test,\"+f+\",{},{},{},{},{}\\n\".format(len(x_feature),Accuracy, precision , recall , F1))\r\n",
    "        print(\"\\nDevelopment Metrics\")\r\n",
    "        print(\"nDevelopment len \",len(dev_df))\r\n",
    "        Accuracy, precision , recall , F1 = RFC_metrics(dev_df[x_feature] , dev_df[y_feature]  , trained_model )\r\n",
    "        w_io.write(\"Develop,\"+f+\",{},{},{},{},{}\\n\".format(len(x_feature),Accuracy, precision , recall , F1))\r\n",
    "        tmp1+=[Accuracy]\r\n",
    "        tmp2+=[precision]\r\n",
    "        tmp3+=[recall]\r\n",
    "        tmp4+=[F1]\r\n",
    "    avg_Accuracy = round( np.array(tmp1).mean() , 4)\r\n",
    "    avg_precision = round( np.array(tmp2).mean() ,4)\r\n",
    "    avg_recall = round( np.array(tmp3).mean(),4)\r\n",
    "    avg_F1 = round( np.array(tmp4).mean(),4)\r\n",
    "    Accuracy_list+=[avg_Accuracy]\r\n",
    "    precision_list+=[avg_precision]\r\n",
    "    recall_list+=[avg_recall]\r\n",
    "    F1_list+=[avg_F1]\r\n",
    "    result_io.write(f+\",{},{},{},{},{}\\n\".format(len(x_feature),avg_Accuracy, avg_precision , avg_recall , avg_F1))\r\n",
    "    FileName = f + \"_gnder_RFC_model.pkl\"\r\n",
    "    '''\r\n",
    "    with open('./TrainedModel/'+ FileName , 'wb') as handle:\r\n",
    "          pickle.dump(trained_model, handle)\r\n",
    "          print(\"\\Output model Done.\")\r\n",
    "    '''\r\n",
    "    \r\n",
    "w_io.close()\r\n",
    "result_io.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Combination 0 Training feature category: w2v\n",
      "len of x_feature: 200\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9996\n",
      "Precision_score ::  0.9997\n",
      "Recall_score ::  0.9997\n",
      "F1_score ::  0.9997\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9428\n",
      "Precision_score ::  0.9416\n",
      "Recall_score ::  0.9627\n",
      "F1_score ::  0.952\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9464\n",
      "Precision_score ::  0.9431\n",
      "Recall_score ::  0.9672\n",
      "F1_score ::  0.955\n",
      "Combination 1 Training feature category: phonetic\n",
      "len of x_feature: 321\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9283\n",
      "Precision_score ::  0.9391\n",
      "Recall_score ::  0.9392\n",
      "F1_score ::  0.9391\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8751\n",
      "Precision_score ::  0.8908\n",
      "Recall_score ::  0.8982\n",
      "F1_score ::  0.8945\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.87\n",
      "Precision_score ::  0.8818\n",
      "Recall_score ::  0.8971\n",
      "F1_score ::  0.8894\n",
      "Combination 2 Training feature category: fortune_map\n",
      "len of x_feature: 27\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.5988\n",
      "Precision_score ::  0.5993\n",
      "Recall_score ::  0.9564\n",
      "F1_score ::  0.7369\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.602\n",
      "Precision_score ::  0.6031\n",
      "Recall_score ::  0.9566\n",
      "F1_score ::  0.7398\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.59\n",
      "Precision_score ::  0.5929\n",
      "Recall_score ::  0.9528\n",
      "F1_score ::  0.7309\n",
      "Combination 3 Training feature category: Zodiac\n",
      "len of x_feature: 12\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.5927\n",
      "Precision_score ::  0.598\n",
      "Recall_score ::  0.9396\n",
      "F1_score ::  0.7308\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.5903\n",
      "Precision_score ::  0.5957\n",
      "Recall_score ::  0.94\n",
      "F1_score ::  0.7293\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.5937\n",
      "Precision_score ::  0.599\n",
      "Recall_score ::  0.9421\n",
      "F1_score ::  0.7324\n",
      "Combination 4 Training feature category: radical\n",
      "len of x_feature: 408\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.8166\n",
      "Precision_score ::  0.8261\n",
      "Recall_score ::  0.8716\n",
      "F1_score ::  0.8482\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.7995\n",
      "Precision_score ::  0.8119\n",
      "Recall_score ::  0.8576\n",
      "F1_score ::  0.8341\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8014\n",
      "Precision_score ::  0.8136\n",
      "Recall_score ::  0.8608\n",
      "F1_score ::  0.8365\n",
      "Combination 5 Training feature category: uni-gram\n",
      "len of x_feature: 2\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9945\n",
      "Precision_score ::  0.9952\n",
      "Recall_score ::  0.9955\n",
      "F1_score ::  0.9953\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.902\n",
      "Precision_score ::  0.9115\n",
      "Recall_score ::  0.9229\n",
      "F1_score ::  0.9172\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9007\n",
      "Precision_score ::  0.9124\n",
      "Recall_score ::  0.9204\n",
      "F1_score ::  0.9164\n",
      "Combination 6 Training feature category: ['w2v', 'phonetic']\n",
      "len of x_feature: 521\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9443\n",
      "Precision_score ::  0.9416\n",
      "Recall_score ::  0.965\n",
      "F1_score ::  0.9532\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9414\n",
      "Precision_score ::  0.9367\n",
      "Recall_score ::  0.9655\n",
      "F1_score ::  0.9509\n",
      "Combination 7 Training feature category: ['w2v', 'fortune_map']\n",
      "len of x_feature: 227\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.944\n",
      "Precision_score ::  0.9417\n",
      "Recall_score ::  0.9646\n",
      "F1_score ::  0.953\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9429\n",
      "Precision_score ::  0.9381\n",
      "Recall_score ::  0.9667\n",
      "F1_score ::  0.9522\n",
      "Combination 8 Training feature category: ['w2v', 'Zodiac']\n",
      "len of x_feature: 212\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9433\n",
      "Precision_score ::  0.9413\n",
      "Recall_score ::  0.9638\n",
      "F1_score ::  0.9524\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9444\n",
      "Precision_score ::  0.9435\n",
      "Recall_score ::  0.9647\n",
      "F1_score ::  0.954\n",
      "Combination 9 Training feature category: ['w2v', 'radical']\n",
      "len of x_feature: 608\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9998\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.944\n",
      "Precision_score ::  0.9409\n",
      "Recall_score ::  0.9654\n",
      "F1_score ::  0.953\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9419\n",
      "Precision_score ::  0.94\n",
      "Recall_score ::  0.9634\n",
      "F1_score ::  0.9516\n",
      "Combination 10 Training feature category: ['w2v', 'uni-gram']\n",
      "len of x_feature: 202\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9426\n",
      "Precision_score ::  0.9391\n",
      "Recall_score ::  0.9648\n",
      "F1_score ::  0.9518\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9396\n",
      "Precision_score ::  0.937\n",
      "Recall_score ::  0.9623\n",
      "F1_score ::  0.9495\n",
      "Combination 11 Training feature category: ['phonetic', 'fortune_map']\n",
      "len of x_feature: 348\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.983\n",
      "Precision_score ::  0.9863\n",
      "Recall_score ::  0.9847\n",
      "F1_score ::  0.9855\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8819\n",
      "Precision_score ::  0.8901\n",
      "Recall_score ::  0.912\n",
      "F1_score ::  0.9009\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8765\n",
      "Precision_score ::  0.8843\n",
      "Recall_score ::  0.9087\n",
      "F1_score ::  0.8964\n",
      "Combination 12 Training feature category: ['phonetic', 'Zodiac']\n",
      "len of x_feature: 333\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.966\n",
      "Precision_score ::  0.9728\n",
      "Recall_score ::  0.9692\n",
      "F1_score ::  0.971\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8637\n",
      "Precision_score ::  0.8797\n",
      "Recall_score ::  0.8895\n",
      "F1_score ::  0.8846\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8645\n",
      "Precision_score ::  0.882\n",
      "Recall_score ::  0.8888\n",
      "F1_score ::  0.8854\n",
      "Combination 13 Training feature category: ['phonetic', 'radical']\n",
      "len of x_feature: 729\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9917\n",
      "Precision_score ::  0.9927\n",
      "Recall_score ::  0.9933\n",
      "F1_score ::  0.993\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9304\n",
      "Precision_score ::  0.9331\n",
      "Recall_score ::  0.9491\n",
      "F1_score ::  0.941\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9315\n",
      "Precision_score ::  0.937\n",
      "Recall_score ::  0.9473\n",
      "F1_score ::  0.9421\n",
      "Combination 14 Training feature category: ['phonetic', 'uni-gram']\n",
      "len of x_feature: 323\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9946\n",
      "Precision_score ::  0.9951\n",
      "Recall_score ::  0.9958\n",
      "F1_score ::  0.9955\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9219\n",
      "Precision_score ::  0.9247\n",
      "Recall_score ::  0.9442\n",
      "F1_score ::  0.9344\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9203\n",
      "Precision_score ::  0.9196\n",
      "Recall_score ::  0.9456\n",
      "F1_score ::  0.9324\n",
      "Combination 15 Training feature category: ['fortune_map', 'Zodiac']\n",
      "len of x_feature: 39\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.621\n",
      "Precision_score ::  0.6252\n",
      "Recall_score ::  0.8868\n",
      "F1_score ::  0.7334\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.6084\n",
      "Precision_score ::  0.6192\n",
      "Recall_score ::  0.8731\n",
      "F1_score ::  0.7246\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.5933\n",
      "Precision_score ::  0.6087\n",
      "Recall_score ::  0.8604\n",
      "F1_score ::  0.713\n",
      "Combination 16 Training feature category: ['fortune_map', 'radical']\n",
      "len of x_feature: 435\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9157\n",
      "Precision_score ::  0.9242\n",
      "Recall_score ::  0.9329\n",
      "F1_score ::  0.9285\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8138\n",
      "Precision_score ::  0.8331\n",
      "Recall_score ::  0.8556\n",
      "F1_score ::  0.8442\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8089\n",
      "Precision_score ::  0.8279\n",
      "Recall_score ::  0.8546\n",
      "F1_score ::  0.841\n",
      "Combination 17 Training feature category: ['fortune_map', 'uni-gram']\n",
      "len of x_feature: 29\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9996\n",
      "Precision_score ::  0.9996\n",
      "Recall_score ::  0.9997\n",
      "F1_score ::  0.9997\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8104\n",
      "Precision_score ::  0.8305\n",
      "Recall_score ::  0.8529\n",
      "F1_score ::  0.8416\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8089\n",
      "Precision_score ::  0.8228\n",
      "Recall_score ::  0.8577\n",
      "F1_score ::  0.8399\n",
      "Combination 18 Training feature category: ['Zodiac', 'radical']\n",
      "len of x_feature: 420\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.8533\n",
      "Precision_score ::  0.8641\n",
      "Recall_score ::  0.8906\n",
      "F1_score ::  0.8772\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.7847\n",
      "Precision_score ::  0.804\n",
      "Recall_score ::  0.8385\n",
      "F1_score ::  0.8209\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.7824\n",
      "Precision_score ::  0.8001\n",
      "Recall_score ::  0.8412\n",
      "F1_score ::  0.8201\n",
      "Combination 19 Training feature category: ['Zodiac', 'uni-gram']\n",
      "len of x_feature: 14\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9987\n",
      "Precision_score ::  0.9987\n",
      "Recall_score ::  0.999\n",
      "F1_score ::  0.9989\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8213\n",
      "Precision_score ::  0.8388\n",
      "Recall_score ::  0.8612\n",
      "F1_score ::  0.8499\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8171\n",
      "Precision_score ::  0.8357\n",
      "Recall_score ::  0.8607\n",
      "F1_score ::  0.848\n",
      "Combination 20 Training feature category: ['radical', 'uni-gram']\n",
      "len of x_feature: 410\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9947\n",
      "Precision_score ::  0.995\n",
      "Recall_score ::  0.996\n",
      "F1_score ::  0.9955\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.914\n",
      "Precision_score ::  0.921\n",
      "Recall_score ::  0.9336\n",
      "F1_score ::  0.9273\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9116\n",
      "Precision_score ::  0.9193\n",
      "Recall_score ::  0.9321\n",
      "F1_score ::  0.9257\n",
      "Combination 21 Training feature category: ['w2v', 'phonetic', 'fortune_map']\n",
      "len of x_feature: 548\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9439\n",
      "Precision_score ::  0.941\n",
      "Recall_score ::  0.9652\n",
      "F1_score ::  0.953\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9429\n",
      "Precision_score ::  0.9395\n",
      "Recall_score ::  0.9645\n",
      "F1_score ::  0.9518\n",
      "Combination 22 Training feature category: ['w2v', 'phonetic', 'Zodiac']\n",
      "len of x_feature: 533\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9434\n",
      "Precision_score ::  0.9407\n",
      "Recall_score ::  0.9652\n",
      "F1_score ::  0.9528\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9425\n",
      "Precision_score ::  0.9397\n",
      "Recall_score ::  0.9635\n",
      "F1_score ::  0.9514\n",
      "Combination 23 Training feature category: ['w2v', 'phonetic', 'radical']\n",
      "len of x_feature: 929\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9436\n",
      "Precision_score ::  0.9413\n",
      "Recall_score ::  0.9642\n",
      "F1_score ::  0.9526\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9445\n",
      "Precision_score ::  0.9436\n",
      "Recall_score ::  0.9631\n",
      "F1_score ::  0.9532\n",
      "Combination 24 Training feature category: ['w2v', 'phonetic', 'uni-gram']\n",
      "len of x_feature: 523\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9422\n",
      "Precision_score ::  0.9384\n",
      "Recall_score ::  0.9646\n",
      "F1_score ::  0.9513\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9413\n",
      "Precision_score ::  0.9398\n",
      "Recall_score ::  0.9613\n",
      "F1_score ::  0.9504\n",
      "Combination 25 Training feature category: ['w2v', 'fortune_map', 'Zodiac']\n",
      "len of x_feature: 239\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9445\n",
      "Precision_score ::  0.9427\n",
      "Recall_score ::  0.9651\n",
      "F1_score ::  0.9538\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9438\n",
      "Precision_score ::  0.9419\n",
      "Recall_score ::  0.9636\n",
      "F1_score ::  0.9526\n",
      "Combination 26 Training feature category: ['w2v', 'fortune_map', 'radical']\n",
      "len of x_feature: 635\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9435\n",
      "Precision_score ::  0.9415\n",
      "Recall_score ::  0.964\n",
      "F1_score ::  0.9526\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9411\n",
      "Precision_score ::  0.9371\n",
      "Recall_score ::  0.9649\n",
      "F1_score ::  0.9508\n",
      "Combination 27 Training feature category: ['w2v', 'fortune_map', 'uni-gram']\n",
      "len of x_feature: 229\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9431\n",
      "Precision_score ::  0.9406\n",
      "Recall_score ::  0.9641\n",
      "F1_score ::  0.9522\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9414\n",
      "Precision_score ::  0.9367\n",
      "Recall_score ::  0.9654\n",
      "F1_score ::  0.9508\n",
      "Combination 28 Training feature category: ['w2v', 'Zodiac', 'radical']\n",
      "len of x_feature: 620\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9434\n",
      "Precision_score ::  0.942\n",
      "Recall_score ::  0.9633\n",
      "F1_score ::  0.9525\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9434\n",
      "Precision_score ::  0.9399\n",
      "Recall_score ::  0.9657\n",
      "F1_score ::  0.9526\n",
      "Combination 29 Training feature category: ['w2v', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 214\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9447\n",
      "Precision_score ::  0.9428\n",
      "Recall_score ::  0.9647\n",
      "F1_score ::  0.9536\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9431\n",
      "Precision_score ::  0.9397\n",
      "Recall_score ::  0.9643\n",
      "F1_score ::  0.9518\n",
      "Combination 30 Training feature category: ['w2v', 'radical', 'uni-gram']\n",
      "len of x_feature: 610\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9448\n",
      "Precision_score ::  0.9421\n",
      "Recall_score ::  0.9652\n",
      "F1_score ::  0.9535\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9412\n",
      "Precision_score ::  0.9396\n",
      "Recall_score ::  0.9618\n",
      "F1_score ::  0.9506\n",
      "Combination 31 Training feature category: ['phonetic', 'fortune_map', 'Zodiac']\n",
      "len of x_feature: 360\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9959\n",
      "Precision_score ::  0.9968\n",
      "Recall_score ::  0.9962\n",
      "F1_score ::  0.9965\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8782\n",
      "Precision_score ::  0.885\n",
      "Recall_score ::  0.9118\n",
      "F1_score ::  0.8982\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8692\n",
      "Precision_score ::  0.8777\n",
      "Recall_score ::  0.9056\n",
      "F1_score ::  0.8914\n",
      "Combination 32 Training feature category: ['phonetic', 'fortune_map', 'radical']\n",
      "len of x_feature: 756\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9991\n",
      "Precision_score ::  0.9992\n",
      "Recall_score ::  0.9994\n",
      "F1_score ::  0.9993\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9273\n",
      "Precision_score ::  0.931\n",
      "Recall_score ::  0.9474\n",
      "F1_score ::  0.9391\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9256\n",
      "Precision_score ::  0.9259\n",
      "Recall_score ::  0.9481\n",
      "F1_score ::  0.9369\n",
      "Combination 33 Training feature category: ['phonetic', 'fortune_map', 'uni-gram']\n",
      "len of x_feature: 350\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9997\n",
      "Precision_score ::  0.9996\n",
      "Recall_score ::  0.9998\n",
      "F1_score ::  0.9997\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9112\n",
      "Precision_score ::  0.9121\n",
      "Recall_score ::  0.9393\n",
      "F1_score ::  0.9255\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9118\n",
      "Precision_score ::  0.9187\n",
      "Recall_score ::  0.934\n",
      "F1_score ::  0.9263\n",
      "Combination 34 Training feature category: ['phonetic', 'Zodiac', 'radical']\n",
      "len of x_feature: 741\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.998\n",
      "Precision_score ::  0.9981\n",
      "Recall_score ::  0.9985\n",
      "F1_score ::  0.9983\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9244\n",
      "Precision_score ::  0.9281\n",
      "Recall_score ::  0.9448\n",
      "F1_score ::  0.9364\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9264\n",
      "Precision_score ::  0.9295\n",
      "Recall_score ::  0.9465\n",
      "F1_score ::  0.9379\n",
      "Combination 35 Training feature category: ['phonetic', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 335\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9988\n",
      "Precision_score ::  0.9989\n",
      "Recall_score ::  0.999\n",
      "F1_score ::  0.9989\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.912\n",
      "Precision_score ::  0.9154\n",
      "Recall_score ::  0.9378\n",
      "F1_score ::  0.9265\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9143\n",
      "Precision_score ::  0.9183\n",
      "Recall_score ::  0.9388\n",
      "F1_score ::  0.9284\n",
      "Combination 36 Training feature category: ['phonetic', 'radical', 'uni-gram']\n",
      "len of x_feature: 731\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9948\n",
      "Precision_score ::  0.9948\n",
      "Recall_score ::  0.9964\n",
      "F1_score ::  0.9956\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9319\n",
      "Precision_score ::  0.9335\n",
      "Recall_score ::  0.9511\n",
      "F1_score ::  0.9422\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9336\n",
      "Precision_score ::  0.9362\n",
      "Recall_score ::  0.9535\n",
      "F1_score ::  0.9448\n",
      "Combination 37 Training feature category: ['fortune_map', 'Zodiac', 'radical']\n",
      "len of x_feature: 447\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9668\n",
      "Precision_score ::  0.9711\n",
      "Recall_score ::  0.9724\n",
      "F1_score ::  0.9718\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.808\n",
      "Precision_score ::  0.8211\n",
      "Recall_score ::  0.8604\n",
      "F1_score ::  0.8403\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8001\n",
      "Precision_score ::  0.8119\n",
      "Recall_score ::  0.8597\n",
      "F1_score ::  0.8351\n",
      "Combination 38 Training feature category: ['fortune_map', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 41\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.7273\n",
      "Precision_score ::  0.756\n",
      "Recall_score ::  0.793\n",
      "F1_score ::  0.7741\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.7078\n",
      "Precision_score ::  0.7356\n",
      "Recall_score ::  0.785\n",
      "F1_score ::  0.7595\n",
      "Combination 39 Training feature category: ['fortune_map', 'radical', 'uni-gram']\n",
      "len of x_feature: 437\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9997\n",
      "Precision_score ::  0.9997\n",
      "Recall_score ::  0.9998\n",
      "F1_score ::  0.9997\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8916\n",
      "Precision_score ::  0.8966\n",
      "Recall_score ::  0.9221\n",
      "F1_score ::  0.9092\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8901\n",
      "Precision_score ::  0.8957\n",
      "Recall_score ::  0.9194\n",
      "F1_score ::  0.9074\n",
      "Combination 40 Training feature category: ['Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 422\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9987\n",
      "Precision_score ::  0.9988\n",
      "Recall_score ::  0.9989\n",
      "F1_score ::  0.9989\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8833\n",
      "Precision_score ::  0.8889\n",
      "Recall_score ::  0.9166\n",
      "F1_score ::  0.9025\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8805\n",
      "Precision_score ::  0.8838\n",
      "Recall_score ::  0.9166\n",
      "F1_score ::  0.8999\n",
      "Combination 41 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'Zodiac']\n",
      "len of x_feature: 560\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9432\n",
      "Precision_score ::  0.9416\n",
      "Recall_score ::  0.9631\n",
      "F1_score ::  0.9522\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9415\n",
      "Precision_score ::  0.9394\n",
      "Recall_score ::  0.9636\n",
      "F1_score ::  0.9514\n",
      "Combination 42 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'radical']\n",
      "len of x_feature: 956\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9437\n",
      "Precision_score ::  0.9402\n",
      "Recall_score ::  0.9658\n",
      "F1_score ::  0.9528\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9445\n",
      "Precision_score ::  0.9423\n",
      "Recall_score ::  0.9647\n",
      "F1_score ::  0.9534\n",
      "Combination 43 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'uni-gram']\n",
      "len of x_feature: 550\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9435\n",
      "Precision_score ::  0.94\n",
      "Recall_score ::  0.9658\n",
      "F1_score ::  0.9527\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9398\n",
      "Precision_score ::  0.9368\n",
      "Recall_score ::  0.9614\n",
      "F1_score ::  0.949\n",
      "Combination 44 Training feature category: ['w2v', 'phonetic', 'Zodiac', 'radical']\n",
      "len of x_feature: 941\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9417\n",
      "Precision_score ::  0.9385\n",
      "Recall_score ::  0.9641\n",
      "F1_score ::  0.9511\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9448\n",
      "Precision_score ::  0.9415\n",
      "Recall_score ::  0.967\n",
      "F1_score ::  0.9541\n",
      "Combination 45 Training feature category: ['w2v', 'phonetic', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 535\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9424\n",
      "Precision_score ::  0.9397\n",
      "Recall_score ::  0.9641\n",
      "F1_score ::  0.9517\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9438\n",
      "Precision_score ::  0.9393\n",
      "Recall_score ::  0.9659\n",
      "F1_score ::  0.9524\n",
      "Combination 46 Training feature category: ['w2v', 'phonetic', 'radical', 'uni-gram']\n",
      "len of x_feature: 931\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9432\n",
      "Precision_score ::  0.9404\n",
      "Recall_score ::  0.9643\n",
      "F1_score ::  0.9522\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9462\n",
      "Precision_score ::  0.942\n",
      "Recall_score ::  0.9684\n",
      "F1_score ::  0.955\n",
      "Combination 47 Training feature category: ['w2v', 'fortune_map', 'Zodiac', 'radical']\n",
      "len of x_feature: 647\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9455\n",
      "Precision_score ::  0.9437\n",
      "Recall_score ::  0.965\n",
      "F1_score ::  0.9542\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9428\n",
      "Precision_score ::  0.9387\n",
      "Recall_score ::  0.9657\n",
      "F1_score ::  0.952\n",
      "Combination 48 Training feature category: ['w2v', 'fortune_map', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 241\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9431\n",
      "Precision_score ::  0.9402\n",
      "Recall_score ::  0.9642\n",
      "F1_score ::  0.952\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.943\n",
      "Precision_score ::  0.9394\n",
      "Recall_score ::  0.9658\n",
      "F1_score ::  0.9524\n",
      "Combination 49 Training feature category: ['w2v', 'fortune_map', 'radical', 'uni-gram']\n",
      "len of x_feature: 637\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9442\n",
      "Precision_score ::  0.941\n",
      "Recall_score ::  0.9656\n",
      "F1_score ::  0.9532\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9436\n",
      "Precision_score ::  0.9406\n",
      "Recall_score ::  0.9656\n",
      "F1_score ::  0.9529\n",
      "Combination 50 Training feature category: ['w2v', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 622\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9438\n",
      "Precision_score ::  0.9401\n",
      "Recall_score ::  0.966\n",
      "F1_score ::  0.9529\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9417\n",
      "Precision_score ::  0.9367\n",
      "Recall_score ::  0.9666\n",
      "F1_score ::  0.9514\n",
      "Combination 51 Training feature category: ['phonetic', 'fortune_map', 'Zodiac', 'radical']\n",
      "len of x_feature: 768\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9998\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9234\n",
      "Precision_score ::  0.9253\n",
      "Recall_score ::  0.9462\n",
      "F1_score ::  0.9356\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9204\n",
      "Precision_score ::  0.921\n",
      "Recall_score ::  0.9451\n",
      "F1_score ::  0.9329\n",
      "Combination 52 Training feature category: ['phonetic', 'fortune_map', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 362\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9087\n",
      "Precision_score ::  0.9079\n",
      "Recall_score ::  0.9396\n",
      "F1_score ::  0.9235\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.911\n",
      "Precision_score ::  0.9153\n",
      "Recall_score ::  0.9361\n",
      "F1_score ::  0.9256\n",
      "Combination 53 Training feature category: ['phonetic', 'fortune_map', 'radical', 'uni-gram']\n",
      "len of x_feature: 758\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9996\n",
      "Precision_score ::  0.9997\n",
      "Recall_score ::  0.9997\n",
      "F1_score ::  0.9997\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.927\n",
      "Precision_score ::  0.9278\n",
      "Recall_score ::  0.9492\n",
      "F1_score ::  0.9383\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9286\n",
      "Precision_score ::  0.9322\n",
      "Recall_score ::  0.9484\n",
      "F1_score ::  0.9402\n",
      "Combination 54 Training feature category: ['phonetic', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 743\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9988\n",
      "Precision_score ::  0.9989\n",
      "Recall_score ::  0.999\n",
      "F1_score ::  0.9989\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9297\n",
      "Precision_score ::  0.9328\n",
      "Recall_score ::  0.9489\n",
      "F1_score ::  0.9408\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.931\n",
      "Precision_score ::  0.9339\n",
      "Recall_score ::  0.9496\n",
      "F1_score ::  0.9417\n",
      "Combination 55 Training feature category: ['fortune_map', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 449\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.8782\n",
      "Precision_score ::  0.8811\n",
      "Recall_score ::  0.9169\n",
      "F1_score ::  0.8986\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.8744\n",
      "Precision_score ::  0.8767\n",
      "Recall_score ::  0.9171\n",
      "F1_score ::  0.8964\n",
      "Combination 56 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'Zodiac', 'radical']\n",
      "len of x_feature: 968\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9453\n",
      "Precision_score ::  0.9425\n",
      "Recall_score ::  0.9656\n",
      "F1_score ::  0.9539\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9402\n",
      "Precision_score ::  0.9353\n",
      "Recall_score ::  0.9643\n",
      "F1_score ::  0.9496\n",
      "Combination 57 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'Zodiac', 'uni-gram']\n",
      "len of x_feature: 562\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9443\n",
      "Precision_score ::  0.9424\n",
      "Recall_score ::  0.9644\n",
      "F1_score ::  0.9533\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9383\n",
      "Precision_score ::  0.9346\n",
      "Recall_score ::  0.9615\n",
      "F1_score ::  0.9479\n",
      "Combination 58 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'radical', 'uni-gram']\n",
      "len of x_feature: 958\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.943\n",
      "Precision_score ::  0.9407\n",
      "Recall_score ::  0.964\n",
      "F1_score ::  0.9522\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9439\n",
      "Precision_score ::  0.9422\n",
      "Recall_score ::  0.9625\n",
      "F1_score ::  0.9522\n",
      "Combination 59 Training feature category: ['w2v', 'phonetic', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 943\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9454\n",
      "Precision_score ::  0.9433\n",
      "Recall_score ::  0.9656\n",
      "F1_score ::  0.9543\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9393\n",
      "Precision_score ::  0.9346\n",
      "Recall_score ::  0.9635\n",
      "F1_score ::  0.9488\n",
      "Combination 60 Training feature category: ['w2v', 'fortune_map', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 649\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9439\n",
      "Precision_score ::  0.9433\n",
      "Recall_score ::  0.963\n",
      "F1_score ::  0.9531\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9448\n",
      "Precision_score ::  0.9403\n",
      "Recall_score ::  0.9678\n",
      "F1_score ::  0.9538\n",
      "Combination 61 Training feature category: ['phonetic', 'fortune_map', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 770\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9999\n",
      "Precision_score ::  0.9999\n",
      "Recall_score ::  0.9999\n",
      "F1_score ::  0.9999\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9263\n",
      "Precision_score ::  0.9288\n",
      "Recall_score ::  0.9479\n",
      "F1_score ::  0.9383\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9261\n",
      "Precision_score ::  0.9273\n",
      "Recall_score ::  0.9491\n",
      "F1_score ::  0.938\n",
      "Combination 62 Training feature category: ['w2v', 'phonetic', 'fortune_map', 'Zodiac', 'radical', 'uni-gram']\n",
      "len of x_feature: 970\n",
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  1.0\n",
      "Precision_score ::  1.0\n",
      "Recall_score ::  1.0\n",
      "F1_score ::  1.0\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9439\n",
      "Precision_score ::  0.9414\n",
      "Recall_score ::  0.9651\n",
      "F1_score ::  0.9531\n",
      "\n",
      "Development Metrics\n",
      "nDevelopment len  13850\n",
      "Accuracy ::  0.9442\n",
      "Precision_score ::  0.9368\n",
      "Recall_score ::  0.9689\n",
      "F1_score ::  0.9526\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "source": [
    "dev_df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>BirthYear</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>gender</th>\n",
       "      <th>message</th>\n",
       "      <th>userID</th>\n",
       "      <th>FN1_wv_0</th>\n",
       "      <th>FN2_wv_0</th>\n",
       "      <th>FN1_wv_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Zodiac_狗</th>\n",
       "      <th>Zodiac_猴</th>\n",
       "      <th>Zodiac_羊</th>\n",
       "      <th>Zodiac_虎</th>\n",
       "      <th>Zodiac_蛇</th>\n",
       "      <th>Zodiac_豬</th>\n",
       "      <th>Zodiac_雞</th>\n",
       "      <th>Zodiac_馬</th>\n",
       "      <th>Zodiac_鼠</th>\n",
       "      <th>Zodiac_龍</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121643</th>\n",
       "      <td>郭秀萍</td>\n",
       "      <td>6</td>\n",
       "      <td>秀萍</td>\n",
       "      <td>郭</td>\n",
       "      <td>0</td>\n",
       "      <td>1971</td>\n",
       "      <td>1096256097143074</td>\n",
       "      <td>-6.028177</td>\n",
       "      <td>-1.669684</td>\n",
       "      <td>-5.868910</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72053</th>\n",
       "      <td>陳雪霞</td>\n",
       "      <td>2</td>\n",
       "      <td>雪霞</td>\n",
       "      <td>陳</td>\n",
       "      <td>0</td>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.360215</td>\n",
       "      <td>1.348958</td>\n",
       "      <td>4.014402</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66230</th>\n",
       "      <td>葉競棠</td>\n",
       "      <td>2</td>\n",
       "      <td>競棠</td>\n",
       "      <td>葉</td>\n",
       "      <td>0</td>\n",
       "      <td>1951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.867900</td>\n",
       "      <td>-1.954202</td>\n",
       "      <td>-5.025996</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61165</th>\n",
       "      <td>于曉雯</td>\n",
       "      <td>4</td>\n",
       "      <td>曉雯</td>\n",
       "      <td>于</td>\n",
       "      <td>0</td>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.979229</td>\n",
       "      <td>-1.476311</td>\n",
       "      <td>1.824066</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12409</th>\n",
       "      <td>徐質敏</td>\n",
       "      <td>2</td>\n",
       "      <td>質敏</td>\n",
       "      <td>徐</td>\n",
       "      <td>1</td>\n",
       "      <td>1951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.830149</td>\n",
       "      <td>-6.833077</td>\n",
       "      <td>-4.545825</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>呂聯東</td>\n",
       "      <td>1</td>\n",
       "      <td>聯東</td>\n",
       "      <td>呂</td>\n",
       "      <td>1</td>\n",
       "      <td>1949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.828465</td>\n",
       "      <td>5.197540</td>\n",
       "      <td>-15.155359</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113859</th>\n",
       "      <td>高小妹</td>\n",
       "      <td>6</td>\n",
       "      <td>小妹</td>\n",
       "      <td>高</td>\n",
       "      <td>0</td>\n",
       "      <td>1973</td>\n",
       "      <td>215758365587490</td>\n",
       "      <td>-2.174975</td>\n",
       "      <td>3.197350</td>\n",
       "      <td>4.283507</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128430</th>\n",
       "      <td>朱睿紳</td>\n",
       "      <td>9</td>\n",
       "      <td>睿紳</td>\n",
       "      <td>朱</td>\n",
       "      <td>1</td>\n",
       "      <td>1988</td>\n",
       "      <td>1635708209780201</td>\n",
       "      <td>-2.356484</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>1.819373</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18746</th>\n",
       "      <td>李建棠</td>\n",
       "      <td>2</td>\n",
       "      <td>建棠</td>\n",
       "      <td>李</td>\n",
       "      <td>1</td>\n",
       "      <td>1954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.122230</td>\n",
       "      <td>-1.954202</td>\n",
       "      <td>-3.091460</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86158</th>\n",
       "      <td>賴盈禎</td>\n",
       "      <td>11</td>\n",
       "      <td>盈禎</td>\n",
       "      <td>賴</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>1399290676796157</td>\n",
       "      <td>-1.770196</td>\n",
       "      <td>-4.288151</td>\n",
       "      <td>1.654350</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13850 rows × 977 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       name  BirthYear FirstName LastName  gender  message            userID  \\\n",
       "121643  郭秀萍          6        秀萍        郭       0     1971  1096256097143074   \n",
       "72053   陳雪霞          2        雪霞        陳       0     1954               NaN   \n",
       "66230   葉競棠          2        競棠        葉       0     1951               NaN   \n",
       "61165   于曉雯          4        曉雯        于       0     1960               NaN   \n",
       "12409   徐質敏          2        質敏        徐       1     1951               NaN   \n",
       "...     ...        ...       ...      ...     ...      ...               ...   \n",
       "7917    呂聯東          1        聯東        呂       1     1949               NaN   \n",
       "113859  高小妹          6        小妹        高       0     1973   215758365587490   \n",
       "128430  朱睿紳          9        睿紳        朱       1     1988  1635708209780201   \n",
       "18746   李建棠          2        建棠        李       1     1954               NaN   \n",
       "86158   賴盈禎         11        盈禎        賴       0     1998  1399290676796157   \n",
       "\n",
       "        FN1_wv_0  FN2_wv_0   FN1_wv_1  ...  Zodiac_狗  Zodiac_猴  Zodiac_羊  \\\n",
       "121643 -6.028177 -1.669684  -5.868910  ...         0         0         0   \n",
       "72053   1.360215  1.348958   4.014402  ...         0         0         0   \n",
       "66230  -1.867900 -1.954202  -5.025996  ...         0         0         0   \n",
       "61165  -4.979229 -1.476311   1.824066  ...         0         0         0   \n",
       "12409  -1.830149 -6.833077  -4.545825  ...         0         0         0   \n",
       "...          ...       ...        ...  ...       ...       ...       ...   \n",
       "7917    3.828465  5.197540 -15.155359  ...         0         0         0   \n",
       "113859 -2.174975  3.197350   4.283507  ...         0         0         0   \n",
       "128430 -2.356484  0.194362   1.819373  ...         0         0         0   \n",
       "18746   8.122230 -1.954202  -3.091460  ...         0         0         0   \n",
       "86158  -1.770196 -4.288151   1.654350  ...         0         0         0   \n",
       "\n",
       "        Zodiac_虎  Zodiac_蛇  Zodiac_豬  Zodiac_雞  Zodiac_馬  Zodiac_鼠  Zodiac_龍  \n",
       "121643         0         0         1         0         0         0         0  \n",
       "72053          0         0         0         0         1         0         0  \n",
       "66230          0         0         0         0         0         0         0  \n",
       "61165          0         0         0         0         0         1         0  \n",
       "12409          0         0         0         0         0         0         0  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "7917           0         0         0         0         0         0         0  \n",
       "113859         0         0         0         0         0         0         0  \n",
       "128430         0         0         0         0         0         0         1  \n",
       "18746          0         0         0         0         1         0         0  \n",
       "86158          1         0         0         0         0         0         0  \n",
       "\n",
       "[13850 rows x 977 columns]"
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "train_x, test_x, train_y, test_y = split_dataset( sampled_df.drop(dev_df.index), 0.7, x_feature, y_feature)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(5)save Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "feature =['w2v']\r\n",
    "x_feature = get_x_feature (feature , Name_df.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "\r\n",
    "train_x, test_x, train_y, test_y = split_dataset( FN_augmentation(sampled_df.drop(dev_df.index)), 0.7, x_feature, y_feature)\r\n",
    "\r\n",
    "trained_model = random_forest_classifier(train_x, train_y.values.reshape(-1, 1).ravel(), estimators_num = 64 , min_samples_leaf_num = 1)\r\n",
    "print('Finished training')\r\n",
    "predictions = trained_model.predict(test_x)\r\n",
    "print('Finished prdeiction')\r\n",
    "\r\n",
    "print(\"Train Metrics\")\r\n",
    "print(\"train_x len \",len(train_x))\r\n",
    "Accuracy, precision , recall , F1 = RFC_metrics(train_x , train_y  , trained_model )\r\n",
    "print(\"\\nTest Metrics\")\r\n",
    "print(\"Test len \",len(test_x))\r\n",
    "Accuracy, precision , recall , F1 = RFC_metrics(test_x , test_y  , trained_model )\r\n",
    "\r\n",
    "f = ''.join( [ x[0].upper() for x in feature] ).upper()\r\n",
    "FileName = f + \"_gnder_RFC_model.pkl\"\r\n",
    "\r\n",
    "with open('./TrainedModel/'+ FileName , 'wb') as handle:\r\n",
    "    pickle.dump(trained_model, handle)\r\n",
    "    print(\"Output model Done.\")\r\n",
    "    \r\n",
    "with open('./TrainedModel/'+ f +\"_feature_list.pkl\" , 'wb') as handle:\r\n",
    "    pickle.dump(x_feature, handle)\r\n",
    "    print(\"Output feature Done.\")\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "estimators_num =  64 min_samples_leaf_num =  1 Training Data len =  174511\n",
      "Finished training\n",
      "Finished prdeiction\n",
      "Train Metrics\n",
      "train_x len  174511\n",
      "Accuracy ::  0.9973\n",
      "Precision_score ::  0.9985\n",
      "Recall_score ::  0.9987\n",
      "F1_score ::  0.9986\n",
      "\n",
      "Test Metrics\n",
      "Test len  74791\n",
      "Accuracy ::  0.9902\n",
      "Precision_score ::  0.9921\n",
      "Recall_score ::  0.9977\n",
      "F1_score ::  0.9949\n",
      "Output model Done.\n",
      "Output feature Done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "(3-5) metric評量"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "def RFC_metrics(  data_x , data_y , trained_model ):\r\n",
    "        cf_matrix = confusion_matrix(data_y, trained_model.predict(data_x))\r\n",
    "        TN = cf_matrix[0][0]\r\n",
    "        FP = cf_matrix[0][1]\r\n",
    "        FN = cf_matrix[1][0]\r\n",
    "        TP = cf_matrix[1][1]\r\n",
    "        precison = TP / (TP + FP)\r\n",
    "        recall = TP / (TP + FN)\r\n",
    "        accuracy = (TP + TN) / (TN + FP + FN + TP)\r\n",
    "        F1 = 2*precison*recall / (precison + recall)\r\n",
    "        print(\"Accuracy :: \", round( accuracy, 4) )\r\n",
    "        print(\"Precision_score :: \", round( precison,4)) \r\n",
    "        print(\"Recall_score :: \", round(recall,4))\r\n",
    "        print(\"F1_score :: \", round(F1,4) )\r\n",
    "        return round( accuracy, 4) , round( precison,4) , round(recall,4) ,  round(F1,4)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "target_names = [ '女性' ,'男性']\r\n",
    "\r\n",
    "print(\"report:\\n\",classification_report(test_y, predictions ,target_names= target_names))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          女性       0.88      0.84      0.86     15534\n",
      "          男性       0.89      0.91      0.90     21862\n",
      "\n",
      "    accuracy                           0.88     37396\n",
      "   macro avg       0.88      0.88      0.88     37396\n",
      "weighted avg       0.88      0.88      0.88     37396\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import datetime\r\n",
    "# multi-answer RFC\r\n",
    "def basic_RFClassifier_ts(data_df,x_feature,y_feature,Validation_times,mode,train_index,test_index,random_avg_year_error):\r\n",
    "    single_year_number=0\r\n",
    "    print(datetime.datetime.now())\r\n",
    "    #N fold cross-validation\r\n",
    "    Train_accuracy_score=0\r\n",
    "    Test_accuracy_score=0\r\n",
    "    \r\n",
    "    avg_dist_error = 0\r\n",
    "    avg_random_score=0\r\n",
    "    avg_random_dist_error=0\r\n",
    "    avg_single_year_errorr=0\r\n",
    "    avg_year_error = [0 for x in range(10) ]\r\n",
    "    if mode!=2:\r\n",
    "        random_avg_year_error = [0 for x in range(10) ]\r\n",
    "    for i in range(Validation_times):\r\n",
    "        random_score=0\r\n",
    "        if mode==0:\r\n",
    "            train_x, test_x, train_y, test_y = split_dataset(data_df, 0.7, x_feature, y_feature)\r\n",
    "            train_index = train_x.index\r\n",
    "            test_index = test_x.index\r\n",
    "        else:\r\n",
    "            train_x = data_df.loc[train_index][x_feature]\r\n",
    "            test_x =data_df.loc[test_index][x_feature]\r\n",
    "            train_y = data_df.loc[train_index][y_feature]\r\n",
    "            train_y = train_y.values.reshape(-1, 1)\r\n",
    "            test_y = data_df.loc[test_index][y_feature]\r\n",
    "            test_y = test_y.values.reshape(-1, 1)\r\n",
    "        \r\n",
    "        # Create random forest classifier instance\r\n",
    "        trained_model = random_forest_classifier(train_x, train_y.ravel())\r\n",
    "        print('Finished training')\r\n",
    "        \r\n",
    "        predictions = trained_model.predict(test_x)\r\n",
    "        print('Finished prdeiction')\r\n",
    "        # Train and Test Accuracy\r\n",
    "        if(Validation_times!=1):\r\n",
    "            print('Run times:',i+1)\r\n",
    "\r\n",
    "        test_name_dict_list= get_test_name_dict_list(test_index,data_df,'BirthYear')\r\n",
    "        test_name_year_dict_list =  get_test_name_dict_list(test_index,data_df,'message')\r\n",
    "        print('test dataset 有',len(test_x),'個名字,',len(test_name_dict_list),'種名字')    \r\n",
    "        \r\n",
    "        test_name_list = data_df.loc[test_index].FirstName.tolist()\r\n",
    "        \r\n",
    "        dist_error=0\r\n",
    "        accuracy=0\r\n",
    "        random_dist_error=0\r\n",
    "        single_year_error=0\r\n",
    "        year_error = [0 for x in range(10) ]\r\n",
    "        year_count = [0 for x in range(10) ]\r\n",
    "        \r\n",
    "        if mode!=2:\r\n",
    "            random_year_error = [0 for x in range(10) ]\r\n",
    "            \r\n",
    "        for test_no,year in enumerate(predictions):\r\n",
    "            \r\n",
    "\r\n",
    "            #print(name)\r\n",
    "            name = test_name_list[test_no]\r\n",
    "            if name in test_name_dict_list:\r\n",
    "                year_count[ len(test_name_dict_list[name])-1 ]+=1\r\n",
    "\r\n",
    "                if year in test_name_dict_list[name]:\r\n",
    "                    accuracy+=1\r\n",
    "                else:\r\n",
    "                    #計算錯誤，把平均絕對值誤差加上去\r\n",
    "                    error = get_min_distance(year,test_name_year_dict_list[name]) \r\n",
    "                    dist_error += error\r\n",
    "                    \r\n",
    "                    year_error[ len(test_name_dict_list[name])-1 ]+=error\r\n",
    "      \r\n",
    "                if mode!=2:\r\n",
    "                    random_year = random.randint(1,10)\r\n",
    "                    if random_year in test_name_dict_list[name]:\r\n",
    "                        random_score+=1\r\n",
    "                    else:\r\n",
    "                        error = get_min_distance(random_year,test_name_year_dict_list[name])\r\n",
    "                        random_dist_error += error\r\n",
    "                        random_year_error[ len(test_name_dict_list[name])-1 ] += error\r\n",
    "            else:\r\n",
    "                print('wtf test name not in test_name_dict_list')\r\n",
    "        \r\n",
    "        accuracy/=len(predictions)      \r\n",
    "\r\n",
    "        print (\"Train Accuracy :: \", accuracy_score(train_y, trained_model.predict(train_x)))\r\n",
    "        print (\"Test Accuracy  :: \", accuracy)\r\n",
    "        print('平均年份絕對值誤差::',dist_error/len(predictions) )\r\n",
    "        #print('只在某一年份出現的平均年份絕對值誤差::',single_year_error/single_year_number)\r\n",
    "            \r\n",
    "        for i in range(len(year_error)):\r\n",
    "            avg_year_error[i]+=year_error[i]/year_count[i]\r\n",
    "            if mode!=2:\r\n",
    "                random_avg_year_error[i] = random_year_error[i]/year_count[i]\r\n",
    "                random_avg_year_error[i]+=random_year_error[i]/year_count[i]\r\n",
    "            print('名字只出現在共',i+1,'個年份區間的名字比例::',round(year_count[i]/len(predictions),4)*100,'%')\r\n",
    "            print('名字只出現在共',i+1,'個年份區間的平均誤差::',round(year_error[i]/year_count[i],4))\r\n",
    "            if mode!=2:\r\n",
    "                print('random 名字只出現在共',i+1,'個年份區間的平均誤差::',round(random_year_error[i]/year_count[i],4))\r\n",
    "        if mode==1:    \r\n",
    "            print('Random guess accuracy::',random_score/len(predictions))\r\n",
    "            print('Random guess error::',random_dist_error/len(predictions))\r\n",
    "\r\n",
    "        #print (\" Confusion matrix\\n \", confusion_matrix(test_y, predictions))\r\n",
    "        \r\n",
    "        Train_accuracy_score+=accuracy_score(train_y, trained_model.predict(train_x))\r\n",
    "        Test_accuracy_score+= accuracy\r\n",
    "        avg_dist_error+=dist_error/len(predictions)\r\n",
    "        avg_random_score+=random_score/len(predictions)\r\n",
    "        avg_random_dist_error=random_dist_error/len(predictions)\r\n",
    "        \r\n",
    "#         calculate_errorr_multi_answer( predictions, test_x ,test_name_dict_list,data_df)\r\n",
    "#         validate_error_multi_answer( predictions, data_df,test_y,test_x ,test_name_dict_list)\r\n",
    "        \r\n",
    "    if(Validation_times!=1):\r\n",
    "        Train_accuracy_score/=Validation_times\r\n",
    "        Test_accuracy_score/=Validation_times\r\n",
    "        print (\"Average Train Accuracy :: \", Train_accuracy_score)\r\n",
    "        print (\"Average Test Accuracy  :: \",Test_accuracy_score)\r\n",
    "        print('Average 平均年份絕對值誤差::',avg_dist_error/Validation_times )\r\n",
    "        for i in range(len(year_error)):\r\n",
    "            print('Average 出現在共',i+1,'年份區間的平均誤差::',round(avg_year_error[i]/Validation_times,4))\r\n",
    "            print('random 名字只出現在共',i+1,'個年份區間的平均誤差::',round(random_avg_year_error[i]/Validation_times,4))\r\n",
    "        if mode!=2:\r\n",
    "            print('Average Random guess accuracy::',avg_random_score/Validation_times)\r\n",
    "            print('Average Random guess error::',avg_random_dist_error/Validation_times)  \r\n",
    "        \r\n",
    "        for i in range(9):\r\n",
    "            improve_rate = abs(avg_year_error[i]-random_avg_year_error[i])/random_avg_year_error[i]\r\n",
    "            print('名字只出現在共',i+1,'個年份區間的的improve rate:',round(improve_rate*100,2),'%')\r\n",
    "    return random_avg_year_error"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "ee6b50256cf51eaff9b002b4e0d36bd87519314d49e8d201117cf9d724322922"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}